{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b7ba7b-433c-463c-8e5e-8b975a5be463",
   "metadata": {},
   "source": [
    "# Penguins in Production\n",
    "\n",
    "This notebook creates a [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) to build an end-to-end Machine Learning system to solve the problem of classifying penguin species.\n",
    "\n",
    "This example uses the [Penguins dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data).\n",
    "\n",
    "<img src='https://imgur.com/orZWHly.png' alt='Penguins dataset' width=\"900\">\n",
    "\n",
    "This notebook was created by [Santiago L. Valdarrama](https://twitter.com/svpino) as part of the [Machine Learning School](https://www.ml.school) program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6203b0-5a40-4a14-b9bb-6e092f1bb2e7",
   "metadata": {},
   "source": [
    "Let's ensure we are running the latest version of the SakeMaker SDK. **Restart the Kernel** after you run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72eb4984-3c21-4033-be45-2de2cfc1257c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mName: sagemaker\n",
      "Version: 2.146.0\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: attrs, boto3, google-pasta, importlib-metadata, jsonschema, numpy, packaging, pandas, pathos, platformdirs, protobuf, protobuf3-to-dict, PyYAML, schema, smdebug-rulesconfig\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q --upgrade awscli boto3\n",
    "!pip install -q --upgrade sagemaker==2.146.0\n",
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915b1d0b-d9da-4529-aca5-fd1c08a36f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import argparse\n",
    "import random\n",
    "import tempfile\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from threading import Thread, Event\n",
    "from pathlib import Path\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.inputs import (\n",
    "    TrainingInput, FileSystemInput, CreateModelInput, TransformInput\n",
    ")\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.workflow.steps import (\n",
    "    TuningStep, TrainingStep, ProcessingStep, CacheConfig,\n",
    "    CreateModelStep, TransformStep\n",
    ")\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import Join, JsonGet\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import (\n",
    "    CronExpressionGenerator, EndpointInput, DefaultModelMonitor, ModelQualityMonitor, DatasetFormat\n",
    ")\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.lambda_step import LambdaStep, LambdaOutput, LambdaOutputTypeEnum\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, ParameterString, ParameterFloat, ParameterBoolean\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.quality_check_step import (\n",
    "    DataQualityCheckConfig, QualityCheckStep, ModelQualityCheckConfig\n",
    ")\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.parameter import IntegerParameter\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.tensorflow import TensorFlow, TensorFlowProcessor\n",
    "from sagemaker.tensorflow.model import TensorFlowModel, TensorFlowPredictor\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef66efe2-6a01-41b5-ba8a-9c82c480994c",
   "metadata": {},
   "source": [
    "Let's start by defining a few variables and constants we'll use throughout this notebook:\n",
    "\n",
    "* `sagemaker_client`: We'll use a [boto3 SageMaker Client](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html) instance to access SageMaker.\n",
    "* `iam_client`: We'll use a [boto3 IAM Client](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/iam.html) instance to access IAM.\n",
    "* `role`: This is the execution role attached to this notebook. We can use this role with any of the SageMaker services that need it to ensure they run with the appropriate permissions.\n",
    "* `region`: The current region attached to our session. \n",
    "* `sagemaker_session`: The current SageMaker session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7bb1e9bf-25d8-401b-a7d9-0455b1a7434d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iam_client = boto3.client(\"iam\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "\n",
    "BUCKET = \"mlschool\"\n",
    "PENGUINS_FOLDER = Path(\"penguins\")\n",
    "CODE_FOLDER = PENGUINS_FOLDER / \"code\"\n",
    "S3_FILEPATH = f\"s3://{BUCKET}/{PENGUINS_FOLDER}\"\n",
    "LOCAL_FILEPATH = Path(PENGUINS_FOLDER)/ \"data.csv\"\n",
    "MODEL_PACKAGE_GROUP_NAME = \"penguins\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accefa0d-31d6-4df4-814a-d74c703689b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Downloading the Dataset\n",
    "\n",
    "Let's download the [Penguins dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data) and store it in S3.\n",
    "\n",
    "The SageMaker Pipeline will use the data stored in this S3 location. A production application can add more data to the exact location, and the Pipeline will still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "882a8be9-dc31-4df1-9009-3b2d0284cb70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset S3 location: s3://mlschool/penguins/data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3api create-bucket --bucket $BUCKET\n",
    "\n",
    "# Create the local folder if it doesn't exist.\n",
    "PENGUINS_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the official Penguins dataset and store it locally.\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins_size.csv\", \n",
    "    LOCAL_FILEPATH\n",
    ")\n",
    "\n",
    "# Upload the dataset to S3. We need to do this to make it available to \n",
    "# the preprocessing step.\n",
    "INPUT_DATA_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(LOCAL_FILEPATH), \n",
    "    desired_s3_uri=S3_FILEPATH,\n",
    ")\n",
    "\n",
    "print(f\"Dataset S3 location: {INPUT_DATA_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1efbc-5f66-4b44-9555-68a4731e8e7b",
   "metadata": {},
   "source": [
    "We can now load and display the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19b546a-6884-483b-8cda-0521e2656a99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1    Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2    Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3    Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4    Adelie  Torgersen              36.7             19.3              193.0   \n",
       "..      ...        ...               ...              ...                ...   \n",
       "339  Gentoo     Biscoe               NaN              NaN                NaN   \n",
       "340  Gentoo     Biscoe              46.8             14.3              215.0   \n",
       "341  Gentoo     Biscoe              50.4             15.7              222.0   \n",
       "342  Gentoo     Biscoe              45.2             14.8              212.0   \n",
       "343  Gentoo     Biscoe              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    MALE  \n",
       "1         3800.0  FEMALE  \n",
       "2         3250.0  FEMALE  \n",
       "3            NaN     NaN  \n",
       "4         3450.0  FEMALE  \n",
       "..           ...     ...  \n",
       "339          NaN     NaN  \n",
       "340       4850.0  FEMALE  \n",
       "341       5750.0    MALE  \n",
       "342       5200.0  FEMALE  \n",
       "343       5400.0    MALE  \n",
       "\n",
       "[344 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(LOCAL_FILEPATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e223761b-4fab-4c9a-8aa8-4f899915d8a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remote Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d06e0-b711-4e3d-b424-6fa611a51f94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Preprocessing Script\n",
    "\n",
    "Let's create a script to do feature engineering on the original dataset. We will run this script using a SageMaker Processing Job later in this session.\n",
    "\n",
    "The script should split the data into train, validation, and test sets so we can later train and evaluate a model. We will save the Scikit-Learn pipeline that we use to preprocess the data to use it during inference time.\n",
    "\n",
    "The script uses the [np.split()](https://numpy.org/doc/stable/reference/generated/numpy.split.html) function to split the dataset into three sets in the following way:\n",
    "\n",
    "1. The train set will use the top 70% of the data.\n",
    "2. The validation set will use 15% of the data, starting with the sample after the 70% used for the train set.\n",
    "3. Finally, the test set will use the remaining 15% of the data.\n",
    "\n",
    "Pay special attention to the way the Scikit-Learn pipeline `preprocessor` is used to process the three sets:\n",
    "\n",
    "* First, we use the `fit_transform()` to fit the pipeline on the train set.\n",
    "* Then, we consecutively transform the validation and test sets using `transform()`.\n",
    "\n",
    "Always use `fit_transform()` on the training data to fit the scaling parameters we need to transform the data. For example, `fit_transform()` will learn the mean and variance of the features of the training set. It can then use these same parameters to scale the validation and test sets.\n",
    "\n",
    "That's why we want to save this Scikit-Learn pipeline to use later to scale production data using the same parameters we learned on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6ba7c0-1bd6-4fe5-8b7f-f6cbdfd3846c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PENGUINS_FOLDER}/preprocessor.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from pickle import dump\n",
    "\n",
    "\n",
    "# This is the location where the SageMaker Processing job\n",
    "# will save the input dataset.\n",
    "BASE_DIR = \"/opt/ml/processing\"\n",
    "DATA_FILEPATH = Path(BASE_DIR) / \"input\" / \"data.csv\"\n",
    "\n",
    "\n",
    "def save_splits(base_dir, train, validation, test):\n",
    "    \"\"\"\n",
    "    One of the goals of this script is to output the three\n",
    "    dataset splits. This function will save each of these\n",
    "    splits to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_path = Path(base_dir) / \"train\" \n",
    "    validation_path = Path(base_dir) / \"validation\" \n",
    "    test_path = Path(base_dir) / \"test\"\n",
    "    \n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    validation_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    pd.DataFrame(train).to_csv(train_path / \"train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(validation_path / \"validation.csv\", header=False, index=False)\n",
    "    pd.DataFrame(test).to_csv(test_path / \"test.csv\", header=False, index=False)\n",
    "    \n",
    "\n",
    "def save_pipeline(base_dir, pipeline):\n",
    "    \"\"\"\n",
    "    Saves the Scikit-Learn pipeline that we used to\n",
    "    preprocess the data.\n",
    "    \"\"\"\n",
    "    pipeline_path = Path(base_dir) / \"pipeline\"\n",
    "    pipeline_path.mkdir(parents=True, exist_ok=True)\n",
    "    dump(pipeline, open(pipeline_path / \"pipeline.pkl\", 'wb'))\n",
    "    \n",
    "\n",
    "def generate_baseline_dataset(split_name, base_dir, X, y):\n",
    "    \"\"\"\n",
    "    To monitor the data and the quality of our model we need to compare the \n",
    "    production quality and results against a baseline. To create those baselines, \n",
    "    we need to use a dataset to compute statistics and constraints. That dataset\n",
    "    should contain information in the same format as expected by the production\n",
    "    endpoint. This function will generate a baseline dataset and save it to \n",
    "    disk so we can later use it.\n",
    "    \n",
    "    \"\"\"\n",
    "    baseline_path = Path(base_dir) / f\"{split_name}-baseline\" \n",
    "    baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = X.copy()\n",
    "    \n",
    "    # The baseline dataset needs a column containing the groundtruth.\n",
    "    df[\"groundtruth\"] = y\n",
    "    df[\"groundtruth\"] = df[\"groundtruth\"].values.astype(str)\n",
    "    \n",
    "    # We will use the baseline dataset to generate baselines\n",
    "    # for monitoring data and model quality. To simplify the process, \n",
    "    # we don't want to include any NaN rows.\n",
    "    df = df.dropna()\n",
    "\n",
    "    df.to_json(baseline_path / f\"{split_name}-baseline.json\", orient='records', lines=True)\n",
    "    \n",
    "    \n",
    "def preprocess(base_dir, data_filepath):\n",
    "    \"\"\"\n",
    "    Preprocesses the supplied raw dataset and splits it into a train, validation,\n",
    "    and a test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_filepath)\n",
    "    \n",
    "    numerical_columns = [column for column in df.columns if df[column].dtype in [\"int64\", \"float64\"]]\n",
    "    \n",
    "    numerical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"numerical\", numerical_preprocessor, numerical_columns),\n",
    "            (\"categorical\", categorical_preprocessor, [\"island\"]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "    X = df.drop([\"sex\"], axis=1)\n",
    "    columns = list(X.columns)\n",
    "    \n",
    "    X = X.to_numpy()\n",
    "    \n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(.7 * len(X)), int(.85 * len(X))])\n",
    "    \n",
    "    X_train = pd.DataFrame(train, columns=columns)\n",
    "    X_validation = pd.DataFrame(validation, columns=columns)\n",
    "    X_test = pd.DataFrame(test, columns=columns)\n",
    "    \n",
    "    y_train = X_train.species\n",
    "    y_validation = X_validation.species\n",
    "    y_test = X_test.species\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_validation = label_encoder.transform(y_validation)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    \n",
    "    X_train.drop([\"species\"], axis=1, inplace=True)\n",
    "    X_validation.drop([\"species\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"species\"], axis=1, inplace=True)\n",
    "\n",
    "    # Let's generate a dataset that we can later use to compute\n",
    "    # baseline statistics and constraints about the data that we\n",
    "    # used to train our model.\n",
    "    generate_baseline_dataset(\"train\", base_dir, X_train, y_train)\n",
    "    \n",
    "    # To generate baseline constraints about the quality of the\n",
    "    # model's predictions, we will use the test set.\n",
    "    generate_baseline_dataset(\"test\", base_dir, X_test, y_test)\n",
    "    \n",
    "    # Transform the data using the Scikit-Learn pipeline.\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_validation = preprocessor.transform(X_validation)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    \n",
    "    train = np.concatenate((X_train, np.expand_dims(y_train, axis=1)), axis=1)\n",
    "    validation = np.concatenate((X_validation, np.expand_dims(y_validation, axis=1)), axis=1)\n",
    "    test = np.concatenate((X_test, np.expand_dims(y_test, axis=1)), axis=1)\n",
    "    \n",
    "    save_splits(base_dir, train, validation, test)\n",
    "    save_pipeline(base_dir, pipeline=preprocessor)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess(BASE_DIR, DATA_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8608092-7aab-4fd2-aa99-47c2db27bdb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training Script\n",
    "\n",
    "This script is responsible for training a simple neural network on the train data, validating the model, and saving it so we can later use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92b121d-dcb9-43e8-9ee3-3ececb583e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PENGUINS_FOLDER}/train.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "def train(base_directory, train_path, validation_path, epochs=50, batch_size=32):\n",
    "    X_train = pd.read_csv(Path(train_path) / \"train.csv\")\n",
    "    y_train = X_train[X_train.columns[-1]]\n",
    "    X_train.drop(X_train.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    X_validation = pd.read_csv(Path(validation_path) / \"validation.csv\")\n",
    "    y_validation = X_validation[X_validation.columns[-1]]\n",
    "    X_validation.drop(X_validation.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape=(X_train.shape[1],), activation=\"relu\"),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=SGD(learning_rate=0.01),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        validation_data=(X_validation, y_validation),\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    predictions = np.argmax(model.predict(X_validation), axis=-1)\n",
    "    print(f\"Validation accuracy: {accuracy_score(y_validation, predictions)}\")\n",
    "    \n",
    "    model_filepath = Path(base_directory) / \"model\" / \"001\"\n",
    "    model.save(model_filepath)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Any hyperparameters provided by the training job are passed to the entry point\n",
    "    # as script arguments. SageMaker will also provide a list of special parameters\n",
    "    # that you can capture here. Here is the full list: \n",
    "    # https://github.com/aws/sagemaker-training-toolkit/blob/master/src/sagemaker_training/params.py\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--base_directory\", type=str, default=\"/opt/ml/\")\n",
    "    parser.add_argument(\"--train_path\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\", None))\n",
    "    parser.add_argument(\"--validation_path\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\", None))\n",
    "    parser.add_argument(\"--epochs\", type=int, default=50)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    train(\n",
    "        base_directory=args.base_directory,\n",
    "        train_path=args.train_path,\n",
    "        validation_path=args.validation_path,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa9691-f49f-48af-b272-3d4d17563b01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation Script\n",
    "\n",
    "This script is responsible for loading the model we created and evaluating it on the test set. Before finishing, this script will generate an evaluation report of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee3ab26-afa5-4ceb-9f7a-005d5fdea646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PENGUINS_FOLDER}/evaluation.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/opt/ml/processing/model/\"\n",
    "TEST_PATH = \"/opt/ml/processing/test/\"\n",
    "OUTPUT_PATH = \"/opt/ml/processing/evaluation/\"\n",
    "\n",
    "\n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    # The first step is to extract the model package provided\n",
    "    # by SageMaker.\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    # We can now load the model from disk.\n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    \n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test[X_test.columns[-1]]\n",
    "    X_test.drop(X_test.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "    # Let's add the accuracy of the model to our evaluation report.\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": accuracy\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # We need to save the evaluation report to the output path.\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=MODEL_PATH, \n",
    "        test_path=TEST_PATH,\n",
    "        output_path=OUTPUT_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc27c6-31d4-454d-ae5b-1aeba25f0ac0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Inference Script\n",
    "\n",
    "Deploying the model we trained directly to an endpoint doesn't lets us control the data that goes in and comes out of the endpoint. Fortunately, SageMaker allows us to include an `inference.py` file with the model assets from where we can control how the endpoint works. You can see more information about how this works by checking the [SageMaker TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container) documentation.\n",
    "\n",
    "We will include the inference code as part of the model assets to control the inference process on the SageMaker endpoint. SageMaker will automatically call the `handler()` function for every request to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57e7ad9e-598b-4e28-9a20-a93ad2bb5f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $CODE_FOLDER/inference.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pickle import load\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "PIPELINE_FILE = Path(\"/tmp\") / \"pipeline.pkl\"\n",
    "\n",
    "# By default, we will read the S3 location of the Scikit-Learn\n",
    "# pipeline from an environment variable that we'll configure\n",
    "# when registering the model.\n",
    "PIPELINE_S3_LOCATION = os.environ.get(\"PIPELINE_S3_LOCATION\", None)\n",
    "\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "def handler(data, context, pipeline_s3_location=PIPELINE_S3_LOCATION):\n",
    "    \"\"\"\n",
    "    This is the entrypoint that will be called by SageMaker when the endpoint\n",
    "    receives a request. You can see more information at \n",
    "    https://github.com/aws/sagemaker-tensorflow-serving-container.\n",
    "    \"\"\"\n",
    "    print(\"Handling endpoint request\")\n",
    "    \n",
    "    download_pipeline(pipeline_s3_location)\n",
    "    \n",
    "    instance = _process_input(data, context)\n",
    "    output = _predict(instance, context)\n",
    "    return _process_output(output, context)\n",
    "\n",
    "\n",
    "def download_pipeline(pipeline_s3_location):\n",
    "    \"\"\"\n",
    "    This function will download the Scikit-Learn pipeline from S3\n",
    "    if it doesn't already exist. We need the pipeline to pre-process\n",
    "    the data before we run it through the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    s3_parts = pipeline_s3_location.split('/', 3)\n",
    "    bucket = s3_parts[2]\n",
    "    key = s3_parts[3]\n",
    "    \n",
    "    if not PIPELINE_FILE.exists():\n",
    "        s3.Bucket(bucket).download_file(f\"{key}/pipeline.pkl\", str(PIPELINE_FILE))\n",
    "\n",
    "\n",
    "def transform(payload):\n",
    "    \"\"\"\n",
    "    This function transforms the payload in the request using the\n",
    "    Scikit-Learn pipeline that we created during the preprocessing step.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Transforming input data...\")\n",
    "\n",
    "    pipeline = load(open(PIPELINE_FILE, 'rb'))\n",
    "    \n",
    "    island = payload.get(\"island\", \"\")\n",
    "    culmen_length_mm = payload.get(\"culmen_length_mm\", 0)\n",
    "    culmen_depth_mm = payload.get(\"culmen_depth_mm\", 0)\n",
    "    flipper_length_mm = payload.get(\"flipper_length_mm\", 0)\n",
    "    body_mass_g = payload.get(\"body_mass_g\", 0)\n",
    "    \n",
    "    data = pd.DataFrame(\n",
    "        columns=[\"island\", \"culmen_length_mm\", \"culmen_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"], \n",
    "        data=[[\n",
    "            island, \n",
    "            culmen_length_mm, \n",
    "            culmen_depth_mm, \n",
    "            flipper_length_mm, \n",
    "            body_mass_g\n",
    "        ]]\n",
    "    )\n",
    "    \n",
    "    result = pipeline.transform(data)\n",
    "    return result[0].tolist()\n",
    "    \n",
    "\n",
    "def _process_input(data, context):\n",
    "    print(\"Processing input data...\")\n",
    "    \n",
    "    if context is None:\n",
    "        # The context will be None when we are testing the code\n",
    "        # directly from a notebook. In that case, we can use the\n",
    "        # data directly.\n",
    "        endpoint_input = data\n",
    "    elif context.request_content_type in (\"application/json\", \"application/octet-stream\"):\n",
    "        # When the endpoint is running, we will receive a context\n",
    "        # object. We need to parse the input and turn it into \n",
    "        # JSON in that case.\n",
    "        endpoint_input = json.loads(data.read().decode(\"utf-8\"))\n",
    "\n",
    "        if endpoint_input is None:\n",
    "            raise ValueError(\"There was an error parsing the input request.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {context.request_content_type or 'unknown'}\")\n",
    "        \n",
    "    return transform(endpoint_input)\n",
    "\n",
    "\n",
    "def _predict(instance, context):\n",
    "    print(\"Sending input data to model to make a prediction...\")\n",
    "    \n",
    "    model_input = json.dumps({\"instances\": [instance]})\n",
    "    \n",
    "    if context is None:\n",
    "        # The context will be None when we are testing the code\n",
    "        # directly from a notebook. In that case, we want to return\n",
    "        # a fake prediction back.\n",
    "        result = {\n",
    "            \"predictions\": [\n",
    "                [0.2, 0.5, 0.3]\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        # When the endpoint is running, we will receive a context\n",
    "        # object. In that case we need to send the instance to the\n",
    "        # model to get a prediction back.\n",
    "        response = requests.post(context.rest_uri, data=model_input)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(response.content.decode('utf-8'))\n",
    "            \n",
    "        result = json.loads(response.content)\n",
    "    \n",
    "    print(f\"Response: {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def _process_output(output, context):\n",
    "    print(\"Processing prediction received from the model...\")\n",
    "    \n",
    "    response_content_type = \"application/json\" if context is None else context.accept_header\n",
    "    \n",
    "    prediction = np.argmax(output[\"predictions\"][0])\n",
    "    confidence = output[\"predictions\"][0][prediction]\n",
    "    \n",
    "    print(f\"Prediction: {prediction}. Confidence: {confidence}\")\n",
    "    \n",
    "    result = json.dumps({\n",
    "        \"prediction\": str(prediction),\n",
    "        \"confidence\": confidence\n",
    "    }), response_content_type\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc79a0-adfd-4ce9-8580-5cd228c3c2d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing Scripts Locally\n",
    "\n",
    "We can now load the scripts we just created and run them locally to ensure they work as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2540d8-278a-4953-bc54-0469d154427d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders: ['train-baseline', 'test-baseline', 'train', 'validation', 'test', 'pipeline']\n",
      "\n",
      "Baseline train:\n",
      "{\"island\":\"Biscoe\",\"culmen_length_mm\":52.5,\"culmen_depth_mm\":15.6,\"flipper_length_mm\":221.0,\"body_mass_g\":5450.0,\"groundtruth\":\"2\"}\n",
      "{\"island\":\"Biscoe\",\"culmen_length_mm\":38.8,\"culmen_depth_mm\":17.2,\"flipper_length_mm\":180.0,\"body_mass_g\":3800.0,\"groundtruth\":\"0\"}\n",
      "{\"island\":\"Torgersen\",\"culmen_length_mm\":39.3,\"culmen_depth_mm\":20.6,\"flipper_length_mm\":190.0,\"body_mass_g\":3650.0,\"groundtruth\":\"0\"}\n",
      "{\"island\":\"Biscoe\",\"culmen_length_mm\":46.5,\"culmen_depth_mm\":14.5,\"flipper_length_mm\":213.0,\"body_mass_g\":4400.0,\"groundtruth\":\"2\"}\n",
      "{\"island\":\"Torgersen\",\"culmen_length_mm\":39.0,\"culmen_depth_mm\":17.1,\"flipper_length_mm\":191.0,\"body_mass_g\":3050.0,\"groundtruth\":\"0\"}\n",
      "\n",
      "Baseline test:\n",
      "{\"island\":\"Dream\",\"culmen_length_mm\":36.4,\"culmen_depth_mm\":17.0,\"flipper_length_mm\":195.0,\"body_mass_g\":3325.0,\"groundtruth\":\"0\"}\n",
      "{\"island\":\"Torgersen\",\"culmen_length_mm\":36.7,\"culmen_depth_mm\":19.3,\"flipper_length_mm\":193.0,\"body_mass_g\":3450.0,\"groundtruth\":\"0\"}\n",
      "{\"island\":\"Torgersen\",\"culmen_length_mm\":45.8,\"culmen_depth_mm\":18.9,\"flipper_length_mm\":197.0,\"body_mass_g\":4150.0,\"groundtruth\":\"0\"}\n",
      "{\"island\":\"Biscoe\",\"culmen_length_mm\":46.1,\"culmen_depth_mm\":13.2,\"flipper_length_mm\":211.0,\"body_mass_g\":4500.0,\"groundtruth\":\"2\"}\n",
      "{\"island\":\"Biscoe\",\"culmen_length_mm\":48.4,\"culmen_depth_mm\":14.4,\"flipper_length_mm\":203.0,\"body_mass_g\":4625.0,\"groundtruth\":\"2\"}\n",
      "Epoch 1/10\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2023-05-02 18:52:57.340 tensorflow-2-6-cpu-py-ml-t3-medium-9169b2e75617c45c79c40579f6a8:95 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-05-02 18:52:57.456 tensorflow-2-6-cpu-py-ml-t3-medium-9169b2e75617c45c79c40579f6a8:95 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "8/8 - 1s - loss: 1.1994 - accuracy: 0.2803 - val_loss: 1.1516 - val_accuracy: 0.3137\n",
      "Epoch 2/10\n",
      "8/8 - 0s - loss: 1.1661 - accuracy: 0.3096 - val_loss: 1.1232 - val_accuracy: 0.3137\n",
      "Epoch 3/10\n",
      "8/8 - 0s - loss: 1.1359 - accuracy: 0.3305 - val_loss: 1.0970 - val_accuracy: 0.3725\n",
      "Epoch 4/10\n",
      "8/8 - 0s - loss: 1.1081 - accuracy: 0.3556 - val_loss: 1.0736 - val_accuracy: 0.3725\n",
      "Epoch 5/10\n",
      "8/8 - 0s - loss: 1.0837 - accuracy: 0.3891 - val_loss: 1.0511 - val_accuracy: 0.3922\n",
      "Epoch 6/10\n",
      "8/8 - 0s - loss: 1.0603 - accuracy: 0.4100 - val_loss: 1.0290 - val_accuracy: 0.4118\n",
      "Epoch 7/10\n",
      "8/8 - 0s - loss: 1.0381 - accuracy: 0.4268 - val_loss: 1.0078 - val_accuracy: 0.4706\n",
      "Epoch 8/10\n",
      "8/8 - 0s - loss: 1.0161 - accuracy: 0.4561 - val_loss: 0.9855 - val_accuracy: 0.5294\n",
      "Epoch 9/10\n",
      "8/8 - 0s - loss: 0.9933 - accuracy: 0.4937 - val_loss: 0.9623 - val_accuracy: 0.5686\n",
      "Epoch 10/10\n",
      "8/8 - 0s - loss: 0.9699 - accuracy: 0.5105 - val_loss: 0.9379 - val_accuracy: 0.6078\n",
      "Validation accuracy: 0.6078431372549019\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpg6v7luu_/model/001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg6v7luu_/model/001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6078431372549019\n"
     ]
    }
   ],
   "source": [
    "from penguins.preprocessor import preprocess\n",
    "from penguins.train import train\n",
    "from penguins.evaluation import evaluate\n",
    "\n",
    "\n",
    "def print_baseline(split_name):\n",
    "    print()\n",
    "    print(f\"Baseline {split_name}:\")\n",
    "    with open(Path(directory) / f\"{split_name}-baseline\" / f\"{split_name}-baseline.json\") as baseline:\n",
    "        lines = [next(baseline) for _ in range(5)]\n",
    "        \n",
    "    for l in lines:\n",
    "        print(l[:-1])\n",
    "\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    # First, we preprocess the data and create the \n",
    "    # dataset splits.\n",
    "    preprocess(\n",
    "        base_dir=directory, \n",
    "        data_filepath=LOCAL_FILEPATH\n",
    "    )\n",
    "    \n",
    "    print(f\"Folders: {os.listdir(directory)}\")\n",
    "    \n",
    "    print_baseline(\"train\")\n",
    "    print_baseline(\"test\")\n",
    "\n",
    "    # Then, we train a model using the train and \n",
    "    # validation splits.\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=10\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(Path(directory) / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(Path(directory) / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "    \n",
    "    # We can now call the evaluation script.\n",
    "    evaluate(\n",
    "        model_path=directory, \n",
    "        test_path=Path(directory) / \"test\",\n",
    "        output_path=Path(directory) / \"evaluation\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e7e63-39a8-4859-af1e-3e7b1573f9a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's test the inference code locally to ensure it works before deploying it. The `handler()` function is the entry point that will be called by SageMaker whenever the endpoint receives a request.\n",
    "\n",
    "When testing the inference code, we want to set the `context` to `None` so the function recognizes we call it locally. We also want to set the `pipeline_s3_location` to the S3 location of the Scikit-Learn pipeline. We generated this pipeline in the preprocessing step from Session 1 and uploaded it to the location specified by the `proprocessor_destination` pipeline configuration variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7aca49b-2080-4068-80e6-8b3f10e54177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling endpoint request\n",
      "Processing input data...\n",
      "Transforming input data...\n",
      "Sending input data to model to make a prediction...\n",
      "Response: {'predictions': [[0.2, 0.5, 0.3]]}\n",
      "Processing prediction received from the model...\n",
      "Prediction: 1. Confidence: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{\"prediction\": \"1\", \"confidence\": 0.5}', 'application/json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from penguins.code.inference import handler\n",
    "\n",
    "handler(\n",
    "    data={\n",
    "        \"island\": \"Biscoe\",\n",
    "        \"culmen_length_mm\": 48.6,\n",
    "        \"culmen_depth_mm\": 16.0,\n",
    "        \"flipper_length_mm\": 230.0,\n",
    "        \"body_mass_g\": 5800.0,\n",
    "    }, \n",
    "    context=None, \n",
    "    pipeline_s3_location=preprocessor_destination.default_value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3938a1d-d5bd-4967-ad65-a945d5df1f61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline Configuration\n",
    "\n",
    "While building a pipeline, you only want to rerun every step if you expect a different result. To accomplish this, you can instruct SageMaker to reuse the result of a previous successful run of a pipeline step. You can find more information about this topic in [Caching Pipeline Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html).\n",
    "\n",
    "When creating a SageMaker Pipeline, we can specify a list of parameters we can use on individual pipeline steps. To read more about these parameters, check [Pipeline Parameters](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html).\n",
    "\n",
    "These are the parameters we need:\n",
    "\n",
    "* `dataset_location`: This parameter represents the dataset's location in S3. We will use this parameter to indicate the SageMaker Processing Job where to find the dataset. The Processing Job will download the dataset from S3 and make it available on the instance running the script.\n",
    "* `preprocessor_destination`: We need to define the location where the SageMaker Processing Job will store the output. When it finishes, the Processing Job will copy the script's output to the S3 location specified by this parameter. By default, SageMaker uploads the output of a job to a custom location in S3, but unfortunately, if we rely on that functionality, we can't cache the Processing Step in the Pipeline.\n",
    "* `train_dataset_baseline_destination`: This parameter represents the location where we will store the train dataset to compute constraints and statistic baselines to monitor the model.\n",
    "* `test_dataset_baseline_destination`: This parameter represents the location where we will store the test dataset to compute constraints and statistic baselines to monitor the model.\n",
    "* `timestamp_signature`: We'll use this parameter to automatically generate resources using a unique suffix to avoid collisions.\n",
    "* `evaluation_destination`: This parameter represents the location where the Processing Step running the evaluation script will store the report. \n",
    "* `model_approval_status`: This parameter represents the default approval status we will use when registering a new model. Check [Update the Approval Status of a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-approve.html) for more information about the different approval status of a model and how you can update them.\n",
    "* `accuracy_threshold`: This parameter represents the minimum accuracy that the model should reach for it to be registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86de7edd-18b0-40d1-ac8e-0f3ef4469be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(\n",
    "    enable_caching=True, \n",
    "    expire_after=\"15d\"\n",
    ")\n",
    "\n",
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=INPUT_DATA_URI,\n",
    ")\n",
    "\n",
    "preprocessor_destination = ParameterString(\n",
    "    name=\"preprocessor_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing\",\n",
    ")\n",
    "\n",
    "train_dataset_baseline_destination = ParameterString(\n",
    "    name=\"train_dataset_baseline_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing/baselines/train\",\n",
    ")\n",
    "\n",
    "test_dataset_baseline_destination = ParameterString(\n",
    "    name=\"test_dataset_baseline_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing/baselines/test\",\n",
    ")\n",
    "\n",
    "timestamp_signature = ParameterString(\n",
    "    name=\"timestamp_signature\",\n",
    "    default_value=\"\",\n",
    ")\n",
    "\n",
    "evaluation_destination = ParameterString(\n",
    "    name=\"evaluation_destination\",\n",
    "    default_value=f'{S3_FILEPATH}/evaluation',\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"model_approval_status\", \n",
    "    default_value=\"Approved\"\n",
    ")\n",
    "\n",
    "accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold\", \n",
    "    default_value=0.70\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e109b-4559-4ad1-9528-f24596c6750b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9771e08-5560-492a-845e-f06988b6ae1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Preprocessing Step\n",
    "\n",
    "The first step we need in the pipeline is a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) to run the preprocessing script. This Processing Step will create a SageMaker Processing Job in the background, run the script, and upload the output to S3. You can use Processing Jobs to perform data preprocessing, post-processing, feature engineering, data validation, and model evaluation. Check the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "A processor gives the Processing Step information about the hardware and software that SageMaker should use to launch the Processing Job. To run the script, we need access to Scikit-Learn, so we can use the [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#scikit-learn-processor) processor that comes out-of-the-box with the SageMaker's Python SDK. The [Data Processing with Framework Processors](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks.html) page discusses other built-in processors you can use. The [Docker Registry Paths and Example Code](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html) page contains information about the available framework versions for each region.\n",
    "\n",
    "Here is the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep). Notice how it uses the processor that we defined above.\n",
    "\n",
    "We also need to define the list of inputs that we need on the preprocessing script. In this case, the input is the dataset we stored in S3. \n",
    "\n",
    "We have a few outputs that we want SageMaker to capture when the Processing Job finishes. SageMaker will upload every one of these outputs to the location specified by the `preprocessor_destination` parameter except the baseline data, which we will upload to the location specified by the `baseline_destination` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b982bc3-28f0-473f-b8d2-fc35dd251e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"penguins-preprocessing\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "preprocess_step = ProcessingStep(\n",
    "    name=\"preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=dataset_location, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"pipeline\", source=\"/opt/ml/processing/pipeline\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"train-baseline\", source=\"/opt/ml/processing/train-baseline\", destination=train_dataset_baseline_destination),\n",
    "        ProcessingOutput(output_name=\"test-baseline\", source=\"/opt/ml/processing/test-baseline\", destination=test_dataset_baseline_destination),\n",
    "    ],\n",
    "    code=f\"{PENGUINS_FOLDER}/preprocessor.py\",\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cff4c1-6510-4d99-8ae1-cb14927b87c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training Step\n",
    "\n",
    "We can now create a [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training) that we can add to the pipeline. This Training Step will create a SageMaker Training Job in the background, run the training script, and upload the output to S3. Check the [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) SageMaker's SDK documentation for more information. \n",
    "\n",
    "SageMaker uses the concept of an [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) to handle end-to-end training and deployment tasks. For this example, we will use the built-in [TensorFlow Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) to run the training script we wrote before. The [Docker Registry Paths and Example Code](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html) page contains information about the available framework versions for each region. Here, you can also check the available SageMaker [Deep Learning Container images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md).\n",
    "\n",
    "Notice the list of hyperparameters defined below. SageMaker will pass these hyperparameters as arguments to the entry point of the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90fe82ae-6a2c-4461-bc83-bb52d8871e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=f\"{PENGUINS_FOLDER}/train.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    framework_version=\"2.6\",\n",
    "    py_version=\"py38\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    script_mode=True,\n",
    "    disable_profiler=True,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d2b43-3bb5-4fe9-b3e4-cb8eb55c8a21",
   "metadata": {},
   "source": [
    "We can now create the [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) using the estimator we defined before.\n",
    "\n",
    "This step will receive the train and validation split from the preprocessing step as inputs. Notice how we reference both splits using the `preprocess_step` variable. This creates a dependency between the Training and Processing Step we defined in Session 1. When we build a new Pipeline, we'll see that the Training Step will run once the Processing Step finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99e4850c-83d6-4f4e-a813-d5a3f4bb7486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_step = TrainingStep(\n",
    "    name=\"training\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d0b30-edf1-4b05-a570-e4f1d5a312e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation Step\n",
    "\n",
    "To run the evaluation script, we can use a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing). Check the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "Whenever you want to run a Processing Job using a machine learning framework, you can use an instance of the [FrameworkProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.FrameworkProcessor) class. For example, the [TensorFlowProcessor](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks-tensorflow.html) subclass will give you access to TensorFlow. You can also configure a Processing Job from scratch using a [ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor) instance combined with the [sagemaker.image_uris.retrieve()](https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html) function for generating the URI of one of the  SageMaker pre-built docker images. \n",
    "\n",
    "This time, we will use a [TensorFlowProcessor](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks-tensorflow.html) because we need our script to have access to TensorFlow and Scikit-Learn.\n",
    "\n",
    "We can now create a [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) to run the evaluation script. \n",
    "\n",
    "The inputs of this step will be the model we created and the test set we generated during the preprocessing phase. The output will be the evaluation report file.\n",
    "\n",
    "The [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) lets us specify a list of [PropertyFile](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.properties.PropertyFile) instances from the output of the job. We can use this to map the evaluation report generated in the evaluation script. Check [How to Build and Manage Property Files](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14efc051-fcdd-4cfc-8751-26fae45fc6c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "tensorflow_processor = TensorFlowProcessor(\n",
    "    framework_version=\"2.6\",\n",
    "    py_version=\"py38\",\n",
    "    base_job_name=\"penguins-evaluation-processor\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "# By default, the TensorFlowProcessor runs the script using\n",
    "# /bin/bash as its entrypoint. We want to ensure we run it \n",
    "# using python3.\n",
    "tensorflow_processor.framework_entrypoint_command = [\"python3\"]\n",
    "\n",
    "# We want to map the evaluation report that we generate inside\n",
    "# the evaluation script so we can later reference it.\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "\n",
    "# Notice how this step uses the model generated by the tuning or training\n",
    "# step, and the test set generated by the preprocessing step.\n",
    "evaluation_step = ProcessingStep(\n",
    "    name=\"evaluation\",\n",
    "    processor=tensorflow_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", destination=evaluation_destination),\n",
    "    ],\n",
    "    code=f\"{PENGUINS_FOLDER}/evaluation.py\",\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272be0f1-2bdf-42fe-8b92-2ce512bf863d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create Model Step\n",
    "\n",
    "To create the model quality baseline, we must generate predictions for the train set and compare them with the ground truth labels.\n",
    "\n",
    "We can do this by running a Batch Transform Job to predict every sample from the training dataset. We can use a [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform) as part of the pipeline to run this job. You can check [Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) for more information about Batch Transform Jobs.\n",
    "\n",
    "The Transform Step requires a model. In previous sessions, we only registered the model in the Model Registry as part of the pipeline, but now we also need to create the model. That way, the Batch Transform Job can use it to generate predictions.\n",
    "\n",
    "Let's configure a [TensorFlowModel](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-model) and a Model Step to create the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d5a0a57-c4f8-484e-937c-3b5f3ad7d1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.tensorflow.model:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "model = TensorFlowModel(\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=str(CODE_FOLDER),\n",
    "    env={\n",
    "        \"PIPELINE_S3_LOCATION\": preprocessor_destination,\n",
    "    },\n",
    "    framework_version=\"2.6\",\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "create_model_step = ModelStep(\n",
    "    name=\"create-model\",\n",
    "    step_args=model.create(instance_type=\"ml.m5.large\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80288507-6e37-4301-8d24-0e9a22a4ca3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transform Step\n",
    "\n",
    "Let's configure the [Batch Transform Job](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) using a [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform). This Batch Transform Job will run every sample from the training dataset through the model so we can compute the baseline metrics.\n",
    "\n",
    "We can use an instance of the [Transformer](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html) class to configure the job.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "322858a6-029e-4c20-a243-0cfc9e38c2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    # We can specify the name of the model the Batch Transform Job will \n",
    "    # use by using the property from the Model Step that created the model.\n",
    "    model_name=create_model_step.properties.ModelName,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    instance_count=1,\n",
    "    \n",
    "    # The baseline set that we generated in the preprocessing step\n",
    "    # is in JSON format, where every line is a JSON sample.\n",
    "    accept=\"application/json\",\n",
    "    strategy=\"SingleRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    \n",
    "    output_path=f\"{S3_FILEPATH}/transform\",\n",
    ")\n",
    "\n",
    "transform_step = TransformStep(\n",
    "    name=\"transform\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(\n",
    "        \n",
    "        # We will use the test dataset we generated during the preprocessing \n",
    "        # step to run it through the model and generate predictions.\n",
    "        data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\"test-baseline\"].S3Output.S3Uri,\n",
    "\n",
    "        join_source=\"Input\",\n",
    "        content_type=\"application/json\",\n",
    "        split_type=\"Line\",\n",
    "    ),\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c61f3-dd75-4129-8617-ce64c2f967e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Quality Check Step\n",
    "\n",
    "Data quality monitoring allows us to monitor the quality of the data coming into our endpoint and detect whether it \n",
    "drifts away from the nature of the baseline data we used to train our model.\n",
    "\n",
    "The first step is to create a baseline job using a [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) to analyze the train set. The baseline computes schema constraints and statistics for each feature in our data. Check the [QualityCheckStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.quality_check_step.QualityCheckStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "Let's set up the configuration to monitor the quality of our data using Pipeline parameters. For more information about how to coordinate these parameters in different situations, check [ Baseline calculation, drift detection, and lifecycle with ClarifyCheck and QualityCheck steps in Amazon SageMaker Model Building Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.html):\n",
    "\n",
    "* `data_quality_skip_check`: Whether we should skip checking data drift during this pipeline execution. Set this to `True` if you are starting the pipeline for the first time to build your first model version or want to generate the initial baselines.\n",
    "* `data_quality_register_new_baseline`: Whether you want to compute and register a new baseline.\n",
    "* `data_quality_supplied_baseline_statistics`: You can use this property to specify the location of existing baseline statistics.\n",
    "* `data_quality_supplied_baseline_constraints`: You can use this property to specify the location of existing baseline constraints.\n",
    "\n",
    "Let's now configure the [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) and feed it the train set we generated in the preprocessing step.\n",
    "\n",
    "We can configure the instance that will run the quality check using the [CheckJobConfig](https://sagemaker.readthedocs.io/en/v2.73.0/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.check_job_config.CheckJobConfig) class, and we can use the `DataQualityCheckConfig` class to configure the job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70784cb6-02c6-45d5-8e44-e32f8864f2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_quality_skip_check = ParameterBoolean(\n",
    "    name=\"data_quality_skip_check\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "data_quality_register_new_baseline = ParameterBoolean(\n",
    "    name=\"data_quality_register_new_baseline\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "data_quality_supplied_baseline_statistics = ParameterString(\n",
    "    name=\"data_quality_supplied_baseline_statistics\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "data_quality_supplied_baseline_constraints = ParameterString(\n",
    "    name=\"data_quality_supplied_baseline_constraints\", \n",
    "    default_value=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "077fdec7-b11e-4ada-a379-6ba850a774f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "check_job_config = CheckJobConfig(\n",
    "    instance_type=\"ml.t3.xlarge\",\n",
    "    instance_count=1,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    volume_size_in_gb=20,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "data_quality_check_config = DataQualityCheckConfig(\n",
    "    # We will use the train dataset we generated during the preprocessing \n",
    "    # step to generate the data quality baseline.\n",
    "    baseline_dataset=preprocess_step.properties.ProcessingOutputConfig.Outputs[\"train-baseline\"].S3Output.S3Uri,\n",
    "    \n",
    "    dataset_format=DatasetFormat.json(lines=True),\n",
    "    output_s3_uri=Join(on='/', values=[S3_FILEPATH, \"monitoring\", \"data-quality\"]),\n",
    ")\n",
    "\n",
    "data_quality_check_step = QualityCheckStep(\n",
    "    name=\"data-quality-check\",\n",
    "    check_job_config=check_job_config,\n",
    "    quality_check_config=data_quality_check_config,\n",
    "    skip_check=data_quality_skip_check,\n",
    "    register_new_baseline=data_quality_register_new_baseline,\n",
    "    supplied_baseline_statistics=data_quality_supplied_baseline_statistics,\n",
    "    supplied_baseline_constraints=data_quality_supplied_baseline_constraints,\n",
    "    model_package_group_name=MODEL_PACKAGE_GROUP_NAME,\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0e240-82a3-4ad4-8069-24f12a4319fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model Quality Check Step\n",
    "\n",
    "Model quality monitoring allows us to monitor the model's performance by comparing its predictions with the actual ground truth labels. \n",
    "\n",
    "The first step is to create a baseline job using a [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) to compare predictions from the model with the ground truth labels in the baseline dataset. The baseline job automatically creates baseline statistical rules and constraints that define thresholds against which we can evaluate the model performance. Check the [QualityCheckStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.quality_check_step.QualityCheckStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "Let's set up the configuration to monitor the quality of our model using Pipeline parameters. For more information about how to coordinate these parameters in different situations, check [Baseline calculation, drift detection, and lifecycle with ClarifyCheck and QualityCheck steps in Amazon SageMaker Model Building Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.html):\n",
    "\n",
    "* `model_quality_skip_check`: Whether we should skip checking model drift during this pipeline execution. Set this to `True` if you are starting the pipeline for the first time to build your first model version or want to generate the initial baselines.\n",
    "* `model_quality_register_new_baseline`: Whether you want to compute and register a new baseline.\n",
    "* `model_quality_supplied_baseline_statistics`: You can use this property to specify the location of existing baseline statistics.\n",
    "* `model_quality_supplied_baseline_constraints`: You can use this property to specify the location of existing baseline constraints.\n",
    "\n",
    "\n",
    "Let's now configure the [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) and feed it the data we generated in the Transform Step.\n",
    "\n",
    "We will use the same [CheckJobConfig](https://sagemaker.readthedocs.io/en/v2.73.0/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.check_job_config.CheckJobConfig) we configured for the Data Quality Check Step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c60c329c-eefe-4e3f-8333-ce70c1ca5f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_quality_skip_check = ParameterBoolean(\n",
    "    name=\"model_quality_skip_check\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "model_quality_register_new_baseline = ParameterBoolean(\n",
    "    name=\"model_quality_register_new_baseline\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "model_quality_supplied_baseline_statistics = ParameterString(\n",
    "    name=\"model_quality_supplied_baseline_statistics\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "model_quality_supplied_baseline_constraints = ParameterString(\n",
    "    name=\"model_quality_supplied_baseline_constraints\", \n",
    "    default_value=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f456eb92-1160-4fa8-8ae8-b4b432ac20b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "model_quality_check_config = ModelQualityCheckConfig(\n",
    "    # We are going to use the output of the Transform Step to generate\n",
    "    # the model quality baseline.\n",
    "    baseline_dataset=transform_step.properties.TransformOutput.S3OutputPath,\n",
    "    \n",
    "    dataset_format=DatasetFormat.json(lines=True),\n",
    "    output_s3_uri=Join(on='/', values=[S3_FILEPATH, \"monitoring\", \"model-quality\"]),\n",
    "    \n",
    "    # We need to specify the problem type and the fields where the prediction\n",
    "    # and groundtruth are so the process knows how to interpret the results.\n",
    "    problem_type=\"MulticlassClassification\",\n",
    "    inference_attribute=\"$.SageMakerOutput.prediction\",\n",
    "    ground_truth_attribute=\"groundtruth\",\n",
    ")\n",
    "\n",
    "model_quality_check_step = QualityCheckStep(\n",
    "    name=\"model-quality-check\",\n",
    "    check_job_config=check_job_config,\n",
    "    quality_check_config=model_quality_check_config,\n",
    "    skip_check=model_quality_skip_check,\n",
    "    register_new_baseline=model_quality_register_new_baseline,\n",
    "    supplied_baseline_statistics=model_quality_supplied_baseline_statistics,\n",
    "    supplied_baseline_constraints=model_quality_supplied_baseline_constraints,\n",
    "    model_package_group_name=MODEL_PACKAGE_GROUP_NAME,\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693535ba-fca7-4e89-a4cb-b4f333fa2d03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Register Model Step\n",
    "\n",
    "In Session 4, we configured a set of [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) using the evaluation report we generated during the Evaluation Step. After running the Data and Model Quality Steps, we will have access to a much more comprehensive set of metrics that we can use when registering the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a773f134-ac2f-4dba-976e-9b7f0b384b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    \n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "drift_check_baselines = DriftCheckBaselines(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=model.register(\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=\"2.6\",\n",
    "        model_package_group_name=MODEL_PACKAGE_GROUP_NAME,\n",
    "        model_metrics=model_metrics,\n",
    "        drift_check_baselines=drift_check_baselines,\n",
    "        approval_status=model_approval_status,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b60d5-6be3-428f-9979-4fe9eebfc5eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Deploy Step\n",
    "\n",
    "In Session 4, we registered the model as part of the pipeline but deployed it manually. Instead, we can use a [Lambda Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-lambda) to deploy the model automatically.\n",
    "\n",
    "Let's start by writing the Lambda function to take the model information and create a new hosting endpoint.\n",
    "\n",
    "Let's define the [LambdaStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.lambda_step.LambdaStep) that will run the function to deploy the model. In this example, this step will create a new Lambda function every time it runs, so we must remove any old function after the pipeline finishes.\n",
    "\n",
    "We can use [Data Capture](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-capture.html) to record the inputs and outputs of the endpoint to use them later for monitoring the model. Amazon SageMaker Model Monitor automatically parses this captured data and compares metrics from this data with a baseline that you create for the model. \n",
    "\n",
    "We'll enable Data Capture and use the following settings:\n",
    "\n",
    "* `data_capture_enabled`: Whether we want to enable Data Capture.\n",
    "* `data_capture_percentage`: Represents the percentage of information that flows through the endpoint that we want to capture. For this example, we'll set that to 100%.\n",
    "* `data_capture_destination`: Specifies the S3 location where we want to store the captured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28c75afd-d0d0-47f4-b7b6-9d590c5b600e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PENGUINS_FOLDER/lambda.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    model_name = event[\"model_name\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    endpoint_config_name = event[\"endpoint_config_name\"]\n",
    "    data_capture_enabled = event[\"data_capture_enabled\"]\n",
    "    data_capture_percentage = event[\"data_capture_percentage\"]\n",
    "    data_capture_destination = event[\"data_capture_destination\"]\n",
    "    role = event[\"role\"]\n",
    "    \n",
    "    \n",
    "    # The first step is to create a new model. We will use the\n",
    "    # ARN of the model we registered.\n",
    "    sagemaker.create_model(\n",
    "        ModelName=model_name, \n",
    "        ExecutionRoleArn=role, \n",
    "        Containers=[{\n",
    "            \"ModelPackageName\": event[\"model_package_arn\"]\n",
    "        }] \n",
    "    )\n",
    "\n",
    "    # Then, we need to create an Endpoint Configuration.\n",
    "    # Here is where we specify the hardware we need for the\n",
    "    # endpoint and the Data Capture configuration. \n",
    "    sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"ModelName\": model_name,\n",
    "                \"InstanceType\": \"ml.m5.large\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "        DataCaptureConfig={\n",
    "            \"EnableCapture\": data_capture_enabled,\n",
    "            \"InitialSamplingPercentage\": data_capture_percentage,\n",
    "            \"DestinationS3Uri\": data_capture_destination,\n",
    "            \"CaptureOptions\": [\n",
    "                {\n",
    "                    'CaptureMode': \"Input\"\n",
    "                },\n",
    "                {\n",
    "                    'CaptureMode': \"Output\"\n",
    "                },\n",
    "            ],\n",
    "            \"CaptureContentTypeHeader\": {\n",
    "                \"JsonContentTypes\": [\n",
    "                    \"application/json\",\n",
    "                    \"application/octect-stream\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Finally, we can create the new Endpoint using the\n",
    "    # Endpoint Configuration we created above.\n",
    "    sagemaker.create_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Endpoint deployed successfully\"),\n",
    "        \"model_name\": model_name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a4446-6db4-4515-bb1d-88ee21013bb2",
   "metadata": {},
   "source": [
    "We need to ensure our Lambda function has permission to interact with SageMaker, so let's create a new role to run the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9941979-c085-4ef9-8c66-908378d89a91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lambda_role(role_name):\n",
    "    try:\n",
    "        response = iam_client.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps({\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": \"lambda.amazonaws.com\"\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\"\n",
    "                    }\n",
    "                ]\n",
    "            }),\n",
    "            Description=\"Lambda Pipeline Role\"\n",
    "        )\n",
    "\n",
    "        role_arn = response['Role']['Arn']\n",
    "\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "        )\n",
    "\n",
    "        iam_client.attach_role_policy(\n",
    "            PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "            RoleName=role_name\n",
    "        )\n",
    "\n",
    "        return role_arn\n",
    "\n",
    "    except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "        response = iam_client.get_role(RoleName=role_name)\n",
    "        return response['Role']['Arn']\n",
    "    \n",
    "\n",
    "lambda_role = create_lambda_role(\"lambda-pipeline-role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c6eda89-70f3-49b4-8983-90f4db72fd02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_capture_enabled = ParameterBoolean(\n",
    "    name=\"data_capture_enabled\",\n",
    "    default_value=True,\n",
    ")\n",
    "\n",
    "data_capture_percentage = ParameterInteger(\n",
    "    name=\"data_capture_percentage\",\n",
    "    default_value=100,\n",
    ")\n",
    "\n",
    "data_capture_destination = ParameterString(\n",
    "    name=\"data_capture_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/monitoring/data-capture\",\n",
    ")\n",
    "\n",
    "\n",
    "function_name = f\"deploy-endpoint-fn-{time.strftime('%m%d%H%M%S', time.localtime())}\"\n",
    "endpoint_name = \"penguins-endpoint\"\n",
    "\n",
    "deploy_step = LambdaStep(\n",
    "    name=\"deploy\",\n",
    "    lambda_func=Lambda(\n",
    "        function_name=function_name,\n",
    "        execution_role_arn=lambda_role,\n",
    "        script=str(PENGUINS_FOLDER / \"lambda.py\"),\n",
    "        handler=\"lambda.lambda_handler\",\n",
    "        timeout=600,\n",
    "        memory_size=10240,\n",
    "    ),\n",
    "    inputs={\n",
    "        # We can use the timestamp_signature pipeline parameter\n",
    "        # to add a suffix to the model and the endpoint configuration\n",
    "        # and avoid name collisions.\n",
    "        \"model_name\": Join(on=\"-\", values=[\"penguins-model\", timestamp_signature]),\n",
    "        \"endpoint_config_name\": Join(on=\"-\", values=[\"penguins-endpoint-config\", timestamp_signature]),\n",
    "\n",
    "        # We use the ARN of the model we registered to\n",
    "        # deploy it to the endpoint.\n",
    "        \"model_package_arn\": register_model_step.properties.ModelPackageArn,\n",
    "\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"data_capture_enabled\": data_capture_enabled,\n",
    "        \"data_capture_percentage\": data_capture_percentage,\n",
    "        \"data_capture_destination\": data_capture_destination,\n",
    "        \"role\": role,\n",
    "    },\n",
    "    outputs=[\n",
    "        LambdaOutput(output_name=\"model_name\", output_type=LambdaOutputTypeEnum.String)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00b5e6-9858-4acc-bbfe-a2ce24ec20e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Condition Step\n",
    "\n",
    "We only want to compute the model quality baseline if the model's performance is above the predefined threshold. The [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) will gate all necessary steps to compute the baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bacaa9c6-22b0-48df-b138-95b6422fe834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\"\n",
    "    ),\n",
    "    right=accuracy_threshold\n",
    ")\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name=\"fail\",\n",
    "    error_message=Join(\n",
    "        on=\" \", \n",
    "        values=[\n",
    "            \"Execution failed because the model's accuracy was lower than\", \n",
    "            accuracy_threshold\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[\n",
    "        create_model_step, \n",
    "        transform_step, \n",
    "        model_quality_check_step, \n",
    "        register_model_step,\n",
    "        deploy_step\n",
    "    ],\n",
    "    else_steps=[fail_step], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a7905-2550-4979-b885-f2daabb5d45e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running the Pipeline\n",
    "\n",
    "We can now run the pipeline. If the pipeline succeeds, there will be a new running endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4da5e453-acd8-47a0-a39f-264d05dd93d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination,\n",
    "        timestamp_signature,\n",
    "        data_capture_enabled,\n",
    "        data_capture_percentage,\n",
    "        data_capture_destination,\n",
    "        data_quality_skip_check,\n",
    "        data_quality_register_new_baseline,\n",
    "        data_quality_supplied_baseline_statistics,\n",
    "        data_quality_supplied_baseline_constraints,\n",
    "        model_quality_skip_check,\n",
    "        model_quality_register_new_baseline,\n",
    "        model_quality_supplied_baseline_statistics,\n",
    "        model_quality_supplied_baseline_constraints,\n",
    "        evaluation_destination,\n",
    "        model_approval_status,\n",
    "        accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        data_quality_check_step,\n",
    "        training_step, \n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24713751-b109-47be-8d6f-5f4c7511f6d4",
   "metadata": {},
   "source": [
    "Submit the pipeline definition to the SageMaker Pipelines service to create a pipeline if it doesn't exist or update it if it does.\n",
    "\n",
    "We are going to overwrite the value of `timestamp_signature` to specify a unique time-based suffix that we'll use to generate the name of different resources we create during the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b54dbf6e-9b52-41a6-bec3-91c56536b3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start(parameters=dict(\n",
    "    timestamp_signature=time.strftime(\"%m%d%H%M%S\", time.localtime())\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef99386-e0f3-411d-8715-8538d6d7bba9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Endpoint\n",
    "\n",
    "We can now create a [Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html) from the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfd679a8-7f4b-47ee-9bdc-ca9942aa59a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waiter = sagemaker_client.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(\n",
    "    EndpointName=endpoint_name,\n",
    "    WaiterConfig={\n",
    "        \"Delay\": 10,\n",
    "        \"MaxAttempts\": 30\n",
    "    }\n",
    ")\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8148ef38-92ed-4f9a-8024-69e2d9d6b5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': '0', 'confidence': 0.662686348}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict({\n",
    "    \"island\": \"Dream\",\n",
    "    \"culmen_length_mm\": 46.4,\n",
    "    \"culmen_depth_mm\": 18.6,\n",
    "    \"flipper_length_mm\": 190.0,\n",
    "    \"body_mass_g\": 3450.0,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f236ab-484d-49cf-a9bf-4130ca431b6c",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b479872-58e2-4c61-8ccf-68d35185b282",
   "metadata": {},
   "source": [
    "### Generating Predictions and Ground Truth Data\n",
    "\n",
    "Let's generate predictions and ground truth data to test the monitoring functionality.\n",
    "\n",
    "We will repeatedly send every sample from the dataset to the endpoint and generate random ground truth data for the sake of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "284603a1-d488-4af7-b06e-a7e774dc1fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This event will let us stop the infinite threads\n",
    "# that generate prediction and ground truth data.\n",
    "stop_thread = Event()\n",
    "\n",
    "ground_truth_path = f\"{S3_FILEPATH}/monitoring/groundtruth\"\n",
    "\n",
    "# Let's use the original dataset to generate predictions and ground\n",
    "# truth data. \n",
    "data = pd.read_csv(LOCAL_FILEPATH).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beba47c-75bf-49fd-80e9-146c3ff815f1",
   "metadata": {},
   "source": [
    "Let's generate prediction data using the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e373a722-f5de-4e3a-ac5f-afe27c3f844b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(predictor):\n",
    "    for index in data.index:\n",
    "        payload = {\n",
    "            \"island\": data[\"island\"][index],\n",
    "            \"culmen_length_mm\": data[\"culmen_length_mm\"][index],\n",
    "            \"culmen_depth_mm\": data[\"culmen_depth_mm\"][index],\n",
    "            \"flipper_length_mm\": data[\"flipper_length_mm\"][index],\n",
    "            \"body_mass_g\": data[\"body_mass_g\"][index],\n",
    "        }\n",
    "\n",
    "        predictor.predict(payload, inference_id=str(index))\n",
    "        sleep(1)\n",
    "        \n",
    "        if stop_thread.is_set():\n",
    "            break\n",
    "    \n",
    "def generate_prediction_data(predictor):\n",
    "    while True:\n",
    "        predict(predictor)\n",
    "        if stop_thread.is_set():\n",
    "            break\n",
    "            \n",
    "\n",
    "prediction_thread = Thread(\n",
    "    target=generate_prediction_data,\n",
    "    args=(predictor,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f586a-eb71-4d90-b2cd-c59c2fbac70c",
   "metadata": {},
   "source": [
    "Let's generate ground truth data and store it in S3. Notice the S3 path to save the ground truth data has the same path format as the data captured by the endpoint. Check [Ingest Ground Truth Labels and Merge Them With Predictions](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html) for more information about this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a34a5140-5ace-4b87-9b27-9e6d17e46456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_ground_truth_record(inference_id):\n",
    "    random.seed(inference_id)\n",
    "    \n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            \"data\": str(random.choice([0, 1, 2])),\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(records, upload_time):\n",
    "    records = [json.dumps(r) for r in records]\n",
    "    data = \"\\n\".join(records)\n",
    "    uri = f\"{ground_truth_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    \n",
    "    print(f\"Uploading ground truth data to {uri}...\")\n",
    "    \n",
    "    S3Uploader.upload_string_as_file_body(data, uri)\n",
    "\n",
    "    \n",
    "def generate_ground_truth_data(max_records):\n",
    "    while True:\n",
    "        records = [generate_ground_truth_record(i) for i in range(max_records)]\n",
    "        upload_ground_truth(records, datetime.utcnow())\n",
    "        \n",
    "        if stop_thread.is_set():\n",
    "            break\n",
    "            \n",
    "        sleep(30)\n",
    "    \n",
    "groundtruth_thread = Thread(\n",
    "    target=generate_ground_truth_data,\n",
    "    args=(len(data),)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f37ae-7656-4b8d-8c7d-60f9fa5c737d",
   "metadata": {},
   "source": [
    "Let's start both threads now. These threads will run forever until you restart the kernel or set the `stop_thread` event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b40a0087-93d7-4b6e-9be5-d7a2c622b77c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/1644.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/1714.jsonl...\n"
     ]
    }
   ],
   "source": [
    "prediction_thread.start()\n",
    "groundtruth_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a24f8-9fac-47ef-b707-4919d2c14ecd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Checking the Captured Data\n",
    "\n",
    "Let's check the S3 location where the endpoint stores the requests and responses that it receives. We defined this location using the `data_capture_destination` pipeline parameter.\n",
    "\n",
    "Notice that it make take a few minutes for the first few files to show up in S3. Keep running the following line until you get some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3ba479ee-aefc-4480-9ebf-cd3e679edbe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://mlschool/penguins/monitoring/data-capture/penguins-endpoint/AllTraffic/2023/04/28/19/16-06-992-abf52eaa-40cd-4fb9-916a-96bfe20252c0.jsonl']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/1815.jsonl...\n"
     ]
    }
   ],
   "source": [
    "files = S3Downloader.list(data_capture_destination.default_value)\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52455abe-3eea-46e5-a4b3-95a83ba5f926",
   "metadata": {},
   "source": [
    "These files contain the data captured by the endpoint in a SageMaker-specific JSON-line format. Each inference request is captured in a single line in the `jsonl` file. The line contains both the input and output merged together.\n",
    "\n",
    "Let's read the first line from the first file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ea31c263-f941-4177-bdc7-842e4b6172b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"application/json\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"{\\\"island\\\": \\\"Dream\\\", \\\"culmen_length_mm\\\": 46.4, \\\"culmen_depth_mm\\\": 18.6, \\\"flipper_length_mm\\\": 190.0, \\\"body_mass_g\\\": 3450.0}\",\n",
      "      \"encoding\": \"JSON\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"application/json\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"{\\\"prediction\\\": \\\"0\\\", \\\"confidence\\\": 0.497521222}\",\n",
      "      \"encoding\": \"JSON\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"33532b83-7f7c-4335-9c8a-a8023c3799c6\",\n",
      "    \"inferenceTime\": \"2023-04-28T19:16:06Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if len(files):\n",
    "    lines = S3Downloader.read_file(files[0])\n",
    "    print(json.dumps(json.loads(lines.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a58ae-d3aa-4f69-bd52-66b05458bee7",
   "metadata": {},
   "source": [
    "### Monitoring Data Quality\n",
    "\n",
    "We can now set up a schedule to continuously monitor data coming into the endpoint and compare it to the baseline we generated before. This monitoring job will use the baseline statistics and constraints we generated during the Data Quality Check Step. Check [Schedule Data Quality Monitoring Jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-schedule-data-monitor.html) for more information.\n",
    "\n",
    "SageMaker looks for violations in the data captured by the endpoint. By default, they combine the input data with the endpoint output and compare the result with the previous baseline we generated. If we let SageMaker do this, we will get three violations:\n",
    "\n",
    "1. An \"extra column check\" violation because the field `confidence` doesn't exist in the baseline.\n",
    "2. An \"extra column check\" violation because the field `prediction` doesn't exist in the baseline.\n",
    "3. A \"missing column check\" violation because the field `groundtruth` doesn't appear in the data captured from the endpoint.\n",
    "\n",
    "We can fix these violations by creating a preprocessing script configuring the data we want the monitoring job to use. This script will create a `groundtruth` column, and exclude `confidence` and `prediction`. By doing this, we will not receive any of these three violations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "345efa6b-40bd-4084-83fd-654847bf22c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_QUALITY_PREPROCESSOR = \"data_quality_preprocessor.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c83ca-9b2c-40cc-81f9-bf85c0f17b5e",
   "metadata": {},
   "source": [
    "Here is the preprocessing script for the Data Quality Monitoring Job. Check [Preprocessing and Postprocessing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html) for more information about how to configure these scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2efcc106-b86d-4998-8fae-095c52a2b56b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/data_quality_preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PENGUINS_FOLDER}/{DATA_QUALITY_PREPROCESSOR}\n",
    "\n",
    "def preprocess_handler(inference_record):\n",
    "    input_data = inference_record.endpoint_input.data\n",
    "    output_data = json.loads(inference_record.endpoint_output.data)\n",
    "    \n",
    "    response = json.loads(input_data)\n",
    "    response[\"groundtruth\"] = output_data[\"prediction\"]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa310b-2443-4a61-a09a-ea59df21f5c6",
   "metadata": {},
   "source": [
    "The monitoring schedule expects an S3 location pointing to the preprocessing script. Let's upload the script to the default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f501b907-6844-412e-bb79-e04fce790e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-325223348818/penguins-monitoring/data_quality_preprocessor.py'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/3921.jsonl...\n"
     ]
    }
   ],
   "source": [
    "bucket = boto3.Session().resource(\"s3\").Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"penguins-monitoring\"\n",
    "bucket.Object(os.path.join(prefix, DATA_QUALITY_PREPROCESSOR)).upload_file(str(PENGUINS_FOLDER / DATA_QUALITY_PREPROCESSOR))\n",
    "data_quality_preprocessor = f\"s3://{os.path.join(bucket.name, prefix, DATA_QUALITY_PREPROCESSOR)}\"\n",
    "data_quality_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59c8199-5c13-4284-9ca9-1b695e3ff122",
   "metadata": {},
   "source": [
    "We can now set up the Data Quality Monitoring Job using the [DefaultModelMonitor](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.DefaultModelMonitor) class. Notice how we specify the `record_preprocessor_script` using the S3 location where we uploaded our script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5ded982d-d858-4ca6-b754-196917251a60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: penguins-data-monitoring-schedule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/3951.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4021.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4051.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4121.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4151.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4222.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4252.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4322.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4352.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4423.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4453.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4523.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4553.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4623.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4654.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4724.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4754.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4824.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4855.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4925.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/4955.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5025.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5056.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5126.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5156.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5226.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5256.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5326.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5357.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5427.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5457.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5527.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5557.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5628.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5658.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5728.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5758.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5828.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5858.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/20/5929.jsonl...\n"
     ]
    }
   ],
   "source": [
    "data_monitor = DefaultModelMonitor(\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "data_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=\"penguins-data-monitoring-schedule\",\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    record_preprocessor_script=data_quality_preprocessor,\n",
    "    statistics=f\"{S3_FILEPATH}/monitoring/data-quality/statistics.json\",\n",
    "    constraints=f\"{S3_FILEPATH}/monitoring/data-quality/constraints.json\",\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3705ec7-e7fb-4eca-8290-53df06361e77",
   "metadata": {},
   "source": [
    "You can describe the schedule to see more information about the Data Quality Monitoring Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2e6ce5ec-a4c4-4f79-a78b-d27f678f6db9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:325223348818:monitoring-schedule/penguins-data-monitoring-schedule',\n",
       " 'MonitoringScheduleName': 'penguins-data-monitoring-schedule',\n",
       " 'MonitoringScheduleStatus': 'Scheduled',\n",
       " 'MonitoringType': 'DataQuality',\n",
       " 'CreationTime': datetime.datetime(2023, 4, 28, 19, 18, 30, 771000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 4, 28, 19, 18, 38, 360000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinitionName': 'data-quality-job-definition-2023-04-28-19-18-29-791',\n",
       "  'MonitoringType': 'DataQuality'},\n",
       " 'EndpointName': 'penguins-endpoint',\n",
       " 'LastMonitoringExecutionSummary': {'MonitoringScheduleName': 'penguins-data-monitoring-schedule',\n",
       "  'ScheduledTime': datetime.datetime(2023, 4, 27, 19, 0, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2023, 4, 27, 19, 6, 13, 320000, tzinfo=tzlocal()),\n",
       "  'LastModifiedTime': datetime.datetime(2023, 4, 27, 19, 14, 19, 162000, tzinfo=tzlocal()),\n",
       "  'MonitoringExecutionStatus': 'CompletedWithViolations',\n",
       "  'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:325223348818:processing-job/model-monitoring-202304271900-e2878b2fc8bfe9393f44fe0d',\n",
       "  'EndpointName': 'penguins-endpoint'},\n",
       " 'ResponseMetadata': {'RequestId': 'f53ad141-95b2-462e-ac9e-5c31fe6d3417',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f53ad141-95b2-462e-ac9e-5c31fe6d3417',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '970',\n",
       "   'date': 'Fri, 28 Apr 2023 19:28:38 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/2850.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/2920.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/2950.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3021.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3051.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3121.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3151.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3221.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3251.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3322.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3352.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3422.jsonl...\n",
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/19/3452.jsonl...\n"
     ]
    }
   ],
   "source": [
    "data_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ecc695-535a-4556-89e6-082670746afa",
   "metadata": {},
   "source": [
    "### Monitoring Model Quality\n",
    "\n",
    "Let's set up a schedule to continuously monitor the quality of the model and compare it to the baseline we generated before. This monitoring job will use the baseline constraints we generated during the Model Quality Check Step. Check [Schedule Model Quality Monitoring Jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-schedule.html) for more information.\n",
    "\n",
    "To set up a Model Quality Monitoring Job, we can use the [ModelQualityMonitor](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelQualityMonitor) class. The [EndpointInput](https://sagemaker.readthedocs.io/en/v2.24.2/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.EndpointInput) instance configures the attribute the monitoring job should use to determine the prediction from the model.\n",
    "\n",
    "Check [Amazon SageMaker Model Quality Monitor](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/model_quality/model_quality_churn_sdk.html) for a complete tutorial on how to run a Model Monitoring Job in SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6b1bfce1-e812-4c6e-bade-8419d6c7ae5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: penguins-model-monitoring-schedule\n"
     ]
    }
   ],
   "source": [
    "model_monitor = ModelQualityMonitor(\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "endpoint_input = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    \n",
    "    # The endpoint returns an attribute `prediction` with the\n",
    "    # prediction from the model. That's the attribute we want to\n",
    "    # use to compare with the ground truth.\n",
    "    inference_attribute=\"prediction\",\n",
    "    \n",
    "    destination=\"/opt/ml/processing/input_data\",\n",
    ")\n",
    "\n",
    "model_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=\"penguins-model-monitoring-schedule\",\n",
    "    endpoint_input=endpoint_input,\n",
    "    problem_type=\"MulticlassClassification\",\n",
    "    ground_truth_input=ground_truth_path,\n",
    "    output_s3_uri=f\"{S3_FILEPATH}/monitoring/model-quality\",\n",
    "    constraints=f\"{S3_FILEPATH}/monitoring/model-quality/constraints.json\",\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b3e732-039b-471d-bfa9-8dd8b39950dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can describe the schedule to see more information about the Model Quality Monitoring Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "126bfac0-09a2-44a8-a6e3-b43abe9d9983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:us-east-1:325223348818:monitoring-schedule/penguins-model-monitoring-schedule',\n",
       " 'MonitoringScheduleName': 'penguins-model-monitoring-schedule',\n",
       " 'MonitoringScheduleStatus': 'Pending',\n",
       " 'MonitoringType': 'ModelQuality',\n",
       " 'CreationTime': datetime.datetime(2023, 4, 28, 19, 19, 8, 998000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 4, 28, 19, 19, 9, 91000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinitionName': 'model-quality-job-definition-2023-04-28-19-19-08-331',\n",
       "  'MonitoringType': 'ModelQuality'},\n",
       " 'EndpointName': 'penguins-endpoint',\n",
       " 'LastMonitoringExecutionSummary': {'MonitoringScheduleName': 'penguins-model-monitoring-schedule',\n",
       "  'ScheduledTime': datetime.datetime(2023, 4, 28, 15, 0, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2023, 4, 28, 15, 7, 28, 127000, tzinfo=tzlocal()),\n",
       "  'LastModifiedTime': datetime.datetime(2023, 4, 28, 15, 29, 42, 278000, tzinfo=tzlocal()),\n",
       "  'MonitoringExecutionStatus': 'CompletedWithViolations',\n",
       "  'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:325223348818:processing-job/model-quality-monitoring-202304281500-d87a0cf34bcebe21503ff107',\n",
       "  'EndpointName': 'penguins-endpoint'},\n",
       " 'ResponseMetadata': {'RequestId': 'c1270602-e538-467c-935d-c7aa708e7667',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c1270602-e538-467c-935d-c7aa708e7667',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '984',\n",
       "   'date': 'Fri, 28 Apr 2023 19:19:08 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dded2c0-2ef4-4a46-bc79-8366998aa8c4",
   "metadata": {},
   "source": [
    "### Stopping Monitoring Jobs\n",
    "\n",
    "Let's stop the monitoring jobs by deleting the monitoring schedules we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "eba13a80-e1aa-4a21-9fe2-46c288ce447b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: penguins-data-monitoring-schedule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Deleting Data Quality Job Definition with name: data-quality-job-definition-2023-04-28-20-39-24-206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: penguins-model-monitoring-schedule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Deleting Model Quality Job Definition with name: model-quality-job-definition-2023-04-28-19-19-08-331\n"
     ]
    }
   ],
   "source": [
    "data_monitor.delete_monitoring_schedule()\n",
    "model_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f0425-f0a4-4530-851b-7f665c55106b",
   "metadata": {},
   "source": [
    "We also need to stop the threads generating predictions and ground truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f265d3ab-384e-4e49-ab94-e7f87dea8f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ground truth data to s3://mlschool/penguins/monitoring/groundtruth/2023/04/28/21/3044.jsonl...\n"
     ]
    }
   ],
   "source": [
    "stop_thread.set()\n",
    "\n",
    "prediction_thread.join()\n",
    "groundtruth_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad4f27-8ddb-44c8-b472-08fc69eab34e",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "Before you finish, don't forget to clean up after yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12ec02ec-6de1-4973-b9a0-525c81a5a56e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: penguins-model-0502190721\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: penguins-endpoint-config-0502190721\n",
      "INFO:sagemaker:Deleting endpoint with name: penguins-endpoint\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cda93bb-29f8-47ad-a25f-f7b21df90325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session1_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-11c317c5ecdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdelete_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession1_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdelete_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession2_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdelete_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession3_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'session1_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8704c94-7a42-45f9-b006-74832f07cbc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's delete every model we registered under our model package group\n",
    "for mp in sagemaker_client.list_model_packages(ModelPackageGroupName=model_package_group_name)[\"ModelPackageSummaryList\"]:\n",
    "    print(f\"Deleting {mp['ModelPackageArn']}\")\n",
    "    sagemaker_client.delete_model_package(ModelPackageName=mp[\"ModelPackageArn\"])\n",
    "\n",
    "# We can now delete the model package group.    \n",
    "sagemaker_client.delete_model_package_group(ModelPackageGroupName=model_package_group_name)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
