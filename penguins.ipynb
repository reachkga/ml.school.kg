{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b7ba7b-433c-463c-8e5e-8b975a5be463",
   "metadata": {},
   "source": [
    "# Machine Learning In Production\n",
    "\n",
    "<img src='https://imgur.com/orZWHly.png' alt='Penguins dataset' width=\"900\">\n",
    "\n",
    "This notebook was created by [Santiago L. Valdarrama](https://twitter.com/svpino) as part of the [Machine Learning School](https://www.ml.school) program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b80dfa35-b345-4f38-8426-f0223de0c401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72eb4984-3c21-4033-be45-2de2cfc1257c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.22.22 requires botocore==1.23.22, but you have botocore 1.29.114 which is incompatible.\n",
      "awscli 1.22.22 requires s3transfer<0.6.0,>=0.5.0, but you have s3transfer 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mName: sagemaker\n",
      "Version: 2.146.0\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: attrs, boto3, google-pasta, importlib-metadata, jsonschema, numpy, packaging, pandas, pathos, platformdirs, protobuf, protobuf3-to-dict, PyYAML, schema, smdebug-rulesconfig\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# Let's make sure we are running the latest version of the SakeMaker's SDK. \n",
    "# Restart the notebook after you upgrade the library.\n",
    "\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q --upgrade sagemaker\n",
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29488e15-8d6b-46ab-b1ef-976652fb9021",
   "metadata": {},
   "source": [
    "If you set the following constant to a specific pipeline, you can run the entire notebook but only the specified pipeline will run.\n",
    "\n",
    "Here are the possible values:\n",
    "\n",
    "* PREPROCESSING\n",
    "* TRAINING\n",
    "* TUNING\n",
    "* EVALUATION\n",
    "* DEPLOYMENT\n",
    "* CUSTOM_ENDPOINT\n",
    "* MONITORING\n",
    "\n",
    "For example, setting `PIPELINE` to `DEPLOYMENT` will only execute the deployment pipeline from Session 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affb5875-e236-4027-882b-99bf68dde963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PIPELINE = \"CUSTOM_ENDPOINT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9992fc69-4868-4e50-a50e-76da237f70ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Session 1 - Getting Started\n",
    "\n",
    "This session aims to build a simple [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with one step to preprocess the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "915b1d0b-d9da-4529-aca5-fd1c08a36f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import argparse\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb24b35-450a-4b96-a544-38f084433b62",
   "metadata": {},
   "source": [
    "## Step 1 - Creating an S3 Bucket\n",
    "\n",
    "We need to create an S3 bucket where we will upload everything we need during the program.\n",
    "\n",
    "Make sure you set `BUCKET` to the name of the bucket you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea8d2fd-7dd4-43c8-b9d9-5372448d72a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Location\": \"/mlschool\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "BUCKET = \"mlschool\"\n",
    "\n",
    "!aws s3api create-bucket --bucket $BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accefa0d-31d6-4df4-814a-d74c703689b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2 - Downloading the Dataset\n",
    "\n",
    "We can now download the [Penguins dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data) and store it in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882a8be9-dc31-4df1-9009-3b2d0284cb70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset S3 location: s3://mlschool/penguins/data.csv\n"
     ]
    }
   ],
   "source": [
    "S3_FILEPATH = f\"s3://{BUCKET}/penguins\"\n",
    "DATA_FILEPATH = \"penguins/data.csv\"\n",
    "\n",
    "# Download the official Penguins dataset and store it locally.\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins_size.csv\", \n",
    "    DATA_FILEPATH\n",
    ")\n",
    "\n",
    "# Upload the dataset to S3. We need to do this to make it available to \n",
    "# the preprocessing step.\n",
    "INPUT_DATA_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=DATA_FILEPATH, \n",
    "    desired_s3_uri=S3_FILEPATH,\n",
    ")\n",
    "\n",
    "print(f\"Dataset S3 location: {INPUT_DATA_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1efbc-5f66-4b44-9555-68a4731e8e7b",
   "metadata": {},
   "source": [
    "We can now load and display the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19b546a-6884-483b-8cda-0521e2656a99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1    Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2    Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3    Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4    Adelie  Torgersen              36.7             19.3              193.0   \n",
       "..      ...        ...               ...              ...                ...   \n",
       "339  Gentoo     Biscoe               NaN              NaN                NaN   \n",
       "340  Gentoo     Biscoe              46.8             14.3              215.0   \n",
       "341  Gentoo     Biscoe              50.4             15.7              222.0   \n",
       "342  Gentoo     Biscoe              45.2             14.8              212.0   \n",
       "343  Gentoo     Biscoe              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    MALE  \n",
       "1         3800.0  FEMALE  \n",
       "2         3250.0  FEMALE  \n",
       "3            NaN     NaN  \n",
       "4         3450.0  FEMALE  \n",
       "..           ...     ...  \n",
       "339          NaN     NaN  \n",
       "340       4850.0  FEMALE  \n",
       "341       5750.0    MALE  \n",
       "342       5200.0  FEMALE  \n",
       "343       5400.0    MALE  \n",
       "\n",
       "[344 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_FILEPATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d06e0-b711-4e3d-b424-6fa611a51f94",
   "metadata": {},
   "source": [
    "## Step 3 - Preprocessing the Dataset\n",
    "\n",
    "Let's create a script to do feature engineering on the original dataset. \n",
    "\n",
    "This script should also split the data into train, validation, and a test set so we can later train and evaluate a model. We will save the Scikit-Learn pipeline that we use to preprocess the data to use it during inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6ba7c0-1bd6-4fe5-8b7f-f6cbdfd3846c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile penguins/preprocessor.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from pickle import dump\n",
    "\n",
    "\n",
    "BASE_DIR = \"/opt/ml/processing\"\n",
    "DATA_FILEPATH = Path(BASE_DIR) / \"input\" / \"data.csv\"\n",
    "\n",
    "\n",
    "def save_splits(base_dir, train, validation, test):\n",
    "    \"\"\"\n",
    "    Saves the supplied datasets to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_path = Path(base_dir) / \"train\" \n",
    "    validation_path = Path(base_dir) / \"validation\" \n",
    "    test_path = Path(base_dir) / \"test\"\n",
    "    \n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    validation_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    pd.DataFrame(train).to_csv(train_path / \"train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(validation_path / \"validation.csv\", header=False, index=False)\n",
    "    pd.DataFrame(test).to_csv(test_path / \"test.csv\", header=False, index=False)\n",
    "\n",
    "    \n",
    "def save_pipeline(base_dir, pipeline):\n",
    "    \"\"\"\n",
    "    Saves the Scikit-Learn pipeline that we used to\n",
    "    preprocess the data.\n",
    "    \"\"\"\n",
    "    pipeline_path = Path(base_dir) / \"pipeline\"\n",
    "    pipeline_path.mkdir(parents=True, exist_ok=True)\n",
    "    dump(pipeline, open(pipeline_path / \"pipeline.pkl\", 'wb'))\n",
    "    \n",
    "\n",
    "def preprocess(base_dir, data_filepath):\n",
    "    \"\"\"\n",
    "    Preprocesses the supplied raw dataset and splits it into a train, validation,\n",
    "    and a test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_filepath)\n",
    "    \n",
    "    numerical_columns = [column for column in df.columns if df[column].dtype in [\"int64\", \"float64\"]]\n",
    "    \n",
    "    numerical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"numerical\", numerical_preprocessor, numerical_columns),\n",
    "            (\"categorical\", categorical_preprocessor, [\"island\"]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "    X = df.drop([\"sex\"], axis=1)\n",
    "    columns = list(X.columns)\n",
    "    \n",
    "    X = X.to_numpy()\n",
    "    \n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(.7 * len(X)), int(.85 * len(X))])\n",
    "    \n",
    "    X_train = pd.DataFrame(train, columns=columns)\n",
    "    X_validation = pd.DataFrame(validation, columns=columns)\n",
    "    X_test = pd.DataFrame(test, columns=columns)\n",
    "    \n",
    "    y_train = X_train.species\n",
    "    y_validation = X_validation.species\n",
    "    y_test = X_test.species\n",
    "\n",
    "    X_train.drop([\"species\"], axis=1, inplace=True)\n",
    "    X_validation.drop([\"species\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"species\"], axis=1, inplace=True)\n",
    "\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_validation = preprocessor.transform(X_validation)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_validation = label_encoder.transform(y_validation)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    \n",
    "    \n",
    "    train = np.concatenate((X_train, np.expand_dims(y_train, axis=1)), axis=1)\n",
    "    validation = np.concatenate((X_validation, np.expand_dims(y_validation, axis=1)), axis=1)\n",
    "    test = np.concatenate((X_test, np.expand_dims(y_test, axis=1)), axis=1)\n",
    "    \n",
    "    save_splits(base_dir, train, validation, test)\n",
    "    save_pipeline(base_dir, pipeline=preprocessor)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess(BASE_DIR, DATA_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fbdcb-8ee8-4104-bcd3-d7329693299e",
   "metadata": {},
   "source": [
    "## Step 4 - Testing the Preprocessing Script\n",
    "\n",
    "We can now load the script we just created and run it locally to ensure it creates the 3 splits. \n",
    "\n",
    "Having a way to run scripts locally is crucial to shorten the development feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f122a4-acff-4687-91b9-bfef13567d88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: ['train', 'validation', 'test', 'pipeline']\n",
      "Train: ['train.csv']\n",
      "Validation: ['validation.csv']\n",
      "Test: ['test.csv']\n",
      "Pipeline: ['pipeline.pkl']\n"
     ]
    }
   ],
   "source": [
    "from penguins.preprocessor import preprocess\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    preprocess(\n",
    "        base_dir=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "    \n",
    "    print(f\"Splits: {os.listdir(directory)}\")\n",
    "    print(f\"Train: {os.listdir(Path(directory) / 'train')}\")\n",
    "    print(f\"Validation: {os.listdir(Path(directory) / 'validation')}\")\n",
    "    print(f\"Test: {os.listdir(Path(directory) / 'test')}\")\n",
    "    print(f\"Pipeline: {os.listdir(Path(directory) / 'pipeline')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3938a1d-d5bd-4967-ad65-a945d5df1f61",
   "metadata": {},
   "source": [
    "## Step 5 - Pipeline Configuration\n",
    "\n",
    "When we create a SageMaker Pipeline we can specify a list of paramaters that we can use throughout the individual pipeline steps. To read more about these parameters, check [Pipeline Parameters](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html).\n",
    "\n",
    "These are the parameters that will use in our pipeline:\n",
    "\n",
    "* `dataset_location`: This parameter represents the location of the dataset in S3. We will use this parameter during the preprocessing step to access the dataset.\n",
    "* `preprocessor_destination`: We need to define the location where the preprocessing step will be storing the dataset splits and the preprocessing pipeline to avoid SageMaker from appending a timestamp to their auto-generated location. If we let SageMaker use a timestamp, we can't cache this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86de7edd-18b0-40d1-ac8e-0f3ef4469be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=INPUT_DATA_URI,\n",
    ")\n",
    "\n",
    "preprocessor_destination = ParameterString(\n",
    "    name=\"preprocessor_destination\",\n",
    "    default_value=f'{S3_FILEPATH}/preprocessing',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b42440-b3c0-4ded-b578-52e21f5fbfdd",
   "metadata": {},
   "source": [
    "## Step 6 - Caching Pipeline Steps\n",
    "\n",
    "While you are building your pipeline, you don't want to rerun every step of the process unless you expect a different result. Instead, you can instruct SageMaker to reuse the result of a previous successful run of a pipeline step.\n",
    "\n",
    "You can accomplish this by caching your steps. You can find more information about this topic in [Caching Pipeline Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html).\n",
    "\n",
    "Getting caching to work is tricky, and you will find SageMaker missing the cache frequently. Whenever that happens, you need to dig and figure out how to adjust the step configuration to prevent SageMaker from autogenerating data that prevents a cache hit. For example, to cache the preprocessing step we need to define the destination of the processing job to prevent SageMaker from using an autogenerated timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e0a332-e54e-4e57-97c7-9b54f4058738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll use this cache configuration to cache individual steps for \n",
    "# a maximum of 15 days.\n",
    "cache_config = CacheConfig(\n",
    "    enable_caching=True, \n",
    "    expire_after=\"15d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9771e08-5560-492a-845e-f06988b6ae1b",
   "metadata": {},
   "source": [
    "## Step 7 - Setting up a Processing Step\n",
    "\n",
    "The first step we need in our pipeline is a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) to run the preprocessing script. Check the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "To run our script, we need access to Scikit-Learn, so we can use the [SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#scikit-learn-processor) processor that comes out-of-the-box with the SageMaker's Python SDK.\n",
    "\n",
    "The input of this step will be the dataset location. The outputs will be the three sets and the Scikit-Learn preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b982bc3-28f0-473f-b8d2-fc35dd251e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"penguins-preprocessing\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "preprocess_step = ProcessingStep(\n",
    "    name=\"preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=dataset_location, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"pipeline\", source=\"/opt/ml/processing/pipeline\", destination=preprocessor_destination),\n",
    "    ],\n",
    "    code=\"penguins/preprocessor.py\",\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465690a-67b5-4d68-a026-dd874ee569e8",
   "metadata": {},
   "source": [
    "## Step 8 - Defining and Running the Pipeline\n",
    "\n",
    "We can now define and run the SageMaker Pipeline. Check [Pipeline Structure and Execution](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-pipeline.html) for more information about how to define a pipeline and [Run a Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/run-pipeline.html) for information about how to run it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564fe6fb-00aa-480f-a58f-3144b2e33a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d0ac8-1439-4329-9a1c-c43eafacd0da",
   "metadata": {},
   "source": [
    "Submit the pipeline definition to the SageMaker Pipelines service to create a pipeline if it doesn't exist, or update the pipeline if it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4410f2f-a17b-4272-abd2-e092e134174c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PIPELINE == \"PREPROCESSING\":\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032460ff-eacc-4945-ba74-8782b2d02660",
   "metadata": {},
   "source": [
    "## Step 9 - Cleaning up\n",
    "\n",
    "Before you finish, don't forget to clean up after you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "83c39d12-77e1-48b5-908d-df28bf591ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:325223348818:pipeline/session1-penguins-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '32f6ae54-7f2f-4fba-a7a1-a7c4c276624a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '32f6ae54-7f2f-4fba-a7a1-a7c4c276624a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '94',\n",
       "   'date': 'Wed, 12 Apr 2023 23:02:57 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session1_pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03d209-764a-4499-9467-b50e17c0976d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assignments\n",
    "\n",
    "1. Set up an Amazon SageMaker domain using the Standard Setup. Make sure you set the network configuration to VPC Only. Create a new execution role and ensure it has access to the S3 bucket you’ll use during this class. You can also specify “Any S3 bucket” if you want this role to access every S3 bucket in your AWS account.\n",
    "\n",
    "2. Create a GitHub repository and clone it from inside SageMaker Studio. We’ll use this repository to store the code used during this program.\n",
    "\n",
    "3. Configure your SageMaker Studio session to store your name and email address and cache your credentials. You can use the following commands from a Terminal window:\n",
    "\n",
    "```bash\n",
    "$ git config --global user.name \"John Doe\"\n",
    "$ git config --global user.email johndoe@example.com\n",
    "$ git config --global credential.helper store\n",
    "```\n",
    "\n",
    "4. Throughout the course, you will work on the \"Pipeline of Digits\" project with the goal of seting up a SageMaker pipeline for a simple computer vision project. For this assignment, open the `mnist.ipynb` notebook and follow the instructions to prepare the dataset for the project.\n",
    "\n",
    "5. Setup a SageMaker pipeline for the \"Pipeline of Digits\" project. Create a preprocessing step where you split the MNIST dataset into a train and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696bed04-048c-4956-9016-b8a76519bd8c",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Amazon SageMaker is free to try. Your free tier starts from the first month when you create your first SageMaker resource and lasts 2 months. Check out the [Amazon SageMaker Pricing](https://aws.amazon.com/sagemaker/pricing/) for more information.\n",
    "\n",
    "2. We’ll be working extensively with [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html) and [SageMaker’s Python SDK](https://sagemaker.readthedocs.io/en/stable/). Keep their documentation handy.\n",
    "\n",
    "3. Check the [SageMaker Pipelines Overview](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) for an introduction to the fundamental components of a SageMaker Pipeline.\n",
    "\n",
    "4. Check [Pipeline Parameters](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html) for more information on how to define and use variables in your pipeline.\n",
    "\n",
    "5. Check [Caching Pipeline Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html) for information on how to cache the results of individual pipeline steps.\n",
    "\n",
    "6. Check the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) SageMaker's SDK documentation. You can find an example of how to create a processing job from the pipeline in the [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) page.\n",
    "\n",
    "7. Check [Pipeline Structure and Execution](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-pipeline.html) for more information about how to define a pipeline.\n",
    "\n",
    "8. Check [Run a Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/run-pipeline.html) for information about how to submit the pipeline definition to the SageMaker Pipelines service to create a pipeline if it doesn't exist, or update the pipeline if it does, and then run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c940d74-d409-4425-a796-1186a34c3532",
   "metadata": {},
   "source": [
    "## Additional Notes\n",
    "\n",
    "1. This notebook uses a Scikit-Learn Pipeline to transform the dataset. You should always orchestrate your transformations using pipelines. Check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more details.\n",
    "\n",
    "2. The preprocessing script uses `np.split()` to split the dataset into 3 different splits. It's a neat way of getting the three splits with a single instruction.\n",
    "\n",
    "3. Keras offers a [list of built-in vectorized datasets](https://www.notion.so/Bnomial-RESTful-API-4ecf85043b484ec994d7f70c56abfe27) in NumPy format. You can load any of these datasets with a single line of code, making them convenient.\n",
    "\n",
    "4. Converting a Numpy array into an image you can save and visualize is a useful trick to know. Check the `Image.fromarray()` function from the `PIL` library.\n",
    "\n",
    "5. The [command line interface](https://docs.aws.amazon.com/cli/latest/index.html) is a simple way to interact with the AWS services. You can combine Python code with bash commands in the same notebook cell, which makes notebooks a very flexible tool.\n",
    "\n",
    "6. Check Python’s `pathlib` module. Since Python 3.4, this module offers a clean way to interact with the filesystem.\n",
    "\n",
    "7. This notebook uses the `%%writefile`, `%load_ext`, and `%autoreload` magics. These magics are very useful when using notebooks. Check this list of [line and cell magics](https://ipython.readthedocs.io/en/stable/interactive/magics.html) for other examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c190c5-52b5-4ccc-8d42-847a694b8e66",
   "metadata": {},
   "source": [
    "# Session 2 - Training and Tuning\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) we built in the previous session with one step that trains a model.\n",
    "\n",
    "We explore the [Training](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training) and the [Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning) steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4756a3d8-d47b-4a88-a7f2-65ed7d4c1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.parameter import IntegerParameter\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8608092-7aab-4fd2-aa99-47c2db27bdb7",
   "metadata": {},
   "source": [
    "## Step 1 - Training the Model\n",
    "\n",
    "This script is responsible from training a simple neural network on the train data, validating the model, and saving it so we can later use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92b121d-dcb9-43e8-9ee3-3ececb583e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile penguins/train.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "def train(base_directory, train_path, validation_path, epochs=50, batch_size=32):\n",
    "    X_train = pd.read_csv(Path(train_path) / \"train.csv\")\n",
    "    y_train = X_train[X_train.columns[-1]]\n",
    "    X_train.drop(X_train.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    X_validation = pd.read_csv(Path(validation_path) / \"validation.csv\")\n",
    "    y_validation = X_validation[X_validation.columns[-1]]\n",
    "    X_validation.drop(X_validation.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape=(X_train.shape[1],), activation=\"relu\"),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(3, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=SGD(learning_rate=0.01),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        validation_data=(X_validation, y_validation),\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    predictions = np.argmax(model.predict(X_validation), axis=-1)\n",
    "    print(f\"Validation accuracy: {accuracy_score(y_validation, predictions)}\")\n",
    "    \n",
    "    model_filepath = Path(base_directory) / \"model\" / \"001\"\n",
    "    model.save(model_filepath)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Any hyperparameters provided by the training job are passed to the entry point\n",
    "    # as script arguments. SageMaker will also provide a list of special parameters\n",
    "    # that you can capture here. Here is the full list: \n",
    "    # https://github.com/aws/sagemaker-training-toolkit/blob/master/src/sagemaker_training/params.py\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--base_directory\", type=str, default=\"/opt/ml/\")\n",
    "    parser.add_argument(\"--train_path\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\", None))\n",
    "    parser.add_argument(\"--validation_path\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\", None))\n",
    "    parser.add_argument(\"--epochs\", type=int, default=50)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    train(\n",
    "        base_directory=args.base_directory,\n",
    "        train_path=args.train_path,\n",
    "        validation_path=args.validation_path,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0a4fa-ce70-4882-b9f5-8253df03d890",
   "metadata": {},
   "source": [
    "## Step 2 - Testing the Training Script\n",
    "\n",
    "Let's test the script we just created by running it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14ea27ce-c453-4cb0-b309-dbecd732957e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2023-04-13 20:23:54.266 tensorflow-2-6-cpu-py-ml-t3-medium-9169b2e75617c45c79c40579f6a8:105 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-04-13 20:23:54.332 tensorflow-2-6-cpu-py-ml-t3-medium-9169b2e75617c45c79c40579f6a8:105 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "8/8 - 1s - loss: 1.0914 - accuracy: 0.2720 - val_loss: 1.0718 - val_accuracy: 0.3137\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 1.0455 - accuracy: 0.3975 - val_loss: 1.0402 - val_accuracy: 0.3529\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 1.0129 - accuracy: 0.4435 - val_loss: 1.0136 - val_accuracy: 0.3137\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.9852 - accuracy: 0.4644 - val_loss: 0.9918 - val_accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.9621 - accuracy: 0.5021 - val_loss: 0.9713 - val_accuracy: 0.3725\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.9401 - accuracy: 0.5397 - val_loss: 0.9519 - val_accuracy: 0.4510\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.9188 - accuracy: 0.5774 - val_loss: 0.9329 - val_accuracy: 0.4902\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.8973 - accuracy: 0.6276 - val_loss: 0.9141 - val_accuracy: 0.5490\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.8757 - accuracy: 0.6820 - val_loss: 0.8945 - val_accuracy: 0.6078\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.8536 - accuracy: 0.7071 - val_loss: 0.8747 - val_accuracy: 0.6863\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.8311 - accuracy: 0.7448 - val_loss: 0.8542 - val_accuracy: 0.7059\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.8077 - accuracy: 0.7782 - val_loss: 0.8335 - val_accuracy: 0.7255\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.7841 - accuracy: 0.8075 - val_loss: 0.8126 - val_accuracy: 0.7647\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.7602 - accuracy: 0.8201 - val_loss: 0.7915 - val_accuracy: 0.7647\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.7362 - accuracy: 0.8201 - val_loss: 0.7706 - val_accuracy: 0.7647\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.7130 - accuracy: 0.8201 - val_loss: 0.7495 - val_accuracy: 0.7647\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.6901 - accuracy: 0.8201 - val_loss: 0.7288 - val_accuracy: 0.7647\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.6676 - accuracy: 0.8201 - val_loss: 0.7086 - val_accuracy: 0.7647\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.6458 - accuracy: 0.8201 - val_loss: 0.6882 - val_accuracy: 0.7647\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.6245 - accuracy: 0.8201 - val_loss: 0.6684 - val_accuracy: 0.7647\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.6040 - accuracy: 0.8201 - val_loss: 0.6486 - val_accuracy: 0.7647\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.5842 - accuracy: 0.8201 - val_loss: 0.6294 - val_accuracy: 0.7647\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.5654 - accuracy: 0.8201 - val_loss: 0.6109 - val_accuracy: 0.7647\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.5469 - accuracy: 0.8201 - val_loss: 0.5929 - val_accuracy: 0.7647\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.5293 - accuracy: 0.8201 - val_loss: 0.5757 - val_accuracy: 0.7647\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.5128 - accuracy: 0.8201 - val_loss: 0.5591 - val_accuracy: 0.7647\n",
      "Epoch 27/50\n",
      "8/8 - 0s - loss: 0.4967 - accuracy: 0.8201 - val_loss: 0.5434 - val_accuracy: 0.7647\n",
      "Epoch 28/50\n",
      "8/8 - 0s - loss: 0.4818 - accuracy: 0.8201 - val_loss: 0.5286 - val_accuracy: 0.7647\n",
      "Epoch 29/50\n",
      "8/8 - 0s - loss: 0.4674 - accuracy: 0.8201 - val_loss: 0.5142 - val_accuracy: 0.7647\n",
      "Epoch 30/50\n",
      "8/8 - 0s - loss: 0.4536 - accuracy: 0.8201 - val_loss: 0.5006 - val_accuracy: 0.7647\n",
      "Epoch 31/50\n",
      "8/8 - 0s - loss: 0.4406 - accuracy: 0.8159 - val_loss: 0.4874 - val_accuracy: 0.7647\n",
      "Epoch 32/50\n",
      "8/8 - 0s - loss: 0.4281 - accuracy: 0.8159 - val_loss: 0.4749 - val_accuracy: 0.7647\n",
      "Epoch 33/50\n",
      "8/8 - 0s - loss: 0.4161 - accuracy: 0.8159 - val_loss: 0.4631 - val_accuracy: 0.7647\n",
      "Epoch 34/50\n",
      "8/8 - 0s - loss: 0.4048 - accuracy: 0.8159 - val_loss: 0.4519 - val_accuracy: 0.7647\n",
      "Epoch 35/50\n",
      "8/8 - 0s - loss: 0.3942 - accuracy: 0.8159 - val_loss: 0.4410 - val_accuracy: 0.7647\n",
      "Epoch 36/50\n",
      "8/8 - 0s - loss: 0.3838 - accuracy: 0.8159 - val_loss: 0.4307 - val_accuracy: 0.7647\n",
      "Epoch 37/50\n",
      "8/8 - 0s - loss: 0.3740 - accuracy: 0.8159 - val_loss: 0.4210 - val_accuracy: 0.7647\n",
      "Epoch 38/50\n",
      "8/8 - 0s - loss: 0.3646 - accuracy: 0.8159 - val_loss: 0.4116 - val_accuracy: 0.7647\n",
      "Epoch 39/50\n",
      "8/8 - 0s - loss: 0.3557 - accuracy: 0.8159 - val_loss: 0.4026 - val_accuracy: 0.7647\n",
      "Epoch 40/50\n",
      "8/8 - 0s - loss: 0.3470 - accuracy: 0.8159 - val_loss: 0.3941 - val_accuracy: 0.7647\n",
      "Epoch 41/50\n",
      "8/8 - 0s - loss: 0.3388 - accuracy: 0.8159 - val_loss: 0.3859 - val_accuracy: 0.7843\n",
      "Epoch 42/50\n",
      "8/8 - 0s - loss: 0.3309 - accuracy: 0.8159 - val_loss: 0.3779 - val_accuracy: 0.7843\n",
      "Epoch 43/50\n",
      "8/8 - 0s - loss: 0.3234 - accuracy: 0.8201 - val_loss: 0.3702 - val_accuracy: 0.7843\n",
      "Epoch 44/50\n",
      "8/8 - 0s - loss: 0.3160 - accuracy: 0.8201 - val_loss: 0.3625 - val_accuracy: 0.7843\n",
      "Epoch 45/50\n",
      "8/8 - 0s - loss: 0.3088 - accuracy: 0.8243 - val_loss: 0.3553 - val_accuracy: 0.7843\n",
      "Epoch 46/50\n",
      "8/8 - 0s - loss: 0.3019 - accuracy: 0.8243 - val_loss: 0.3482 - val_accuracy: 0.7843\n",
      "Epoch 47/50\n",
      "8/8 - 0s - loss: 0.2950 - accuracy: 0.8243 - val_loss: 0.3415 - val_accuracy: 0.8039\n",
      "Epoch 48/50\n",
      "8/8 - 0s - loss: 0.2886 - accuracy: 0.8410 - val_loss: 0.3348 - val_accuracy: 0.8039\n",
      "Epoch 49/50\n",
      "8/8 - 0s - loss: 0.2822 - accuracy: 0.8452 - val_loss: 0.3282 - val_accuracy: 0.8235\n",
      "Epoch 50/50\n",
      "8/8 - 0s - loss: 0.2758 - accuracy: 0.8494 - val_loss: 0.3216 - val_accuracy: 0.8235\n",
      "Validation accuracy: 0.8235294117647058\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp10_u1g1g/model/001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp10_u1g1g/model/001/assets\n"
     ]
    }
   ],
   "source": [
    "from penguins.preprocessor import preprocess\n",
    "from penguins.train import train\n",
    "\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    # First, we preprocess the data and create the \n",
    "    # dataset splits.\n",
    "    preprocess(\n",
    "        base_dir=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "\n",
    "    # Then, we train a model using the train and \n",
    "    # validation splits.\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3dc26-db20-43d1-a352-8dc3b7eb7a0a",
   "metadata": {},
   "source": [
    "## Step 3 - Configuring an Estimator\n",
    "\n",
    "SageMaker uses the concept of an [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) to handle end-to-end training and deployment tasks. For this example, we will use the [TensorFlow Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) to run the trainning script we wrote before.\n",
    "\n",
    "SageMaker will pass the list of hyperparameters defined below to the entry point of the training script as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90fe82ae-6a2c-4461-bc83-bb52d8871e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=\"penguins/train.py\",\n",
    "    role=role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    py_version=\"py37\",\n",
    "    framework_version=\"2.4\",\n",
    "    script_mode=True,\n",
    "    disable_profiler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cff4c1-6510-4d99-8ae1-cb14927b87c7",
   "metadata": {},
   "source": [
    "## Step 4 - Setting up a Training Step\n",
    "\n",
    "We can now create a [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training) that we can add to the pipeline. Check the [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) SageMaker's SDK documentation for more information. \n",
    "\n",
    "This step will use the estimator we configured before and will receive the train and validation splits from the preprocessing step as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e4850c-83d6-4f4e-a813-d5a3f4bb7486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_step = TrainingStep(\n",
    "    name=\"training\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797792d0-eda4-4f35-b26c-ef6f2309a309",
   "metadata": {},
   "source": [
    "## Step 5 - Running the Pipeline with the Training Step\n",
    "\n",
    "We can now define and run the SageMaker Pipeline, this time using the new Training Step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1126c623-f6ae-4e09-a6c9-28b86e6fc265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        training_step\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc444f7-3994-4729-a60e-bc7efd326cec",
   "metadata": {},
   "source": [
    "Submit the pipeline definition to the SageMaker Pipelines service to create a pipeline if it doesn't exist, or update the pipeline if it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d7b5345-7e06-4c1a-ac54-f84dbdbe15a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PIPELINE == \"TRAINING\":\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a28de-5999-4d39-b759-c0e8792ea023",
   "metadata": {},
   "source": [
    "## Step 6 - Configuring a Hyperparameter Tuner\n",
    "\n",
    "An alternative to training a model is to train many variants of the model and choose the best one. We can do this with an instance of the [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) class.\n",
    "\n",
    "The tuner uses the same `Estimator` we defined to train the model, and we can specify how it should determine the best model:\n",
    "\n",
    "1. `objective_metric_name`: This is the name of the metric the tuner will use to determine the best model.\n",
    "2. `objective_type`: This is the objective of the tuner. Should it \"Minimize\" the metric or \"Maximize\" it? In this example, sice we are using the validation accuracy of the model, we want the objetive to be \"Maximize.\" If we were using the loss of the model, we would set the objetive to \"Minimize.\"\n",
    "3. `metric_definitions`: Defines how the tuner will determine the value of the metric by looking at the output logs of the training process.\n",
    "\n",
    "The tuner expects a list of the hyperparameters you want to explore. You can use subclasses of the [Parameter](https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html#sagemaker.parameter.ParameterRange) class to specify different types of hyperparameters.\n",
    "\n",
    "Finally, you can control the number of jobs and how many of them will run in parallel using the following two arguments:\n",
    "* `max_jobs`: Defines the maximum total number of training jobs to start for the hyperparameter tuning job.\n",
    "* `max_parallel_jobs`: Defines the maximum number of parallel training jobs to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "038ff2e5-ed28-445b-bc03-4e996ec2286f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"epochs\": IntegerParameter(10, 50)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"val_accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": objective_metric_name, \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}]\n",
    "    \n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    objective_type=objective_type,\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814e258-c633-4e9a-85c5-6ed0f168b503",
   "metadata": {},
   "source": [
    "## Step 7 - Setting up a Tuning Step\n",
    "\n",
    "We can now create a [Tuning Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning) to add it to our pipeline. Check the [TuningStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep) SageMaker's SDK documentation for more information. \n",
    "\n",
    "This step will use the tuner we configured before and will receive the train and validation splits from the preprocessing step as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf5dd9a7-8643-4fbb-8eb4-40f39011e27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_step = TuningStep(\n",
    "    name = \"tuning\",\n",
    "    tuner=tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4babe38c-1682-42d2-8442-101d17aa89b5",
   "metadata": {},
   "source": [
    "## Step 8 - Running the Pipeline with the Tuning Step\n",
    "\n",
    "We can now define and run the SageMaker Pipeline, this time using the new Tuning Step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9799ab39-fcae-41f4-a68b-85ab71b3ba9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        tuning_step\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0708c-3692-4d09-a269-bbd14f7b0226",
   "metadata": {},
   "source": [
    "Submit the pipeline definition to the SageMaker Pipelines service to create a pipeline if it doesn't exist, or update the pipeline if it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77c6d523-6810-4bc7-8fc4-64ae978cf245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PIPELINE == \"TUNING\":\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17942235-e050-4157-b9dd-47de56433855",
   "metadata": {},
   "source": [
    "## Step 9 - Cleaning up\n",
    "\n",
    "Before you finish, don't forget to clean up after you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0140f856-182d-4459-9b6c-45c4a8e69de8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:325223348818:pipeline/session2-tuning-penguins-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'fb4b7e41-1fb4-4077-887b-15ca1bf09910',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fb4b7e41-1fb4-4077-887b-15ca1bf09910',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '101',\n",
       "   'date': 'Tue, 11 Apr 2023 20:35:46 GMT'},\n",
       "  'RetryAttempts': 2}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session2_training_pipeline.delete()\n",
    "session2_tuning_pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca966b85-5bef-4a59-a967-27bdfff47ae1",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "1. Modify the training script so it accepts the `learning_rate` as a new hyperparameter using the list of hyperparameters supplied to the Estimator.\n",
    "\n",
    "2. Replace the TensorFlow Estimator with a Pytorch Estimator. Check [this page](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#create-an-estimator) for an example of how to create a PyTorch Estimator. You'll need to create a new training script that builds a PyTorch model to solve the problem.\n",
    "\n",
    "3. Modify the tuner job to find the best `learning_rate` value between `0.01` and `0.03`. Check the [ContinuousParameter](https://sagemaker.readthedocs.io/en/stable/api/training/parameter.html#sagemaker.parameter.ContinuousParameter) class for more information on how to configure this parameter.\n",
    "\n",
    "4. Modify the pipeline to run the training and tuning jobs concurrently.\n",
    "\n",
    "5. Modify the SageMaker Pipeline you created for the MNIST project and add a training step. That step should only receive one channel with the train data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af93846-ca69-4ae4-99d6-529c6ebda617",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. The [Docker Registry Paths and Example Code](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html) page contains information about the available fremwork versions for each region. You can also check the available SageMaker [Deep Learning Container images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md) here.\n",
    "\n",
    "2. Check [SageMaker Training Toolkit](https://github.com/aws/sagemaker-training-toolkit) for more information about how to train machine learning models within a Docker container using Amazon SageMaker.\n",
    "\n",
    "3. Check the [TrainingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TrainingStep) SageMaker's SDK documentation. You can find an example of how to create a training job from the pipeline in the [Training Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training) page.\n",
    "\n",
    "4. Check the [TuningStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep) SageMaker's SDK documentation. You can find an example of how to create a hyperparameter tuning job from the pipeline in the [Tuning Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning) page.\n",
    "\n",
    "5. Check the [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) and the [TensorFlow Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) documentation for more information about how these classes work. You can also find [other supported frameworks](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html) in the documentation.\n",
    "\n",
    "6. Check the [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) class for more information about how to configure a hyperparameter job.\n",
    "\n",
    "7. The SageMaker SDK passes special hyperparameters to the training job that we can capture from inside the script. Here is the [complete list of available hyperparameters](https://github.com/aws/sagemaker-training-toolkit/blob/master/src/sagemaker_training/params.py). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d40fe8-ba74-4c12-9555-d8ea33d1c8b4",
   "metadata": {},
   "source": [
    "# Session 3 - Evaluating the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a step to evaluate the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34fc262f-a1cf-4f94-9c60-e7c8e83cfdfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "from sagemaker.workflow.properties import PropertyFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa9691-f49f-48af-b272-3d4d17563b01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1 - Evaluating the Model\n",
    "\n",
    "This script is reponsible from loading the model we created and evaluating it on the test set. Before finishing, this script will create a file containing an evaluation report of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ee3ab26-afa5-4ceb-9f7a-005d5fdea646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting penguins/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile penguins/evaluation.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/opt/ml/processing/model/\"\n",
    "TEST_PATH = \"/opt/ml/processing/test/\"\n",
    "OUTPUT_PATH = \"/opt/ml/processing/evaluation/\"\n",
    "\n",
    "\n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    # The first step is to extract the model package provided\n",
    "    # by SageMaker.\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    # We can now load the model from disk.\n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    \n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test[X_test.columns[-1]]\n",
    "    X_test.drop(X_test.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "    # Let's add the accuracy of the model to our evaluation report.\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": accuracy\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # We need to save the evaluation report to the output path.\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=MODEL_PATH, \n",
    "        test_path=TEST_PATH,\n",
    "        output_path=OUTPUT_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc79a0-adfd-4ce9-8580-5cd228c3c2d9",
   "metadata": {},
   "source": [
    "## Step 2 - Testing the Evaluation Script\n",
    "\n",
    "Let's test the script we just created by running it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a2540d8-278a-4953-bc54-0469d154427d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 1s - loss: 1.1324 - accuracy: 0.1255 - val_loss: 1.1050 - val_accuracy: 0.1373\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 1.1005 - accuracy: 0.1799 - val_loss: 1.0847 - val_accuracy: 0.1765\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 1.0733 - accuracy: 0.2176 - val_loss: 1.0660 - val_accuracy: 0.2549\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 1.0483 - accuracy: 0.2678 - val_loss: 1.0497 - val_accuracy: 0.3922\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 1.0260 - accuracy: 0.3180 - val_loss: 1.0336 - val_accuracy: 0.4706\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 1.0045 - accuracy: 0.4770 - val_loss: 1.0183 - val_accuracy: 0.5294\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.9841 - accuracy: 0.6444 - val_loss: 1.0034 - val_accuracy: 0.6863\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.9638 - accuracy: 0.7490 - val_loss: 0.9886 - val_accuracy: 0.7451\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.9436 - accuracy: 0.7824 - val_loss: 0.9735 - val_accuracy: 0.7451\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.9231 - accuracy: 0.8033 - val_loss: 0.9580 - val_accuracy: 0.7451\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.9022 - accuracy: 0.8201 - val_loss: 0.9422 - val_accuracy: 0.7451\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.8806 - accuracy: 0.8410 - val_loss: 0.9260 - val_accuracy: 0.7451\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.8593 - accuracy: 0.8452 - val_loss: 0.9102 - val_accuracy: 0.7451\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.8382 - accuracy: 0.8452 - val_loss: 0.8940 - val_accuracy: 0.7451\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.8164 - accuracy: 0.8494 - val_loss: 0.8776 - val_accuracy: 0.7451\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.7941 - accuracy: 0.8494 - val_loss: 0.8613 - val_accuracy: 0.7451\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.7722 - accuracy: 0.8494 - val_loss: 0.8446 - val_accuracy: 0.7451\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.7498 - accuracy: 0.8494 - val_loss: 0.8284 - val_accuracy: 0.7451\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.7281 - accuracy: 0.8494 - val_loss: 0.8120 - val_accuracy: 0.7451\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.7065 - accuracy: 0.8494 - val_loss: 0.7960 - val_accuracy: 0.7451\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.6852 - accuracy: 0.8494 - val_loss: 0.7801 - val_accuracy: 0.7451\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.6649 - accuracy: 0.8494 - val_loss: 0.7647 - val_accuracy: 0.7451\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.6450 - accuracy: 0.8494 - val_loss: 0.7497 - val_accuracy: 0.7451\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.6257 - accuracy: 0.8494 - val_loss: 0.7350 - val_accuracy: 0.7451\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.6075 - accuracy: 0.8494 - val_loss: 0.7210 - val_accuracy: 0.7451\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.5900 - accuracy: 0.8494 - val_loss: 0.7076 - val_accuracy: 0.7451\n",
      "Epoch 27/50\n",
      "8/8 - 0s - loss: 0.5733 - accuracy: 0.8494 - val_loss: 0.6947 - val_accuracy: 0.7451\n",
      "Epoch 28/50\n",
      "8/8 - 0s - loss: 0.5576 - accuracy: 0.8494 - val_loss: 0.6827 - val_accuracy: 0.7451\n",
      "Epoch 29/50\n",
      "8/8 - 0s - loss: 0.5427 - accuracy: 0.8494 - val_loss: 0.6712 - val_accuracy: 0.7451\n",
      "Epoch 30/50\n",
      "8/8 - 0s - loss: 0.5286 - accuracy: 0.8494 - val_loss: 0.6606 - val_accuracy: 0.7451\n",
      "Epoch 31/50\n",
      "8/8 - 0s - loss: 0.5157 - accuracy: 0.8494 - val_loss: 0.6503 - val_accuracy: 0.7451\n",
      "Epoch 32/50\n",
      "8/8 - 0s - loss: 0.5036 - accuracy: 0.8494 - val_loss: 0.6406 - val_accuracy: 0.7451\n",
      "Epoch 33/50\n",
      "8/8 - 0s - loss: 0.4921 - accuracy: 0.8494 - val_loss: 0.6312 - val_accuracy: 0.7451\n",
      "Epoch 34/50\n",
      "8/8 - 0s - loss: 0.4814 - accuracy: 0.8494 - val_loss: 0.6226 - val_accuracy: 0.7451\n",
      "Epoch 35/50\n",
      "8/8 - 0s - loss: 0.4714 - accuracy: 0.8494 - val_loss: 0.6142 - val_accuracy: 0.7451\n",
      "Epoch 36/50\n",
      "8/8 - 0s - loss: 0.4621 - accuracy: 0.8494 - val_loss: 0.6063 - val_accuracy: 0.7451\n",
      "Epoch 37/50\n",
      "8/8 - 0s - loss: 0.4531 - accuracy: 0.8494 - val_loss: 0.5984 - val_accuracy: 0.7451\n",
      "Epoch 38/50\n",
      "8/8 - 0s - loss: 0.4447 - accuracy: 0.8494 - val_loss: 0.5901 - val_accuracy: 0.7451\n",
      "Epoch 39/50\n",
      "8/8 - 0s - loss: 0.4368 - accuracy: 0.8494 - val_loss: 0.5831 - val_accuracy: 0.7451\n",
      "Epoch 40/50\n",
      "8/8 - 0s - loss: 0.4291 - accuracy: 0.8494 - val_loss: 0.5762 - val_accuracy: 0.7451\n",
      "Epoch 41/50\n",
      "8/8 - 0s - loss: 0.4220 - accuracy: 0.8494 - val_loss: 0.5690 - val_accuracy: 0.7451\n",
      "Epoch 42/50\n",
      "8/8 - 0s - loss: 0.4152 - accuracy: 0.8494 - val_loss: 0.5620 - val_accuracy: 0.7451\n",
      "Epoch 43/50\n",
      "8/8 - 0s - loss: 0.4087 - accuracy: 0.8494 - val_loss: 0.5557 - val_accuracy: 0.7451\n",
      "Epoch 44/50\n",
      "8/8 - 0s - loss: 0.4025 - accuracy: 0.8494 - val_loss: 0.5497 - val_accuracy: 0.7451\n",
      "Epoch 45/50\n",
      "8/8 - 0s - loss: 0.3965 - accuracy: 0.8494 - val_loss: 0.5431 - val_accuracy: 0.7451\n",
      "Epoch 46/50\n",
      "8/8 - 0s - loss: 0.3907 - accuracy: 0.8494 - val_loss: 0.5368 - val_accuracy: 0.7451\n",
      "Epoch 47/50\n",
      "8/8 - 0s - loss: 0.3852 - accuracy: 0.8494 - val_loss: 0.5304 - val_accuracy: 0.7451\n",
      "Epoch 48/50\n",
      "8/8 - 0s - loss: 0.3798 - accuracy: 0.8494 - val_loss: 0.5244 - val_accuracy: 0.7451\n",
      "Epoch 49/50\n",
      "8/8 - 0s - loss: 0.3748 - accuracy: 0.8494 - val_loss: 0.5179 - val_accuracy: 0.7451\n",
      "Epoch 50/50\n",
      "8/8 - 0s - loss: 0.3697 - accuracy: 0.8494 - val_loss: 0.5118 - val_accuracy: 0.7451\n",
      "Validation accuracy: 0.7450980392156863\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpp5y9747i/model/001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp5y9747i/model/001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "from penguins.preprocessor import preprocess\n",
    "from penguins.train import train\n",
    "from penguins.evaluation import evaluate\n",
    "\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    # First, we preprocess the data and create the \n",
    "    # dataset splits.\n",
    "    preprocess(\n",
    "        base_dir=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "\n",
    "    # Then, we train a model using the train and \n",
    "    # validation splits.\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=10\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(Path(directory) / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(Path(directory) / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "    \n",
    "    # We can now call the evaluation script.\n",
    "    evaluate(\n",
    "        model_path=directory, \n",
    "        test_path=Path(directory) / \"test\",\n",
    "        output_path=Path(directory) / \"evaluation\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d0b30-edf1-4b05-a570-e4f1d5a312e1",
   "metadata": {},
   "source": [
    "## Step 3 - Setting up a Processor\n",
    "\n",
    "To run the evaluation script we can use a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing). Check the [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "This time, we will use a [ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor) running a TensorFlow image. This will give us access to every library we need to execute the evaluation script.\n",
    "\n",
    "You can use the [sagemaker.image_utis.retrieve()](https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html) function for generating the URI of pre-built docker images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f85bcbe6-41eb-4f3f-b57d-6cb3ab5e5106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's retrieve the image we want to use to run the\n",
    "# processing job.\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.4\",\n",
    "    py_version=\"py37\",\n",
    "    image_scope=\"training\",\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "# We can now setup the processor using the URI of\n",
    "# the pre-built docker image.\n",
    "evaluation_script_processor = ScriptProcessor(\n",
    "    base_job_name=\"penguins-evaluation-processor\",\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ba1cc-1bed-4b78-ba3c-842945bb26ea",
   "metadata": {},
   "source": [
    "## Step 4 - Configuring the Model Input\n",
    "\n",
    "One of the inputs to the Evaluation Step is the model we created. We explored two different ways to create the model: a Training Step and a Tuning Step.\n",
    "\n",
    "Here we can configure the input to the Evaluation Step based on whether we want to select the best model generated by the Tuning Step, or the model we trained using the Training Step.\n",
    "\n",
    "We can use the [get_top_model_s3_uri()](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep.get_top_model_s3_uri) function to get the model artifacts from the top performing training jobs of the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffcebf04-53af-45e1-8f40-cc205cce8d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# By default, this notebook uses the best model from the Tuning Step.\n",
    "# You can set this variable to False if you want to use the result\n",
    "# of the Training Step.\n",
    "USE_TUNING_STEP = False\n",
    "\n",
    "# This is the input in case we want to use the best model generated\n",
    "# by the Tuning Step.\n",
    "tuning_model_input = ProcessingInput(\n",
    "    source=tuning_step.get_top_model_s3_uri(\n",
    "        top_k=0, \n",
    "        s3_bucket=sagemaker_session.default_bucket()\n",
    "    ),\n",
    "    destination=\"/opt/ml/processing/model\",\n",
    ")\n",
    "\n",
    "# This is the input in case we want to use the trained model\n",
    "# from the Training Step.\n",
    "training_model_input = ProcessingInput(\n",
    "    source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    destination=\"/opt/ml/processing/model\"\n",
    ")\n",
    "\n",
    "# We can now select the appropriate input depending on which step\n",
    "# we are using.\n",
    "model_input = tuning_model_input if USE_TUNING_STEP else training_model_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1109a-6c26-4464-8338-94960729d212",
   "metadata": {},
   "source": [
    "## Step 5 - Setting up a Processing Step\n",
    "\n",
    "We can now create a [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) to run the evaluation script. We'll use the [ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor) we defined before. \n",
    "\n",
    "The inputs of this step will be the model and the test set that we generated during the preprocessing step. The output will be the evaluation report file.\n",
    "\n",
    "The [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) lets us specify a list of [PropertyFile](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.properties.PropertyFile) instances from the output of the job. We can use this to map the evaluation report that we generate in the evaluations script. Check [How to Build and Manage Property Files](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html) for more information.\n",
    "\n",
    "Also, we need to define the location where the evaluation step will be storing the evaluation report to prevent SageMaker from appending a timestamp to their auto-generated location. If we let SageMaker use a timestamp, we can't cache this step. That's the goal of the `evaluation_destination` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48139a07-5c8e-4bc6-b666-bf9531f7f520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the location where the evaluation step will store the \n",
    "# evaluation report.\n",
    "evaluation_destination = ParameterString(\n",
    "    name=\"evaluation_destination\",\n",
    "    default_value=f'{S3_FILEPATH}/evaluation',\n",
    ")\n",
    "\n",
    "\n",
    "# We want to map the evaluation report that we generate inside\n",
    "# the evaluation script so we can later reference it.\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "\n",
    "# Notice how this step uses the model generated by the tuning or training\n",
    "# step, and the test set generated by the preprocessing step.\n",
    "evaluation_step = ProcessingStep(\n",
    "    name=\"evaluation\",\n",
    "    processor=evaluation_script_processor,\n",
    "    inputs=[\n",
    "        model_input,\n",
    "        ProcessingInput(\n",
    "            source=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", destination=evaluation_destination),\n",
    "    ],\n",
    "    code=\"penguins/evaluation.py\",\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f8cb8-d284-425b-8c4a-f644b4ac7ebe",
   "metadata": {},
   "source": [
    "## Step 6 - Running the Pipeline\n",
    "\n",
    "We can now add the model evaluation step to the pipeline.\n",
    "\n",
    "We are going to configure the pipeline to run the Tuning Step or the Training Step depending on the value of the `USE_TUNING_STEP` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32638959-642d-4068-8fbc-3355c618115b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        evaluation_destination,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        tuning_step if USE_TUNING_STEP else training_step,\n",
    "        evaluation_step\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e98fb1-fdff-4ba4-aea3-0d9f271fb24c",
   "metadata": {},
   "source": [
    "Submit the pipeline definition to the SageMaker Pipelines service to create a pipeline if it doesn't exist, or update the pipeline if it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4864ab08-7acc-4719-970e-fcce66c5fef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PIPELINE == \"EVALUATION\":\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520750e9-ee5f-4cd6-beae-5442dc9a75c3",
   "metadata": {},
   "source": [
    "## Step 7 - Cleaning up\n",
    "\n",
    "Before you finish, don't forget to clean up after you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf20d8-420f-4f95-8cb0-03788f7ab556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session3_pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1a43b-a58e-4424-823e-78f3806c7187",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "1. Extend the evaluation report by adding other metrics. For example, add the support of the test set (the number of samples.)\n",
    "\n",
    "2. One of the assignments from the previous session was to replace the TensorFlow Estimator with a Pytorch Estimator. You can now modify the evaluation step to load a script that uses Pytorch to evaluate the model.\n",
    "\n",
    "3. If you are runing the Training and Tuning Steps simultaneously, create two different Evaluation Steps to evaluate both models independently.\n",
    "\n",
    "4. Instead of runing the Training and Tuning Steps simultaneously, run the Tuning Step but create two Evaluation Steps to evaluate the two best models produced by the Tuning Step. Check the [TuningJob.get_top_model_s3_uri()](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep.get_top_model_s3_uri) function to retrieve the two best models.\n",
    "\n",
    "5. Modify the SageMaker Pipeline you created for the MNIST project and add an evaluation step. That step should use the test set you generated in the preprocessing step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a39ea3-a553-4762-ae42-f9272d3c3028",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Resources\n",
    "\n",
    "1. Check the [ScriptProcessor](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ScriptProcessor) SageMaker's SDK documentation for more information about how to run a processing job using a machine learning framework.\n",
    "\n",
    "2. SageMaker offers a list of pre-built docker images. You can use the [sagemaker.image_utis.retrieve()](https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html) function for generating the URI of these images.\n",
    "\n",
    "3. You can use the [TuningJob.get_top_model_s3_uri()](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.TuningStep.get_top_model_s3_uri) function to get the model artifacts from the top performing training jobs of the hyperparameter tuning job.\n",
    "\n",
    "4. Check [How to Build and Manage Property Files](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html) for more information about mapping the output of a [ProcessingStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep) to a [PropertyFile](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.properties.PropertyFile)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917ee33-f895-45e6-83d3-e34255ba550b",
   "metadata": {},
   "source": [
    "# Session 4 - Deploying the Model\n",
    "\n",
    "This session extends the [SageMaker Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) with a step to register a new model if it reaches a predefined accuracy threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6545d1a3-c1ec-4eae-92fb-5b11d8f1dbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.functions import Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696f63c-c036-46be-b352-4e23b5db0553",
   "metadata": {},
   "source": [
    "## Step 1 - Creating Two New Pipeline Parameters\n",
    "\n",
    "We are going to use two new [Pipeline Parameters](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html) in our pipeline:\n",
    "\n",
    "* `model_approval_status`: This parameter represents the default approval status that we will use when registering a new model. Check [Update the Approval Status of a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-approve.html) for more information about the different approval status of a model and how you can update them.\n",
    "* `accuracy_threshold`: This parameter represents the minimum accuracy that the model should reach in order for it to be registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f28a689-c5ca-4373-b615-2adba4f2664a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_approval_status = ParameterString(\n",
    "    name=\"model_approval_status\", \n",
    "    default_value=\"Approved\"\n",
    ")\n",
    "\n",
    "accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold\", \n",
    "    default_value=0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96fbc5-0647-49f1-817f-85c5477e91ab",
   "metadata": {},
   "source": [
    "## Step 2 - Configuring the Model Assets\n",
    "\n",
    "We need to specify the location of the model assets to register a model. We explored two different ways to create the model: a Training Step and a Tuning Step.\n",
    "\n",
    "Here we can configure the model assets based on whether we want to select the best model generated by the Tuning Step, or the model we trained using the Training Step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d6e6241-ebf7-4a02-b9eb-f30639b70f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the model data in case we want to use the best model generated\n",
    "# by the Tuning Step.\n",
    "tuning_model_data = tuning_step.get_top_model_s3_uri(\n",
    "    top_k=0, \n",
    "    s3_bucket=sagemaker_session.default_bucket()\n",
    ")\n",
    "\n",
    "# This is the model data in case we want to use the trained model\n",
    "# from the Training Step.\n",
    "training_model_data = training_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "# We can now select the appropriate model data depending on which step\n",
    "# we are using.\n",
    "model_data = tuning_model_data if USE_TUNING_STEP else training_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e705514-5931-4f36-9633-776c2305bf9a",
   "metadata": {},
   "source": [
    "## Step 3 - Configuring the Model\n",
    "\n",
    "The model we trained uses TensorFlow, so we can use one the built-in TensorFlow inference image to create a [Model](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fd8fa74-dda9-4509-bcd2-db7a30acce6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.4\",\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_data,\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a48e6-507d-42fb-8abc-ebde997e3d43",
   "metadata": {},
   "source": [
    "## Step 4 - Setting up the Model Metrics\n",
    "\n",
    "When we register a model, we can specify a set of [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics). We can use the evaluation report we generated during the Model \n",
    "Evaluation step to populate these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982146f-0c0f-4938-b5d0-06db45a58531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(on=\"\", values=[\n",
    "            evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'],\n",
    "            \"/evaluation.json\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441fac3a-5ecc-441f-84c3-717c4c7ba290",
   "metadata": {},
   "source": [
    "## Step 5 - Setting up a Model Step\n",
    "\n",
    "We can now create a [Model Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-model) to register the model. Check the [ModelStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.model_step.ModelStep) SageMaker's SDK documentation for more information. \n",
    "\n",
    "This step will use the Model we configured before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52a48cef-fb78-412b-a5c6-977eafe98e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:270: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_package_group_name = \"penguins-model-package-group\"\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=model.register(\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=\"2.4\",\n",
    "        # sample_payload_url=\"\",\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=model_approval_status,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c110f7-fe72-4db8-9d06-cfb9a0f2bfbd",
   "metadata": {},
   "source": [
    "## Step 6 - Setting up a Condition Step\n",
    "\n",
    "We only want to register a new model if its accuracy is above a predefined threshold. We can use a [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) to accomplish this. Check the [ConditionStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#conditionstep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "In this example we are going to use a [ConditionGreaterThanOrEqualTo](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.conditions.ConditionGreaterThanOrEqualTo) condition to compare the model's accuracy with the threshold. Take a look at the [Conditions](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html#conditions) section in the documentation for more information about the types of supported conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36e2a2b1-6711-4266-95d8-d2aebd52e199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can get the model accuracy directly from the evaluation\n",
    "# report property file.\n",
    "condition_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\"\n",
    "    ),\n",
    "    right=accuracy_threshold\n",
    ")\n",
    "\n",
    "# If the condition succeeds, we can call the Model Step.\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309b8fa-f03e-4959-853f-dc2416f82bdd",
   "metadata": {},
   "source": [
    "## Step 7 - Running the Pipeline\n",
    "\n",
    "We can now add the registration of the model to the pipeline. Notice how we add the condition step, which will call the Model Step if the condition passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f70bcd33-b499-4e2b-953e-94d1ed96c10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        evaluation_destination,\n",
    "        model_approval_status,\n",
    "        accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        tuning_step if USE_TUNING_STEP else training_step, \n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45b01065-5ba4-4c5c-9735-859b5234614a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PIPELINE == \"DEPLOYMENT\":\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502a7e9-e6fa-4706-8294-7abd51f85d07",
   "metadata": {},
   "source": [
    "## Step 8 - Loading the Latest Approved Model\n",
    "\n",
    "Now that we registered the model, we can load the latest approved model from the Model Registry to deploy it to an endpoint.\n",
    "\n",
    "We can use `boto3` to query the list of approved model packages and get the latest one that's been approved. Check the [boto3 SageMaker Client API](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html) for a list of every available method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff299800-7509-48b4-a343-e18ac4a30a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def get_latest_approved_model_package(model_package_group_name):\n",
    "    \"\"\"\n",
    "    Returns the latest approved model package registered under the \n",
    "    specified model package group.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # We can use the boto3 SageMaker's API to list the existing\n",
    "        # model packages with the specified name. We only care about\n",
    "        # approved models.\n",
    "        response = sagemaker_client.list_model_packages(\n",
    "            ModelPackageGroupName=model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            MaxResults=100,\n",
    "        )\n",
    "        approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "\n",
    "        # If we get a NextToken back, we need to deal with pagination.\n",
    "        while len(approved_packages) == 0 and \"NextToken\" in response:\n",
    "            response = sagemaker_client.list_model_packages(\n",
    "                ModelPackageGroupName=model_package_group_name,\n",
    "                ModelApprovalStatus=\"Approved\",\n",
    "                SortBy=\"CreationTime\",\n",
    "                MaxResults=100,\n",
    "                NextToken=response[\"NextToken\"],\n",
    "            )\n",
    "            approved_packages.extend(response[\"ModelPackageSummaryList\"])\n",
    "\n",
    "        if len(approved_packages) == 0:\n",
    "            print(f\"No approved model pacakages for \\\"{model_package_group_name}\\\"\")\n",
    "            return None\n",
    "\n",
    "        # At this point we identified the latest approved model,\n",
    "        # so we can return it.\n",
    "        print(f\"Latest approved model package: {approved_packages[0]['ModelPackageArn']}\")\n",
    "        return approved_packages[0]\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "        raise Exception(e.response[\"Error\"][\"Message\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3380addd-bb8c-4812-8120-fd97d13a7a4b",
   "metadata": {},
   "source": [
    "We can now use the `get_latest_approved_model_package()` function to get the latest approved model from the Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc6b8c80-aba9-40ce-99c8-ea7abe5f6f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest approved model package: arn:aws:sagemaker:us-east-1:325223348818:model-package/penguins-model-package-group/11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'penguins-model-package-group',\n",
       " 'ModelPackageVersion': 11,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:325223348818:model-package/penguins-model-package-group/11',\n",
       " 'CreationTime': datetime.datetime(2023, 4, 15, 12, 48, 23, 709000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '325223348818.dkr.ecr.us-east-1.amazonaws.com/penguins:latest',\n",
       "    'ImageDigest': 'sha256:5cdafa465bf301b4b083eec1696ced447d5adc126a7bbc1afc0bf37011e07b1f',\n",
       "    'ModelDataUrl': 's3://sagemaker-us-east-1-325223348818/penguins-2023-04-15-12-45-38-865/pipelines-vk9wv42955sy-register-custom-mode-p63e5Zz8WP/output/model.tar.gz',\n",
       "    'Environment': {'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "     'SAGEMAKER_PROGRAM': 'inference.py',\n",
       "     'SAGEMAKER_REGION': 'us-east-1',\n",
       "     'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'},\n",
       "    'Framework': 'TENSORFLOW',\n",
       "    'FrameworkVersion': '2.4'}],\n",
       "  'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.large'],\n",
       "  'SupportedContentTypes': ['application/json'],\n",
       "  'SupportedResponseMIMETypes': ['application/json']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'Approved',\n",
       " 'CreatedBy': {'IamIdentity': {'Arn': 'arn:aws:sts::325223348818:assumed-role/AmazonSageMaker-ExecutionRole-20230312T160501/sagemaker-pipeline-vk9wv42955sy-register-custom-mode',\n",
       "   'PrincipalId': 'AROAUXOGSPJJGTQ2RIUND:sagemaker-pipeline-vk9wv42955sy-register-custom-mode'}},\n",
       " 'MetadataProperties': {'GeneratedBy': 'arn:aws:sagemaker:us-east-1:325223348818:pipeline/penguins-pipeline/execution/vk9wv42955sy'},\n",
       " 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "    'S3Uri': 's3://mlschool/penguins/evaluation/evaluation.json'}},\n",
       "  'Bias': {},\n",
       "  'Explainability': {}},\n",
       " 'Domain': 'MACHINE_LEARNING',\n",
       " 'Task': 'CLASSIFICATION',\n",
       " 'ResponseMetadata': {'RequestId': 'e5dbb308-6150-4536-ab8e-91b6e877b712',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'e5dbb308-6150-4536-ab8e-91b6e877b712',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1752',\n",
       "   'date': 'Sat, 15 Apr 2023 12:53:10 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approved_model_package = get_latest_approved_model_package(model_package_group_name)\n",
    "model_description = None\n",
    "\n",
    "if approved_model_package:\n",
    "    approved_model_package_arn = approved_model_package[\"ModelPackageArn\"]\n",
    "\n",
    "    model_description = sagemaker_client.describe_model_package(\n",
    "        ModelPackageName=approved_model_package_arn\n",
    "    )\n",
    "\n",
    "model_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb161e-ee0a-468d-9af9-136ab91ea1db",
   "metadata": {},
   "source": [
    "## Step 9 - Deploying the Model\n",
    "\n",
    "We can now deploy the latest approved model to an endpoint if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "397f71c0-183c-4018-a563-4b4ac5dd7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_endpoint_exist(endpoint_name):\n",
    "    \"\"\"\n",
    "    Returns whether the supplied endpoint already exists.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b532d-aae8-4bf9-b60e-8a32c713fd2a",
   "metadata": {},
   "source": [
    "Using the arn of the model package from the Model Registry, we can deploy the model by creating a [ModelPackage](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.ModelPackage) instance and calling its `deploy()` method. The information of the model lives in the Model Registry so we don't need to specify anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4304fa43-3d56-4be6-ac47-cca95399c91e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "if PIPELINE == \"DEPLOYMENT\":\n",
    "    model_package = ModelPackage(\n",
    "        role=role, \n",
    "        model_package_arn=approved_model_package_arn, \n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "\n",
    "    endpoint_name = \"penguins-endpoint\"\n",
    "\n",
    "    if not does_endpoint_exist(endpoint_name):\n",
    "        model_package.deploy(\n",
    "            endpoint_name=endpoint_name,\n",
    "            initial_instance_count=1, \n",
    "            instance_type=\"ml.m5.large\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27605ac3-3127-437d-ae8c-faf7de305e2c",
   "metadata": {},
   "source": [
    "## Step 10 - Testing the Endpoint\n",
    "\n",
    "Using a [Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html#sagemaker.predictor.Predictor) from the endpoint name, we can test our model. Notice how the endpoint's interface expects the data to be transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a6861-86e1-4e97-8f69-db2bb6469eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PIPELINE == \"DEPLOYMENT\":\n",
    "    predictor = Predictor(endpoint_name=endpoint_name)\n",
    "\n",
    "    # The payload we need to provide the model is in CSV format. Notice how the model expects data that's\n",
    "    # already transformed. We can't provide the original data from our dataset because the model will not\n",
    "    # work with it.\n",
    "    payload = \"0.6569590202313976, -1.0813829646495108, 1.2097102831892812, 0.9226343641317372, 1.0, 0.0, 0.0\"\n",
    "    p = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "\n",
    "    # We can decode the output of the endpoint and print the \"predictions\" key.\n",
    "    predictions = json.loads(p.decode(\"utf-8\"))[\"predictions\"]\n",
    "    print(f\"Prediction: {np.argmax(predictions, axis=1)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4c712-4502-408a-a6d2-d5d9b4debedb",
   "metadata": {},
   "source": [
    "## Step 11 - Cleaning up\n",
    "\n",
    "Before you finish, don't forget to clean up after you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a5e01-face-4e06-abfc-5573a2d2b902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's delete every model we registered under our model package group\n",
    "for mp in sagemaker_client.list_model_packages(ModelPackageGroupName=model_package_group_name)[\"ModelPackageSummaryList\"]:\n",
    "    print(f\"Deleting {mp['ModelPackageArn']}\")\n",
    "    sagemaker_client.delete_model_package(ModelPackageName=mp[\"ModelPackageArn\"])\n",
    "\n",
    "# We can now delete the model package group.    \n",
    "sagemaker_client.delete_model_package_group(ModelPackageGroupName=model_package_group_name)\n",
    "\n",
    "# And finally we delete the endpoint and the pipeline.\n",
    "predictor.delete_endpoint()\n",
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d944aa-35ad-4f55-9852-667e27d4878a",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "1. Modify your pipeline to add a new [Lambda Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-lambda) that's only called if the model's accuracy is not above the specified threshold. What you decide to do in the Lambda function is not important.\n",
    "\n",
    "2. Modify your pipeline to add a new [Condition Step](#) that's called if the model's accuracy is not above the specified threshold. Set the condition to succeed if the accuracy is above 50%, in which case the model will be registered with a status of \"PendingManualApproval.\" If the accuracy is not greater or equal to 50%, the model shouldn't be registered. In summary, the model should be registered with status \"Approved\" if its accuracy is greater or equal to 75% and with status \"PendingManualApproval\" if its accuracy is greater or equal to 50%.\n",
    "\n",
    "3. Modify the payload that you send to the endpoint to classify multiple examples at once. Remember the payload is a CSV file, so you just need to add multiple lines to it.\n",
    "\n",
    "4. Modify the SageMaker Pipeline you created for the MNIST project and add a step to register the model. Create two separate conditions using the metrics from your evaluation step to decide whether you should register the model. Both conditions have to be true to register the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6b0ee-b369-4230-9cc0-a3b6f7b5d06f",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "1. To learn more about the Model Registry, check [Register and Deploy Models with Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html).\n",
    "\n",
    "2. Check [Update the Approval Status of a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-approve.html) for more information about the different approval status of a model and how you can update them.\n",
    "\n",
    "3. Check the [Model](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html) SageMaker's SDK documentation for more information about the class uses by SageMaker to represent a model you can register and deploy.\n",
    "\n",
    "4. Check the [ModelStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.model_step.ModelStep) SageMaker's SDK documentation. You can find an example of how to create a step to register a model in the [Model Step](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.model_step.ModelStep) page.\n",
    "\n",
    "5. Check the [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) SageMaker's SDK documentation for more information about the metrics you can register with a model.\n",
    "\n",
    "6. Check the [ConditionStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#conditionstep) SageMaker's SDK documentation. You can find an example of how to create a condition step the [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) page.\n",
    "\n",
    "7. Take a look at the [Conditions](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html#conditions) section in the documentation for more information about the types of supported conditions you can use in a pipeline.\n",
    "\n",
    "8. Check the [boto3 SageMaker Client API](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html) for a list of every available method.\n",
    "\n",
    "9. Check the [Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html#sagemaker.predictor.Predictor) SageMaker's SDK documentation for more information about connecting to an endpoint to run predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565cf77e-7fc7-406e-a2e2-40c553f459f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Session 5 - Custom Endpoints\n",
    "\n",
    "Deploying a model directly to an endpoint has a problem: we don't have any control over the input and output of the model inside the endpoint. Fortunately, SageMaker gives us the ability to include an `inference.py` file with the model assets from where we can control how the endpoint works.\n",
    "\n",
    "You can see more information about how this works by checking the [SageMaker TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container) documentation.\n",
    "\n",
    "In the previous session, we deployed a model to an endpoint that expects the input formatted in CSV format. Instead, we want an endpoint that expects JSON. Since this is a production endpoint, we want to ensure it supports unprocessed data, just as customers will send it. Remember that the endpoint we deployed requires the input data to be transformed before it can process it.\n",
    "\n",
    "Here is an example of the payload we want the endpoint to support:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"island\": \"Biscoe\",\n",
    "    \"culmen_length_mm\": 48.6,\n",
    "    \"culmen_depth_mm\": 16.0,\n",
    "    \"flipper_length_mm\": 230.0,\n",
    "    \"body_mass_g\": 5800.0,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8d585140-7940-4543-9954-b74352e8ff3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "from sagemaker.workflow.lambda_step import LambdaStep, LambdaOutput, LambdaOutputTypeEnum\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc27c6-31d4-454d-ae5b-1aeba25f0ac0",
   "metadata": {},
   "source": [
    "## Step 1 - Preparing the Inference Code\n",
    "\n",
    "Here is the inference code that we will include as part of the model assets to control the inference process on the SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "57e7ad9e-598b-4e28-9a20-a93ad2bb5f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/code/inference.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pickle import load\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "MODEL_DIRECTORY = Path(\"/opt/ml/model/\")\n",
    "\n",
    "\n",
    "def handler(data, context, model_directory=MODEL_DIRECTORY):\n",
    "    \"\"\"\n",
    "    This is the entrypoint that will be called by SageMaker when the endpoint\n",
    "    receives a request.\n",
    "    \n",
    "    You can see more information at https://github.com/aws/sagemaker-tensorflow-serving-container.\n",
    "    \"\"\"\n",
    "    print(\"Handling endpoint request\")\n",
    "    \n",
    "    instance = _process_input(data, context, model_directory)\n",
    "    output = _predict(instance, context)\n",
    "    return _process_output(output, context)\n",
    "\n",
    "\n",
    "def transform(payload, model_directory):\n",
    "    print(\"Transforming input data...\")\n",
    "    pipeline = load(open(model_directory / \"code\" / \"pipeline.pkl\", 'rb'))\n",
    "    \n",
    "    island = payload.get(\"island\", \"Biscoe\")\n",
    "    culmen_length_mm = payload.get(\"culmen_length_mm\", 0)\n",
    "    culmen_depth_mm = payload.get(\"culmen_depth_mm\", 0)\n",
    "    flipper_length_mm = payload.get(\"flipper_length_mm\", 0)\n",
    "    body_mass_g = payload.get(\"body_mass_g\", 0)\n",
    "    \n",
    "    data = pd.DataFrame(\n",
    "        columns=[\"island\", \"culmen_length_mm\", \"culmen_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"], \n",
    "        data=[[\n",
    "            island, \n",
    "            culmen_length_mm, \n",
    "            culmen_depth_mm, \n",
    "            flipper_length_mm, \n",
    "            body_mass_g\n",
    "        ]]\n",
    "    )\n",
    "    \n",
    "    result = pipeline.transform(data)\n",
    "    return result[0].tolist()\n",
    "    \n",
    "\n",
    "def _process_input(data, context, model_directory):\n",
    "    print(\"Processing input data...\")\n",
    "    \n",
    "    if context is None:\n",
    "        # The context will be None when we are testing the code\n",
    "        # directly from a notebook. In that case, we can use the\n",
    "        # data directly.\n",
    "        endpoint_input = data\n",
    "    elif context.request_content_type in (\"application/json\", \"application/octet-stream\"):\n",
    "        # When the endpoint is running, we will receive a context\n",
    "        # object. We need to parse the input and turn it into \n",
    "        # JSON in that case.\n",
    "        endpoint_input = json.loads(data.read().decode(\"utf-8\"))\n",
    "\n",
    "        if endpoint_input is None:\n",
    "            raise ValueError(\"There was an error parsing the input request.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {context.request_content_type or 'unknown'}\")\n",
    "        \n",
    "    return transform(endpoint_input, model_directory)\n",
    "\n",
    "\n",
    "def _predict(instance, context):\n",
    "    print(\"Sending input data to model to make a prediction...\")\n",
    "    \n",
    "    model_input = json.dumps({\"instances\": [instance]})\n",
    "    \n",
    "    if context is None:\n",
    "        # The context will be None when we are testing the code\n",
    "        # directly from a notebook. In that case, we want to return\n",
    "        # a fake prediction back.\n",
    "        result = {\n",
    "            \"predictions\": [\n",
    "                [0.2, 0.5, 0.3]\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        # When the endpoint is running, we will receive a context\n",
    "        # object. In that case we need to send the instance to the\n",
    "        # model to get a prediction back.\n",
    "        response = requests.post(context.rest_uri, data=model_input)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(response.content.decode('utf-8'))\n",
    "            \n",
    "        result = json.loads(response.content)\n",
    "    \n",
    "    print(f\"Response: {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def _process_output(output, context):\n",
    "    print(\"Processing prediction received from the model...\")\n",
    "    \n",
    "    response_content_type = \"application/json\" if context is None else context.accept_header\n",
    "    \n",
    "    prediction = np.argmax(output[\"predictions\"][0])\n",
    "    confidence = output[\"predictions\"][0][prediction]\n",
    "    \n",
    "    print(f\"Prediction: {prediction}. Confidence: {confidence}\")\n",
    "    \n",
    "    result = json.dumps({\n",
    "        \"prediction\": str(prediction),\n",
    "        \"confidence\": str(confidence)\n",
    "    }), response_content_type\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d1e463-61c1-4071-82d4-8e2c3ca49253",
   "metadata": {},
   "source": [
    "## Step 2 - Downloading the Scikit-Learn Pipeline\n",
    "\n",
    "The inference code uses the Scikit-Learn preprocessing pipeline to transform the input data before sending it to the model. We need to make the pickled preprocessing pipeline available to the endpoint. Since we uploaded it to S3 as an output from the Preprocessing Step, we can now download it and store it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5bada5fa-1a4a-4113-bde5-a40b2f4bb6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://mlschool/penguins/preprocessing/pipeline.pkl to container/code/pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# This is the location where we uploaded the pickled pipeline.\n",
    "preprocessing_pipeline = f\"{preprocessor_destination.default_value}/pipeline.pkl\"\n",
    "\n",
    "# Let's download the pipeline locally so we can test the inference code and \n",
    "# pack it with the model assets.\n",
    "!aws s3 cp $preprocessing_pipeline container/code/pipeline.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e7e63-39a8-4859-af1e-3e7b1573f9a2",
   "metadata": {},
   "source": [
    "## Step 3 - Testing the Inference Code\n",
    "\n",
    "Let's the test the inference code locally to make sure it works before deploying it. We can call the `handler()` function to test the inference code. This function is the entrypoint that will be called by SageMaker whenever the endpoint receives a request.\n",
    "\n",
    "When we are testing the inference code we want to set the `context` to None so the function recognizes we are calling it locally. We also want to set the `model_directory` to the place where we saved the Scikit-Learn pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a7aca49b-2080-4068-80e6-8b3f10e54177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling endpoint request\n",
      "Processing input data...\n",
      "Transforming input data...\n",
      "Sending input data to model to make a prediction...\n",
      "Response: {'predictions': [[0.2, 0.5, 0.3]]}\n",
      "Processing prediction received from the model...\n",
      "Prediction: 1. Confidence: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{\"prediction\": \"1\", \"confidence\": \"0.5\"}', 'application/json')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from container.code.inference import handler\n",
    "\n",
    "handler(\n",
    "    payload, \n",
    "    context=None, \n",
    "    model_directory=Path(\"container\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c13d26-e8aa-44ef-8b4e-9a947324c67a",
   "metadata": {},
   "source": [
    "## Step 4 - Creating a Custom Container\n",
    "\n",
    "Our inference code uses TensorFlow to make predictions and Scikit-Learn to transform the raw data before sending it to the model. Unfortunately, the built-in TensorFlow SageMaker inference image doesn't come with Scikit-Learn preinstalled. We can solve this problem in two ways:\n",
    "\n",
    "1. We could provide a `requirements.txt` file together with the `inference.py` file and SageMaker will install every library specified in that file.\n",
    "2. We could create a custom container and use it to deploy our model. This option is much more involved but useful if you want complete control over the endpoint.\n",
    "\n",
    "Creating a custom endpoint is much more fun, so let's do that.\n",
    "\n",
    "To create a custom endpoint we need to define the container using a Dockerfile, build it, and publish it in the [Amazon Elastic Container Registry](https://aws.amazon.com/ecr/) (ECR). Unfortunately, SageMaker Studio notebooks can't run the docker command, so we need to create a separate SageMaker Notebook Instance and run the [container/container.ipynb](container/container.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06398f4b-6a7e-4097-a230-ba80a9fc95e0",
   "metadata": {},
   "source": [
    "This is the Dockerfile that we'll use to create the custom image to deploy the model. Notice how this image inherits from a prebuilt TensorFlow Inference image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6174092d-725e-41ba-98b5-c26d8575b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/Dockerfile\n",
    "\n",
    "FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.4-cpu AS sagemaker\n",
    "\n",
    "RUN apt-get clean && \\\n",
    "    apt-get update -y && \\\n",
    "    apt-get install -y --no-install-recommends \\\n",
    "    libgl1-mesa-glx\n",
    "\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install pandas\n",
    "RUN pip install numpy\n",
    "RUN pip install requests\n",
    "RUN pip install tensorflow==2.4\n",
    "RUN pip install scikit-learn==0.23.2\n",
    "\n",
    "LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
    "ENV SAGEMAKER_MULTI_MODEL=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd95087f-794a-421b-9ca7-6f4c8f3d8669",
   "metadata": {},
   "source": [
    "## Step 5 - Building the Custom Container\n",
    "\n",
    "Create a SageMaker Notebook Instance, open the [container/container.ipynb](container/container.ipynb) notebook and run it. This notebook will store the custom image in the `/penguins:latest` ECR location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bf3e0e3c-4e85-41f7-a2ec-086d874a0b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'325223348818.dkr.ecr.us-east-1.amazonaws.com/penguins:latest'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caller_identify = !aws sts get-caller-identity --query 'Account' --output text\n",
    "account_id = caller_identify[0]\n",
    "\n",
    "CUSTOM_CONTAINER_IMAGE_URI = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/penguins:latest\"\n",
    "CUSTOM_CONTAINER_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed63f158-06f3-438b-b489-bb0496f2eddd",
   "metadata": {},
   "source": [
    "## Step 6 - Repacking and Registering the Model\n",
    "\n",
    "Let's register a new [Model](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html) using our custom container. We also need to make sure SageMaker repackages the model assets to include the `inference.py` and `pipeline.pkl` files.\n",
    "\n",
    "SageMaker triggers a repack when we specify the `Model.source_dir` attribute. We want that attribute to point to the local folder containing the files we want to include in the final package. SageMaker will automatically modify the original `model.tar.gz` package to include a `/code` folder containing the file in our local directory:\n",
    "\n",
    "```\n",
    "model/\n",
    "    |--[model_version_number]\n",
    "        |--assets/\n",
    "        |--variables/\n",
    "        |--saved_model.pb\n",
    "code/\n",
    "    |--inference.py\n",
    "    |--pipeline.pkl\n",
    "    |--requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "07513884-c7bd-4710-9730-f8ca7fe904a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:270: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Since we are specifying the `source_dir` attribute, SageMaker\n",
    "# will trigger a repack. This will create a new step in the \n",
    "# pipeline right before registering the model.\n",
    "custom_model = Model(\n",
    "    image_uri=CUSTOM_CONTAINER_IMAGE_URI,\n",
    "    model_data=model_data,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"container/code\",\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "register_custom_model_step = ModelStep(\n",
    "    name=\"register-custom-model\",\n",
    "    step_args=custom_model.register(\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=\"2.4\",\n",
    "        # sample_payload_url=\"\",\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=model_approval_status,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b60d5-6be3-428f-9979-4fe9eebfc5eb",
   "metadata": {},
   "source": [
    "## Step 7 - Preparing a Function to Deploy the Model\n",
    "\n",
    "In the previous session we registered the model as part of the pipeline, but deployed it manually. Instead, we can use a [Lambda Step](#) to automatically deploy the model.\n",
    "\n",
    "Let's start by writing the Lambda function that will take the model information and create a new endpoint hosting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "28c75afd-d0d0-47f4-b7b6-9d590c5b600e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/lambda.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    model_name = event[\"model_name\"]\n",
    "    endpoint_config_name = event[\"endpoint_config_name\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    role = event[\"role\"]\n",
    "    \n",
    "    sagemaker.create_model(\n",
    "        ModelName=model_name, \n",
    "        ExecutionRoleArn=role, \n",
    "        Containers=[{\n",
    "            \"ModelPackageName\": event[\"model_package_arn\"]\n",
    "        }] \n",
    "    )\n",
    "\n",
    "    sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"ModelName\": model_name,\n",
    "                \"InstanceType\": \"ml.m5.large\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sagemaker.create_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        EndpointConfigName=endpoint_config_name\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Endpoint deployed successfully\"),\n",
    "        \"model_name\": model_name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a4446-6db4-4515-bb1d-88ee21013bb2",
   "metadata": {},
   "source": [
    "## Step 8 - Creating a Role for the Lambda Function\n",
    "\n",
    "We need to create a new role to run the lambda function and give it access to SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f9941979-c085-4ef9-8c66-908378d89a91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iam = boto3.client('iam')\n",
    "\n",
    "def create_lambda_role(role_name):\n",
    "    try:\n",
    "        response = iam.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps({\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": \"lambda.amazonaws.com\"\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\"\n",
    "                    }\n",
    "                ]\n",
    "            }),\n",
    "            Description=\"Lambda Role\"\n",
    "        )\n",
    "\n",
    "        role_arn = response['Role']['Arn']\n",
    "\n",
    "        iam.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "        )\n",
    "\n",
    "        iam.attach_role_policy(\n",
    "            PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "            RoleName=role_name\n",
    "        )\n",
    "\n",
    "        return role_arn\n",
    "\n",
    "    except iam.exceptions.EntityAlreadyExistsException:\n",
    "        response = iam.get_role(RoleName=role_name)\n",
    "        return response['Role']['Arn']\n",
    "    \n",
    "\n",
    "lambda_role = create_lambda_role(\"lambda-deployment-role\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dcc96-2890-43ff-a6cd-f2a9969adc52",
   "metadata": {},
   "source": [
    "## Step 9 - Setting up the Lambda Step\n",
    "\n",
    "Let's now define the [LambdaStep](#) that will run the function we defined before.\n",
    "\n",
    "Notice how the Lambda Set uses the model information from the regisytration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7c6eda89-70f3-49b4-8983-90f4db72fd02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can use the current time to generate a unique signature\n",
    "# to generate new assets every time we deploy the model.\n",
    "signature = time.strftime(\"%m%d%H%M%S\", time.localtime())\n",
    "model_name = \"penguins-model-\" + signature\n",
    "endpoint_config_name = \"penguins-endpoint-config-\" + signature\n",
    "endpoint_name = \"penguins-endpoint-\" + signature\n",
    "lambda_function_name = \"deploy-endpoint-fn-\" + signature \n",
    "\n",
    "\n",
    "deploy_step = LambdaStep(\n",
    "    name=\"deploy\",\n",
    "    lambda_func=Lambda(\n",
    "        function_name=lambda_function_name,\n",
    "        execution_role_arn=lambda_role,\n",
    "        script=\"container/lambda.py\",\n",
    "        handler=\"lambda.lambda_handler\",\n",
    "        timeout=600,\n",
    "        memory_size=10240,\n",
    "    ),\n",
    "    inputs={\n",
    "        \"model_name\": model_name,\n",
    "        \"endpoint_config_name\": endpoint_config_name,\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"model_package_arn\": register_custom_model_step.properties.ModelPackageArn,\n",
    "        \"role\": role,\n",
    "    },\n",
    "    outputs=[\n",
    "        LambdaOutput(output_name=\"model_name\", output_type=LambdaOutputTypeEnum.String)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe2299-be2a-46a7-809e-6174d44abddb",
   "metadata": {},
   "source": [
    "## Step 10 - Setting up the Condition Step\n",
    "\n",
    "We only want to register a new model if its accuracy is above a predefined threshold. We can use a [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) to accomplish this. Check the [ConditionStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#conditionstep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "In this example we are going to use a [ConditionGreaterThanOrEqualTo](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.conditions.ConditionGreaterThanOrEqualTo) condition to compare the model's accuracy with the threshold. Take a look at the [Conditions](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html#conditions) section in the documentation for more information about the types of supported conditions.\n",
    "\n",
    "If the condition succeeds, we will register the model and deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "caacdde0-a65f-4225-8303-2b0106da1ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the condition succeeds, we can call the Model Step.\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[\n",
    "        register_custom_model_step, deploy_step\n",
    "    ],\n",
    "    else_steps=[], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade6d67c-6906-434d-9c41-17a4efeb38d2",
   "metadata": {},
   "source": [
    "## Step 11 - Running the Pipeline\n",
    "\n",
    "We can now use the new Condition Step and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d1969a5e-2ebf-474f-a275-ae0946c2fab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        evaluation_destination,\n",
    "        model_approval_status,\n",
    "        accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        tuning_step if USE_TUNING_STEP else training_step, \n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9e01390f-31a5-44b0-a9ea-2c4697a57aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    }
   ],
   "source": [
    "if PIPELINE == \"CUSTOM_ENDPOINT\":\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ca1b1-fdc6-4260-b6f7-ee3c6aab4e76",
   "metadata": {},
   "source": [
    "## Step 12 - Testing the Endpoint\n",
    "\n",
    "We can now create a [Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html) to test the endpoint. Notice how you can specify a serializer and a deserializer to have the predictor automatically serialize and deserialize the information to and from the endpoint.\n",
    "\n",
    "Check [Serializers](https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html) and [Deserializers](https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html) for a list of supported serializers and deserializers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "862118a0-c00b-4f5a-9374-68a94dbfbc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b98a7-2f36-4e4e-a277-c5172e5fbe51",
   "metadata": {
    "tags": []
   },
   "source": [
    "Running one example through the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8148ef38-92ed-4f9a-8024-69e2d9d6b5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': '0', 'confidence': '0.624125779'}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict({\n",
    "    \"island\": \"Dream\",\n",
    "    \"culmen_length_mm\": 46.4,\n",
    "    \"culmen_depth_mm\": 18.6,\n",
    "    \"flipper_length_mm\": 190.0,\n",
    "    \"body_mass_g\": 3450.0,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075ef4c-36a8-4c5d-88ef-2a3e49abdd51",
   "metadata": {},
   "source": [
    "Running another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2476337f-a39b-45d5-ab57-63567c3f0438",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': '2', 'confidence': '0.993786812'}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict({\n",
    "    \"island\": \"Biscoe\",\n",
    "    \"culmen_length_mm\": 48.6,\n",
    "    \"culmen_depth_mm\": 16.0,\n",
    "    \"flipper_length_mm\": 230.0,\n",
    "    \"body_mass_g\": 5800.0,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fcdcd-cc9e-4cf5-8da1-3dc73cb6b59a",
   "metadata": {},
   "source": [
    "## Step 13 - Cleaning up\n",
    "\n",
    "Before you finish, don't forget to clean up after you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0cf877e9-e1bc-40f0-acaa-64b6a5e6650f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '98e5442c-41f2-4fb2-b8ff-59fde66e64d4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '98e5442c-41f2-4fb2-b8ff-59fde66e64d4',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sat, 15 Apr 2023 17:19:37 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Let's delete every model we registered under our model package group\n",
    "# for mp in sagemaker_client.list_model_packages(ModelPackageGroupName=model_package_group_name)[\"ModelPackageSummaryList\"]:\n",
    "#     print(f\"Deleting {mp['ModelPackageArn']}\")\n",
    "#     sagemaker_client.delete_model_package(ModelPackageName=mp[\"ModelPackageArn\"])\n",
    "\n",
    "# # We can now delete the model package group.    \n",
    "# sagemaker_client.delete_model_package_group(ModelPackageGroupName=model_package_group_name)\n",
    "\n",
    "\n",
    "# predictor.delete_endpoint()\n",
    "\n",
    "\n",
    "# sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sagemaker_client.delete_model(ModelName=model_name)\n",
    "\n",
    "# pipeline.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd0716f-4bc8-4814-84cb-1d1a413939af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2547ea-7f79-43b6-abca-7b3d25361346",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "\n",
    "[SageMaker TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917fe920-172d-4b07-bd7d-b2ecea536319",
   "metadata": {},
   "source": [
    "# Session 6 - Model Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "748c47c5-71e6-4f76-9a8b-9a5f4716e806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.quality_check_step import DataQualityCheckConfig, QualityCheckStep, ModelQualityCheckConfig\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.model_monitor import DatasetFormat, model_monitoring\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.workflow.parameters import ParameterBoolean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938b5a9-0e8d-448a-bd30-ee61bcd90907",
   "metadata": {},
   "source": [
    "## Step 1 - Data Quality Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "eb805c2d-2aeb-494e-bd4f-dbb60753d990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_quality_skip_check = ParameterBoolean(\n",
    "    name=\"data_quality_skip_check\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "data_quality_register_new_baseline = ParameterBoolean(\n",
    "    name=\"data_quality_register_new_baseline\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "data_quality_supplied_baseline_statistics = ParameterString(\n",
    "    name=\"data_quality_supplied_baseline_statistics\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "data_quality_supplied_baseline_constraints = ParameterString(\n",
    "    name=\"data_quality_supplied_baseline_constraints\", \n",
    "    default_value=\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c26ac4-5d30-41e9-8952-e4deb39de819",
   "metadata": {},
   "source": [
    "## Step 2 - Setting up Data Quality Check Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "0b80bcab-d2c5-437c-a1c8-8eea208c0e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_job_config = CheckJobConfig(\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    instance_count=1,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    volume_size_in_gb=120,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "data_quality_check_config = DataQualityCheckConfig(\n",
    "    baseline_dataset=preprocess_step.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False, output_columns_position=\"START\"),\n",
    "    output_s3_uri=Join(on='/', values=['s3:/', BUCKET, \"monitor\", \"dataqualitycheckstep\"]),\n",
    ")\n",
    "\n",
    "data_quality_check_step = QualityCheckStep(\n",
    "    name=\"data-quality-check\",\n",
    "    skip_check=data_quality_skip_check,\n",
    "    register_new_baseline=data_quality_register_new_baseline,\n",
    "    quality_check_config=data_quality_check_config,\n",
    "    check_job_config=check_job_config,\n",
    "    supplied_baseline_statistics=data_quality_supplied_baseline_statistics,\n",
    "    supplied_baseline_constraints=data_quality_supplied_baseline_constraints,\n",
    "    model_package_group_name=model_package_group_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a24666-906e-4eba-8c7b-ab4db82f233a",
   "metadata": {},
   "source": [
    "## Step 3 - Model Quality Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "2eb811ae-599f-4379-bdcf-47d2e1c67e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_quality_skip_check = ParameterBoolean(\n",
    "    name=\"model_quality_skip_check\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "model_quality_register_new_baseline = ParameterBoolean(\n",
    "    name=\"model_quality_register_new_baseline\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "model_quality_supplied_baseline_statistics = ParameterString(\n",
    "    name=\"model_quality_supplied_baseline_statistics\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "model_quality_supplied_baseline_constraints = ParameterString(\n",
    "    name=\"model_quality_supplied_baseline_constraints\", \n",
    "    default_value=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fafc7c4-6fef-4832-8b99-8c45d078fdd2",
   "metadata": {},
   "source": [
    "## Step 4 - Setting up Model Quality Check Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9aa3a284-8763-4000-a263-70314b530652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_quality_check_config = ModelQualityCheckConfig(\n",
    "    baseline_dataset=model_data,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=Join(on='/', values=['s3:/', BUCKET, \"monitor\", \"modelqualitycheckstep\"]),\n",
    "    problem_type=\"Classification\",\n",
    "    inference_attribute=\"_c0\", # use auto-populated headers since we don't have headers in the dataset\n",
    "    ground_truth_attribute=\"_c1\", # use auto-populated headers since we don't have headers in the dataset\n",
    ")\n",
    "\n",
    "model_quality_check_step = QualityCheckStep(\n",
    "    name=\"model-quality-check\",\n",
    "    skip_check=model_quality_skip_check,\n",
    "    register_new_baseline=model_quality_register_new_baseline,\n",
    "    quality_check_config=model_quality_check_config,\n",
    "    check_job_config=check_job_config,\n",
    "    supplied_baseline_statistics=model_quality_supplied_baseline_statistics,\n",
    "    supplied_baseline_constraints=model_quality_supplied_baseline_constraints,\n",
    "    model_package_group_name=model_package_group_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693535ba-fca7-4e89-a4cb-b4f333fa2d03",
   "metadata": {},
   "source": [
    "## Step 5 - Setting up the Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "a773f134-ac2f-4dba-976e-9b7f0b384b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(on=\"\", values=[\n",
    "            evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'],\n",
    "            \"/evaluation.json\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    \n",
    "    # model_statistics=MetricsSource(\n",
    "    #     s3_uri=model_quality_check_step.properties.CalculatedBaselineStatistics,\n",
    "    #     content_type=\"application/json\",\n",
    "    # ),\n",
    "    \n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c7f19-6d15-4fd2-8616-50459ee46415",
   "metadata": {},
   "source": [
    "## Step 6 - Setting up the Drift Check Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "8302f356-97f3-4325-9a9a-6a0712de9133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drift_check_baselines = DriftCheckBaselines(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3487a0-05ad-4f3a-8f50-9884dc2aef64",
   "metadata": {},
   "source": [
    "## Step 7 - Setting up a Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "7056a009-91c0-4955-90dd-b90ef8cab149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=custom_model.register(\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=\"2.4\",\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        drift_check_baselines=drift_check_baselines,\n",
    "        approval_status=model_approval_status,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00b5e6-9858-4acc-bbfe-a2ce24ec20e0",
   "metadata": {},
   "source": [
    "## Step 8 - Setting up the Condition Step\n",
    "\n",
    "We only want to register a new model if its accuracy is above a predefined threshold. We can use a [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) to accomplish this. Check the [ConditionStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#conditionstep) SageMaker's SDK documentation for more information.\n",
    "\n",
    "In this example we are going to use a [ConditionGreaterThanOrEqualTo](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.conditions.ConditionGreaterThanOrEqualTo) condition to compare the model's accuracy with the threshold. Take a look at the [Conditions](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_building_pipeline.html#conditions) section in the documentation for more information about the types of supported conditions.\n",
    "\n",
    "If the condition succeeds, we will register the model and deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "bacaa9c6-22b0-48df-b138-95b6422fe834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[\n",
    "        register_model_step, deploy_step\n",
    "    ],\n",
    "    else_steps=[], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a7905-2550-4979-b885-f2daabb5d45e",
   "metadata": {},
   "source": [
    "## Step 9 - Running the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "4da5e453-acd8-47a0-a39f-264d05dd93d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        data_quality_skip_check,\n",
    "        data_quality_register_new_baseline,\n",
    "        data_quality_supplied_baseline_statistics,\n",
    "        data_quality_supplied_baseline_constraints,\n",
    "        model_quality_skip_check,\n",
    "        model_quality_register_new_baseline,\n",
    "        model_quality_supplied_baseline_statistics,\n",
    "        model_quality_supplied_baseline_constraints,\n",
    "        evaluation_destination,\n",
    "        model_approval_status,\n",
    "        accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        data_quality_check_step,\n",
    "        tuning_step if USE_TUNING_STEP else training_step, \n",
    "        model_quality_check_step,\n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b54dbf6e-9b52-41a6-bec3-91c56536b3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b03e4-0a45-4d28-8d55-3f8d17c85574",
   "metadata": {},
   "source": [
    "## Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d007635-494f-498d-8856-4553878905d4",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a22752c-ac52-406c-ae30-faf7fd2ebd27",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "* [SageMaker Inference Toolkit](https://github.com/aws/sagemaker-inference-toolkit)\n",
    "* [Amazon SageMaker Model Monitor](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a625a-7dba-4e77-a572-7198f18ef399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
