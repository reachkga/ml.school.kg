{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The content\n",
    "\n",
    "1. Set up dev environment / MLFlow / Outerbounds\n",
    "\n",
    "1. High-level overview of the Training Pipeline\n",
    "\n",
    "1. Introduction to Metaflow\n",
    "    1. Create a sample metaflow flow \n",
    "    1. Explain how to run it from the command line and from a notebook\n",
    "    1. Metaflow: @project\n",
    "    1. Metaflow: pypi/conda - How do they work\n",
    "\n",
    "1. Integrating Metaflow and MLFlow\n",
    "    1. Step: start\n",
    "    1. Metaflow: Artifacts\n",
    "    1. Metaflow: Cards\n",
    "    1. Metaflow: importing libraries within a step\n",
    "\n",
    "1. Loading the data\n",
    "    1. Step: load\n",
    "    1. Metaflow: Parameters\n",
    "    1. Metaflow: IncludeFile\n",
    "    1. Metaflow: S3 class\n",
    "    1. Metaflow: Retry\n",
    "    1. Metaflow: Branches\n",
    "\n",
    "1. Using cross-validation to train a model\n",
    "    1. Step: cross_validation\n",
    "    1. Metaflow: foreach\n",
    "    1. Why cross-validation? Compare with train-test split\n",
    "    1. Break down the general structure of a cross-validation process\n",
    "\n",
    "1. Transforming the data\n",
    "    1. Step: transform_fold\n",
    "    1. Scikit-learn transformation pipelines\n",
    "    1. Imputation\n",
    "    1. Scaling\n",
    "    1. Encoding (one-hot, label)\n",
    "\n",
    "1. Training a model\n",
    "    1. Step: train_model_fold\n",
    "    1. Metaflow: Environment variables\n",
    "    1. MLFlow: Experiment tracking\n",
    "    1. MLFlow: Parent runs and child runs\n",
    "    1. MLFlow: auto-logging\n",
    "    1. Using Keras with different backends\n",
    "    1. Model architecture, loss function, optimizer\n",
    "\n",
    "1. Evaluating the model\n",
    "    1. Step: evaluate_model_fold\n",
    "    1. MLFlow: Logging metrics \n",
    "\n",
    "1. Final model evaluation\n",
    "    1. Step: evaluate_model\n",
    "    1. Metaflow: Merging artifacts\n",
    "    1. Why do we need this step as part of cross-validation?\n",
    "\n",
    "1. Transforming the entire dataset\n",
    "    1. Step: transform_dataset\n",
    "    1. Why do we need this step?\n",
    "\n",
    "1. Training the final model\n",
    "    1. Step: train_model\n",
    "    1. Why do we need this step?\n",
    "\n",
    "1. Hyperparameter tuning\n",
    "    1. Keras Tuner\n",
    "\n",
    "1. Introduction to model versioning\n",
    "    1. Step: register_model\n",
    "    1. Metaflow: Conditional execution of a step\n",
    "    1. MLFlow: Model registry\n",
    "    1. MLFlow: log_model\n",
    "\n",
    "1. Building a custom inference process\n",
    "    1. MLFlow: Subclassing PythonModel\n",
    "    1. Why do we need a custom inference process?\n",
    "    1. Running     \n",
    "\n",
    "1. Deploying the model\n",
    "    1. MLFlow: Deploying the model locally\n",
    "    1. Loading the latest model from Model Registry\n",
    "    1. Deploying the model to a SageMaker Endpoint\n",
    "    1. Deploying the model to Azure\n",
    "    1. Deploying the model to GCP\n",
    "\n",
    "1. Running a Production Pipeline in the Cloud\n",
    "    1. Running on AWS Batch\n",
    "    1. Running on Kubernetes\n",
    "    1. Metaflow: @resources (Requesting compute resources)\n",
    "    1. Mixing cloud environments\n",
    "\n",
    "1. Scheduling Pipelines\n",
    "    1. Scheduling with AWS Step Functions\n",
    "    1. Scheduling with Argo Workflows\n",
    "    \n",
    "1. Setting up monitoring\n",
    "\n",
    "1. Connecting Flows via Events\n",
    "\n",
    "\n",
    "### Bonus lessons\n",
    "1. Build an EDA flow that includes the code I wrote to explore the penguins dataset\n",
    "1. Multi-user worlkflows using @project decorator in Outerbounds\n",
    "1. Shadow deployments\n",
    "1. Active Learning example\n",
    "1. Knowledge distillation example\n",
    "1. Model compression example\n",
    "1. Test-time augmentation example\n",
    "1. Adversarial validation example\n",
    "1. Human-in-the-loop example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(exist_ok=True)\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/load.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/load.py\n",
    "\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from metaflow import S3\n",
    "\n",
    "\n",
    "def load_data_from_s3(location: str):\n",
    "    \"\"\"Load the dataset from an S3 location.\n",
    "\n",
    "    This function will concatenate every CSV file in the given location\n",
    "    and return a single DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset from location {location}\")\n",
    "\n",
    "    with S3(s3root=location) as s3:\n",
    "        files = s3.get_all()\n",
    "\n",
    "        print(f\"Found {len(files)} file(s) in remote location\")\n",
    "\n",
    "        raw_data = [pd.read_csv(StringIO(file.text)) for file in files]\n",
    "        return pd.concat(raw_data)\n",
    "\n",
    "\n",
    "def load_data_from_file(dataset_location):\n",
    "    \"\"\"Load the dataset from a local file.\n",
    "\n",
    "    This function is useful to test the pipeline locally\n",
    "    without having to access the data remotely.\n",
    "    \"\"\"\n",
    "    location = Path(dataset_location)\n",
    "    print(f\"Loading dataset from location {location.as_posix()}\")\n",
    "    return pd.read_csv(location)\n",
    "\n",
    "\n",
    "def load_data(dataset_location, debug=False):\n",
    "    if debug:\n",
    "        df = load_data_from_file(dataset_location)\n",
    "    else:\n",
    "        df = load_data_from_s3(dataset_location)\n",
    "\n",
    "    # Shuffle the data\n",
    "    data = df.sample(frac=1, random_state=42)\n",
    "\n",
    "    print(f\"Loaded dataset with {len(data)} samples\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from location ../penguins.csv\n",
      "Loaded dataset with 344 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>196.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>45.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>198.0</td>\n",
       "      <td>3950.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4550.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>45.2</td>\n",
       "      <td>16.6</td>\n",
       "      <td>191.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>48.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>203.0</td>\n",
       "      <td>4625.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>47.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.7</td>\n",
       "      <td>18.4</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>38.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>199.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>37.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species     island  culmen_length_mm  culmen_depth_mm  \\\n",
       "194  Chinstrap      Dream              50.9             19.1   \n",
       "157  Chinstrap      Dream              45.2             17.8   \n",
       "225     Gentoo     Biscoe              46.5             13.5   \n",
       "208  Chinstrap      Dream              45.2             16.6   \n",
       "318     Gentoo     Biscoe              48.4             14.4   \n",
       "..         ...        ...               ...              ...   \n",
       "188  Chinstrap      Dream              47.6             18.3   \n",
       "71      Adelie  Torgersen              39.7             18.4   \n",
       "106     Adelie     Biscoe              38.6             17.2   \n",
       "270     Gentoo     Biscoe              46.6             14.2   \n",
       "102     Adelie     Biscoe              37.7             16.0   \n",
       "\n",
       "     flipper_length_mm  body_mass_g     sex  \n",
       "194              196.0       3550.0    MALE  \n",
       "157              198.0       3950.0  FEMALE  \n",
       "225              210.0       4550.0  FEMALE  \n",
       "208              191.0       3250.0  FEMALE  \n",
       "318              203.0       4625.0  FEMALE  \n",
       "..                 ...          ...     ...  \n",
       "188              195.0       3850.0  FEMALE  \n",
       "71               190.0       3900.0    MALE  \n",
       "106              199.0       3750.0  FEMALE  \n",
       "270              210.0       4850.0  FEMALE  \n",
       "102              183.0       3075.0  FEMALE  \n",
       "\n",
       "[344 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load import load_data\n",
    "\n",
    "data = load_data(\"../penguins.csv\", debug=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session X - Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.12.3 executing TrainingFlow for user:svpino\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint not found, so extra checks are disabled.\n",
      "Bootstrapping virtual environment(s) ...\n",
      "Virtual environment(s) bootstrapped!\n",
      "2024-07-29 11:07:23.354 Workflow starting (run-id 1722265643352845):\n",
      "2024-07-29 11:07:23.385 [1722265643352845/start/1 (pid 37577)] Task is starting.\n",
      "2024-07-29 11:07:23.526 [1722265643352845/start/1 (pid 37577)] Task finished successfully.\n",
      "2024-07-29 11:07:23.553 [1722265643352845/load_data/2 (pid 37582)] Task is starting.\n",
      "2024-07-29 11:07:23.820 [1722265643352845/load_data/2 (pid 37582)] Loading dataset from location ../../penguins.csv\n",
      "2024-07-29 11:07:23.821 [1722265643352845/load_data/2 (pid 37582)] Loaded dataset with 344 samples\n",
      "2024-07-29 11:07:23.824 [1722265643352845/load_data/2 (pid 37582)] species  island  ...  body_mass_g     sex\n",
      "2024-07-29 11:07:23.861 [1722265643352845/load_data/2 (pid 37582)] 194  Chinstrap   Dream  ...       3550.0    MALE\n",
      "2024-07-29 11:07:23.861 [1722265643352845/load_data/2 (pid 37582)] 157  Chinstrap   Dream  ...       3950.0  FEMALE\n",
      "2024-07-29 11:07:23.861 [1722265643352845/load_data/2 (pid 37582)] 225     Gentoo  Biscoe  ...       4550.0  FEMALE\n",
      "2024-07-29 11:07:23.861 [1722265643352845/load_data/2 (pid 37582)] 208  Chinstrap   Dream  ...       3250.0  FEMALE\n",
      "2024-07-29 11:07:23.861 [1722265643352845/load_data/2 (pid 37582)] 318     Gentoo  Biscoe  ...       4625.0  FEMALE\n",
      "2024-07-29 11:07:23.861 [1722265643352845/load_data/2 (pid 37582)] \n",
      "2024-07-29 11:07:23.861 [1722265643352845/load_data/2 (pid 37582)] [5 rows x 7 columns]\n",
      "2024-07-29 11:07:23.862 [1722265643352845/load_data/2 (pid 37582)] Task finished successfully.\n",
      "2024-07-29 11:07:23.891 [1722265643352845/end/3 (pid 37597)] Task is starting.\n",
      "2024-07-29 11:07:24.025 [1722265643352845/end/3 (pid 37597)] the end\n",
      "2024-07-29 11:07:24.045 [1722265643352845/end/3 (pid 37597)] Task finished successfully.\n",
      "2024-07-29 11:07:24.046 Done!\n"
     ]
    }
   ],
   "source": [
    "from metaflow import FlowSpec, NBRunner, step, pypi\n",
    "\n",
    "\n",
    "class TrainingFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.load_data)\n",
    "\n",
    "    @pypi(packages={\"pandas\": \"2.2.2\"})\n",
    "    @step\n",
    "    def load_data(self):\n",
    "        from load import load_data\n",
    "\n",
    "        data = load_data(\"../../penguins.csv\", debug=True)\n",
    "        print(data.head())\n",
    "\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"the end\")\n",
    "\n",
    "\n",
    "run = NBRunner(TrainingFlow, base_dir=\"code\", environment=\"pypi\").nbrun()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session X - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.12.3 executing TrainingFlow for user:svpino\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint not found, so extra checks are disabled.\n",
      "Bootstrapping virtual environment(s) ...\n",
      "Virtual environment(s) bootstrapped!\n",
      "2024-07-29 11:09:38.478 Workflow starting (run-id 1722265778477383):\n",
      "2024-07-29 11:09:38.510 [1722265778477383/start/1 (pid 38366)] Task is starting.\n",
      "2024-07-29 11:09:38.657 [1722265778477383/start/1 (pid 38366)] Task finished successfully.\n",
      "2024-07-29 11:09:38.683 [1722265778477383/load_data/2 (pid 38371)] Task is starting.\n",
      "2024-07-29 11:09:38.944 [1722265778477383/load_data/2 (pid 38371)] Loading dataset from location ../../penguins.csv\n",
      "2024-07-29 11:09:38.946 [1722265778477383/load_data/2 (pid 38371)] Loaded dataset with 344 samples\n",
      "2024-07-29 11:09:38.949 [1722265778477383/load_data/2 (pid 38371)] species  island  ...  body_mass_g     sex\n",
      "2024-07-29 11:09:38.986 [1722265778477383/load_data/2 (pid 38371)] 194  Chinstrap   Dream  ...       3550.0    MALE\n",
      "2024-07-29 11:09:38.986 [1722265778477383/load_data/2 (pid 38371)] 157  Chinstrap   Dream  ...       3950.0  FEMALE\n",
      "2024-07-29 11:09:38.986 [1722265778477383/load_data/2 (pid 38371)] 225     Gentoo  Biscoe  ...       4550.0  FEMALE\n",
      "2024-07-29 11:09:38.986 [1722265778477383/load_data/2 (pid 38371)] 208  Chinstrap   Dream  ...       3250.0  FEMALE\n",
      "2024-07-29 11:09:38.986 [1722265778477383/load_data/2 (pid 38371)] 318     Gentoo  Biscoe  ...       4625.0  FEMALE\n",
      "2024-07-29 11:09:38.986 [1722265778477383/load_data/2 (pid 38371)] \n",
      "2024-07-29 11:09:38.986 [1722265778477383/load_data/2 (pid 38371)] [5 rows x 7 columns]\n",
      "2024-07-29 11:09:38.987 [1722265778477383/load_data/2 (pid 38371)] Task finished successfully.\n",
      "2024-07-29 11:09:39.015 [1722265778477383/end/3 (pid 38376)] Task is starting.\n",
      "2024-07-29 11:09:39.146 [1722265778477383/end/3 (pid 38376)] the end\n",
      "2024-07-29 11:09:39.167 [1722265778477383/end/3 (pid 38376)] Task finished successfully.\n",
      "2024-07-29 11:09:39.168 Done!\n"
     ]
    }
   ],
   "source": [
    "from metaflow import FlowSpec, NBRunner, step, pypi\n",
    "\n",
    "\n",
    "class TrainingFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.load_data)\n",
    "\n",
    "    @pypi(packages={\"pandas\": \"2.2.2\"})\n",
    "    @step\n",
    "    def load_data(self):\n",
    "        from load import load_data\n",
    "\n",
    "        data = load_data(\"../../penguins.csv\", debug=True)\n",
    "        print(data.head())\n",
    "\n",
    "        self.next(self.cross_validation)\n",
    "\n",
    "    @step\n",
    "    def cross_validation(self):\n",
    "        from sklearn.model_selection import KFold\n",
    "\n",
    "        kfold = KFold(n_splits=5, shuffle=True)\n",
    "        self.folds = list(enumerate(kfold.split(self.species, self.data)))\n",
    "\n",
    "        self.next(self.transform_fold, foreach=\"folds\")\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"the end\")\n",
    "\n",
    "\n",
    "run = NBRunner(TrainingFlow, base_dir=\"code\", environment=\"pypi\").nbrun()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version: 1\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "latest_model_version = client.search_model_versions(\n",
    "    \"name='penguins'\",\n",
    "    max_results=1,\n",
    "    order_by=[\"last_updated_timestamp DESC\"],\n",
    ")[0]\n",
    "print(f\"Model version: {latest_model_version.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:03 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - scikit-learn (current: 1.4.2, required: scikit-learn==1.5.1)\n",
      " - keras (current: 3.3.0, required: keras==3.5.0)\n",
      " - jax (current: 0.4.26, required: jax[cpu]==0.4.31)\n",
      " - packaging (current: 24.0, required: packaging==24.1)\n",
      " - mlflow (current: 2.12.1, required: mlflow==2.15.1)\n",
      " - setuptools (current: 65.5.0, required: setuptools==72.1.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "/Users/svpino/dev/ml.school/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.5.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/svpino/dev/ml.school/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/svpino/dev/ml.school/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/svpino/dev/ml.school/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.5.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/svpino/dev/ml.school/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.5.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/svpino/dev/ml.school/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "model = mlflow.pyfunc.load_model(latest_model_version.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"../penguins.csv\")\n",
    "data.pop(\"species\")\n",
    "data[\"sex\"] = data[\"sex\"].replace(\".\", np.nan)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def nan_to_none(value):\n",
    "    return None if pd.isna(value) else value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:24 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:24 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:24 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:25 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/03 11:57:26 WARNING mlflow.pyfunc: The underlying model does not support passing additional parameters to the predict function. `params` {'data_capture': True} will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step\n"
     ]
    }
   ],
   "source": [
    "std_dev = data[\"body_mass_g\"].std()\n",
    "\n",
    "# Add random noise within 3 standard deviations to body_mass_g\n",
    "rng = np.random.default_rng()\n",
    "data[\"body_mass_g\"] += rng.uniform(1, 3 * std_dev, size=len(data))\n",
    "\n",
    "for _, row in data[0:200].iterrows():\n",
    "    payload = {k: nan_to_none(v) for k, v in row.to_dict().items()}\n",
    "    prediction = model.predict(payload, params={\"data_capture\": True})\n",
    "    # print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import random\n",
    "\n",
    "connection = sqlite3.connect(\"penguins.db\")\n",
    "\n",
    "query = \"SELECT * FROM data\"\n",
    "df = pd.read_sql_query(query, connection)\n",
    "\n",
    "# Update the species column\n",
    "for index, row in df.iterrows():\n",
    "    if random.random() < 0.9:\n",
    "        # 90% of the time, set species to prediction\n",
    "        species = row[\"prediction\"]\n",
    "    else:\n",
    "        # 10% of the time, set species to a random value\n",
    "        species = random.choice([\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "\n",
    "    # Update the database\n",
    "    update_query = \"UPDATE data SET species = ? WHERE rowid = ?\"\n",
    "    connection.execute(update_query, (species, index + 1))\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()\n",
    "\n",
    "# Close the connection\n",
    "connection.close()\n",
    "\n",
    "print(\"Database updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.12.3 executing TrainingFlow for user:svpino\n",
      "Project: penguins, Branch: user.svpino\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint not found, so extra checks are disabled.\n",
      "Bootstrapping virtual environment(s) ...\n",
      "Virtual environment(s) bootstrapped!\n",
      "2024-07-30 11:45:45.292 Workflow starting (run-id 1722354345288526):\n",
      "2024-07-30 11:45:45.328 [1722354345288526/start/1 (pid 87120)] Task is starting.\n",
      "2024-07-30 11:45:45.996 [1722354345288526/start/1 (pid 87120)] Running flow in development mode.\n",
      "2024-07-30 11:45:46.130 [1722354345288526/start/1 (pid 87120)] Task finished successfully.\n",
      "2024-07-30 11:45:46.161 [1722354345288526/load_data/2 (pid 87130)] Task is starting.\n",
      "2024-07-30 11:45:46.756 [1722354345288526/load_data/2 (pid 87130)] Loading dataset from location ../penguins.csv\n",
      "2024-07-30 11:45:46.757 [1722354345288526/load_data/2 (pid 87130)] Loaded dataset with 344 samples\n",
      "2024-07-30 11:45:46.825 [1722354345288526/load_data/2 (pid 87130)] Loaded dataset with 344 samples\n",
      "2024-07-30 11:45:46.826 [1722354345288526/load_data/2 (pid 87130)] Task finished successfully.\n",
      "2024-07-30 11:45:46.860 [1722354345288526/prepare_dataset/3 (pid 87139)] Task is starting.\n",
      "2024-07-30 11:45:47.511 [1722354345288526/prepare_dataset/3 (pid 87139)] Task finished successfully.\n",
      "2024-07-30 11:45:47.549 [1722354345288526/cross_validation/4 (pid 87155)] Task is starting.\n",
      "2024-07-30 11:45:48.461 [1722354345288526/cross_validation/4 (pid 87155)] Foreach yields 5 child steps.\n",
      "2024-07-30 11:45:48.461 [1722354345288526/cross_validation/4 (pid 87155)] Task finished successfully.\n",
      "2024-07-30 11:45:48.492 [1722354345288526/transform/5 (pid 87160)] Task is starting.\n",
      "2024-07-30 11:45:49.413 [1722354345288526/transform/5 (pid 87160)] Task finished successfully.\n",
      "2024-07-30 11:45:49.446 [1722354345288526/transform_fold/6 (pid 87179)] Task is starting.\n",
      "2024-07-30 11:45:50.341 [1722354345288526/transform_fold/6 (pid 87179)] Task finished successfully.\n",
      "2024-07-30 11:45:50.373 [1722354345288526/transform_fold/7 (pid 87189)] Task is starting.\n",
      "2024-07-30 11:45:51.285 [1722354345288526/transform_fold/7 (pid 87189)] Task finished successfully.\n",
      "2024-07-30 11:45:51.316 [1722354345288526/transform_fold/8 (pid 87204)] Task is starting.\n",
      "2024-07-30 11:45:52.238 [1722354345288526/transform_fold/8 (pid 87204)] Task finished successfully.\n",
      "2024-07-30 11:45:52.269 [1722354345288526/transform_fold/9 (pid 87209)] Task is starting.\n",
      "2024-07-30 11:45:53.185 [1722354345288526/transform_fold/9 (pid 87209)] Task finished successfully.\n",
      "2024-07-30 11:45:53.216 [1722354345288526/transform_fold/10 (pid 87224)] Task is starting.\n",
      "2024-07-30 11:45:54.125 [1722354345288526/transform_fold/10 (pid 87224)] Task finished successfully.\n",
      "2024-07-30 11:45:54.156 [1722354345288526/train_model_fold/11 (pid 87229)] Task is starting.\n",
      "2024-07-30 11:45:54.774 [1722354345288526/train_model_fold/11 (pid 87229)] Training fold 0...\n",
      "2024-07-30 11:45:55.132 [1722354345288526/train_model_fold/11 (pid 87229)] 2024/07/30 11:45:55 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2024-07-30 11:45:58.079 [1722354345288526/train_model_fold/11 (pid 87229)] Task finished successfully.\n",
      "2024-07-30 11:45:58.110 [1722354345288526/train_model_fold/12 (pid 87268)] Task is starting.\n",
      "2024-07-30 11:45:58.671 [1722354345288526/train_model_fold/12 (pid 87268)] Training fold 1...\n",
      "2024-07-30 11:45:59.021 [1722354345288526/train_model_fold/12 (pid 87268)] 2024/07/30 11:45:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2024-07-30 11:46:01.964 [1722354345288526/train_model_fold/12 (pid 87268)] Task finished successfully.\n",
      "2024-07-30 11:46:02.010 [1722354345288526/train_model_fold/13 (pid 87302)] Task is starting.\n",
      "2024-07-30 11:46:02.609 [1722354345288526/train_model_fold/13 (pid 87302)] Training fold 2...\n",
      "2024-07-30 11:46:02.952 [1722354345288526/train_model_fold/13 (pid 87302)] 2024/07/30 11:46:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2024-07-30 11:46:05.932 [1722354345288526/train_model_fold/13 (pid 87302)] Task finished successfully.\n",
      "2024-07-30 11:46:05.963 [1722354345288526/train_model_fold/14 (pid 87335)] Task is starting.\n",
      "2024-07-30 11:46:06.517 [1722354345288526/train_model_fold/14 (pid 87335)] Training fold 3...\n",
      "2024-07-30 11:46:06.859 [1722354345288526/train_model_fold/14 (pid 87335)] 2024/07/30 11:46:06 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2024-07-30 11:46:09.771 [1722354345288526/train_model_fold/14 (pid 87335)] Task finished successfully.\n",
      "2024-07-30 11:46:09.802 [1722354345288526/train_model_fold/15 (pid 87368)] Task is starting.\n",
      "2024-07-30 11:46:10.375 [1722354345288526/train_model_fold/15 (pid 87368)] Training fold 4...\n",
      "2024-07-30 11:46:10.716 [1722354345288526/train_model_fold/15 (pid 87368)] 2024/07/30 11:46:10 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2024-07-30 11:46:13.649 [1722354345288526/train_model_fold/15 (pid 87368)] Task finished successfully.\n",
      "2024-07-30 11:46:13.681 [1722354345288526/evaluate_model_fold/16 (pid 87401)] Task is starting.\n",
      "2024-07-30 11:46:14.220 [1722354345288526/evaluate_model_fold/16 (pid 87401)] Evaluating fold 0...\n",
      "2024-07-30 11:46:14.885 [1722354345288526/evaluate_model_fold/16 (pid 87401)] 3/3 - 0s - 47ms/step - accuracy: 0.9710 - loss: 0.3564\n",
      "2024-07-30 11:46:14.892 [1722354345288526/evaluate_model_fold/16 (pid 87401)] Fold 0 - loss: 0.35639306902885437 - accuracy: 0.9710144996643066\n",
      "2024-07-30 11:46:15.014 [1722354345288526/evaluate_model_fold/16 (pid 87401)] Task finished successfully.\n",
      "2024-07-30 11:46:15.046 [1722354345288526/evaluate_model_fold/17 (pid 87407)] Task is starting.\n",
      "2024-07-30 11:46:15.644 [1722354345288526/evaluate_model_fold/17 (pid 87407)] Evaluating fold 1...\n",
      "2024-07-30 11:46:16.348 [1722354345288526/evaluate_model_fold/17 (pid 87407)] 3/3 - 0s - 48ms/step - accuracy: 0.9855 - loss: 0.0928\n",
      "2024-07-30 11:46:16.355 [1722354345288526/evaluate_model_fold/17 (pid 87407)] Fold 1 - loss: 0.09282015264034271 - accuracy: 0.9855072498321533\n",
      "2024-07-30 11:46:16.479 [1722354345288526/evaluate_model_fold/17 (pid 87407)] Task finished successfully.\n",
      "2024-07-30 11:46:16.511 [1722354345288526/evaluate_model_fold/18 (pid 87423)] Task is starting.\n",
      "2024-07-30 11:46:17.104 [1722354345288526/evaluate_model_fold/18 (pid 87423)] Evaluating fold 2...\n",
      "2024-07-30 11:46:17.770 [1722354345288526/evaluate_model_fold/18 (pid 87423)] 3/3 - 0s - 46ms/step - accuracy: 0.7536 - loss: 0.4173\n",
      "2024-07-30 11:46:17.777 [1722354345288526/evaluate_model_fold/18 (pid 87423)] Fold 2 - loss: 0.4172655940055847 - accuracy: 0.7536231875419617\n",
      "2024-07-30 11:46:17.899 [1722354345288526/evaluate_model_fold/18 (pid 87423)] Task finished successfully.\n",
      "2024-07-30 11:46:17.930 [1722354345288526/evaluate_model_fold/19 (pid 87439)] Task is starting.\n",
      "2024-07-30 11:46:18.455 [1722354345288526/evaluate_model_fold/19 (pid 87439)] Evaluating fold 3...\n",
      "2024-07-30 11:46:19.118 [1722354345288526/evaluate_model_fold/19 (pid 87439)] 3/3 - 0s - 46ms/step - accuracy: 1.0000 - loss: 0.1058\n",
      "2024-07-30 11:46:19.126 [1722354345288526/evaluate_model_fold/19 (pid 87439)] Fold 3 - loss: 0.10580983757972717 - accuracy: 1.0\n",
      "2024-07-30 11:46:19.252 [1722354345288526/evaluate_model_fold/19 (pid 87439)] Task finished successfully.\n",
      "2024-07-30 11:46:19.284 [1722354345288526/evaluate_model_fold/20 (pid 87445)] Task is starting.\n",
      "2024-07-30 11:46:19.873 [1722354345288526/evaluate_model_fold/20 (pid 87445)] Evaluating fold 4...\n",
      "2024-07-30 11:46:20.538 [1722354345288526/evaluate_model_fold/20 (pid 87445)] 3/3 - 0s - 46ms/step - accuracy: 0.9412 - loss: 0.2482\n",
      "2024-07-30 11:46:20.545 [1722354345288526/evaluate_model_fold/20 (pid 87445)] Fold 4 - loss: 0.24822890758514404 - accuracy: 0.9411764740943909\n",
      "2024-07-30 11:46:20.667 [1722354345288526/evaluate_model_fold/20 (pid 87445)] Task finished successfully.\n",
      "2024-07-30 11:46:20.717 [1722354345288526/evaluate_model/21 (pid 87461)] Task is starting.\n",
      "2024-07-30 11:46:21.284 [1722354345288526/evaluate_model/21 (pid 87461)] Accuracy: 0.9302642822265625 ±0.09043958014852428\n",
      "2024-07-30 11:46:21.356 [1722354345288526/evaluate_model/21 (pid 87461)] Loss: 0.2441035121679306 ±0.13009447748062386\n",
      "2024-07-30 11:46:21.357 [1722354345288526/evaluate_model/21 (pid 87461)] Task finished successfully.\n",
      "2024-07-30 11:46:21.389 [1722354345288526/train_model/22 (pid 87466)] Task is starting.\n",
      "2024-07-30 11:46:22.240 [1722354345288526/train_model/22 (pid 87466)] 2024/07/30 11:46:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2024-07-30 11:46:22.529 [1722354345288526/train_model/22 (pid 87466)] Epoch 1/50\n",
      "2024-07-30 11:46:22.836 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 27ms/step - accuracy: 0.3634 - loss: 1.1255\n",
      "2024-07-30 11:46:22.836 [1722354345288526/train_model/22 (pid 87466)] Epoch 2/50\n",
      "2024-07-30 11:46:22.909 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 7ms/step - accuracy: 0.5698 - loss: 0.9795\n",
      "2024-07-30 11:46:22.910 [1722354345288526/train_model/22 (pid 87466)] Epoch 3/50\n",
      "2024-07-30 11:46:22.913 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 299us/step - accuracy: 0.6890 - loss: 0.8711\n",
      "2024-07-30 11:46:22.913 [1722354345288526/train_model/22 (pid 87466)] Epoch 4/50\n",
      "2024-07-30 11:46:22.917 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 282us/step - accuracy: 0.7267 - loss: 0.7884\n",
      "2024-07-30 11:46:22.917 [1722354345288526/train_model/22 (pid 87466)] Epoch 5/50\n",
      "2024-07-30 11:46:22.919 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 216us/step - accuracy: 0.7500 - loss: 0.7238\n",
      "2024-07-30 11:46:22.919 [1722354345288526/train_model/22 (pid 87466)] Epoch 6/50\n",
      "2024-07-30 11:46:22.922 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 231us/step - accuracy: 0.7674 - loss: 0.6725\n",
      "2024-07-30 11:46:22.922 [1722354345288526/train_model/22 (pid 87466)] Epoch 7/50\n",
      "2024-07-30 11:46:22.925 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 232us/step - accuracy: 0.7733 - loss: 0.6304\n",
      "2024-07-30 11:46:22.925 [1722354345288526/train_model/22 (pid 87466)] Epoch 8/50\n",
      "2024-07-30 11:46:22.928 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 224us/step - accuracy: 0.7791 - loss: 0.5959\n",
      "2024-07-30 11:46:22.928 [1722354345288526/train_model/22 (pid 87466)] Epoch 9/50\n",
      "2024-07-30 11:46:22.931 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 225us/step - accuracy: 0.7820 - loss: 0.5674\n",
      "2024-07-30 11:46:22.931 [1722354345288526/train_model/22 (pid 87466)] Epoch 10/50\n",
      "2024-07-30 11:46:22.934 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 227us/step - accuracy: 0.7878 - loss: 0.5429\n",
      "2024-07-30 11:46:22.934 [1722354345288526/train_model/22 (pid 87466)] Epoch 11/50\n",
      "2024-07-30 11:46:22.937 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 243us/step - accuracy: 0.7878 - loss: 0.5216\n",
      "2024-07-30 11:46:22.937 [1722354345288526/train_model/22 (pid 87466)] Epoch 12/50\n",
      "2024-07-30 11:46:22.940 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 226us/step - accuracy: 0.7907 - loss: 0.5029\n",
      "2024-07-30 11:46:22.940 [1722354345288526/train_model/22 (pid 87466)] Epoch 13/50\n",
      "2024-07-30 11:46:22.943 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 224us/step - accuracy: 0.7907 - loss: 0.4863\n",
      "2024-07-30 11:46:22.943 [1722354345288526/train_model/22 (pid 87466)] Epoch 14/50\n",
      "2024-07-30 11:46:22.945 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 221us/step - accuracy: 0.7907 - loss: 0.4714\n",
      "2024-07-30 11:46:22.945 [1722354345288526/train_model/22 (pid 87466)] Epoch 15/50\n",
      "2024-07-30 11:46:22.948 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 230us/step - accuracy: 0.7907 - loss: 0.4577\n",
      "2024-07-30 11:46:22.948 [1722354345288526/train_model/22 (pid 87466)] Epoch 16/50\n",
      "2024-07-30 11:46:22.951 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 228us/step - accuracy: 0.7936 - loss: 0.4456\n",
      "2024-07-30 11:46:22.951 [1722354345288526/train_model/22 (pid 87466)] Epoch 17/50\n",
      "2024-07-30 11:46:22.954 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 215us/step - accuracy: 0.7965 - loss: 0.4343\n",
      "2024-07-30 11:46:22.954 [1722354345288526/train_model/22 (pid 87466)] Epoch 18/50\n",
      "2024-07-30 11:46:22.956 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 213us/step - accuracy: 0.7965 - loss: 0.4240\n",
      "2024-07-30 11:46:22.957 [1722354345288526/train_model/22 (pid 87466)] Epoch 19/50\n",
      "2024-07-30 11:46:22.959 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 226us/step - accuracy: 0.7965 - loss: 0.4141\n",
      "2024-07-30 11:46:22.959 [1722354345288526/train_model/22 (pid 87466)] Epoch 20/50\n",
      "2024-07-30 11:46:22.962 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 231us/step - accuracy: 0.7965 - loss: 0.4052\n",
      "2024-07-30 11:46:22.962 [1722354345288526/train_model/22 (pid 87466)] Epoch 21/50\n",
      "2024-07-30 11:46:22.965 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 227us/step - accuracy: 0.7965 - loss: 0.3967\n",
      "2024-07-30 11:46:22.965 [1722354345288526/train_model/22 (pid 87466)] Epoch 22/50\n",
      "2024-07-30 11:46:22.968 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 218us/step - accuracy: 0.7965 - loss: 0.3888\n",
      "2024-07-30 11:46:22.968 [1722354345288526/train_model/22 (pid 87466)] Epoch 23/50\n",
      "2024-07-30 11:46:22.971 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 215us/step - accuracy: 0.7994 - loss: 0.3813\n",
      "2024-07-30 11:46:22.971 [1722354345288526/train_model/22 (pid 87466)] Epoch 24/50\n",
      "2024-07-30 11:46:22.973 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 230us/step - accuracy: 0.7994 - loss: 0.3743\n",
      "2024-07-30 11:46:22.974 [1722354345288526/train_model/22 (pid 87466)] Epoch 25/50\n",
      "2024-07-30 11:46:22.976 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 236us/step - accuracy: 0.7994 - loss: 0.3676\n",
      "2024-07-30 11:46:22.977 [1722354345288526/train_model/22 (pid 87466)] Epoch 26/50\n",
      "2024-07-30 11:46:22.979 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 217us/step - accuracy: 0.7994 - loss: 0.3611\n",
      "2024-07-30 11:46:22.979 [1722354345288526/train_model/22 (pid 87466)] Epoch 27/50\n",
      "2024-07-30 11:46:22.982 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 229us/step - accuracy: 0.7994 - loss: 0.3551\n",
      "2024-07-30 11:46:22.982 [1722354345288526/train_model/22 (pid 87466)] Epoch 28/50\n",
      "2024-07-30 11:46:22.985 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 226us/step - accuracy: 0.7994 - loss: 0.3491\n",
      "2024-07-30 11:46:22.985 [1722354345288526/train_model/22 (pid 87466)] Epoch 29/50\n",
      "2024-07-30 11:46:22.988 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 225us/step - accuracy: 0.8052 - loss: 0.3435\n",
      "2024-07-30 11:46:22.988 [1722354345288526/train_model/22 (pid 87466)] Epoch 30/50\n",
      "2024-07-30 11:46:22.991 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 228us/step - accuracy: 0.8110 - loss: 0.3381\n",
      "2024-07-30 11:46:22.991 [1722354345288526/train_model/22 (pid 87466)] Epoch 31/50\n",
      "2024-07-30 11:46:22.993 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 224us/step - accuracy: 0.8140 - loss: 0.3329\n",
      "2024-07-30 11:46:22.994 [1722354345288526/train_model/22 (pid 87466)] Epoch 32/50\n",
      "2024-07-30 11:46:22.996 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 217us/step - accuracy: 0.8198 - loss: 0.3279\n",
      "2024-07-30 11:46:22.996 [1722354345288526/train_model/22 (pid 87466)] Epoch 33/50\n",
      "2024-07-30 11:46:22.999 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 226us/step - accuracy: 0.8285 - loss: 0.3232\n",
      "2024-07-30 11:46:22.999 [1722354345288526/train_model/22 (pid 87466)] Epoch 34/50\n",
      "2024-07-30 11:46:23.002 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 218us/step - accuracy: 0.8285 - loss: 0.3185\n",
      "2024-07-30 11:46:23.002 [1722354345288526/train_model/22 (pid 87466)] Epoch 35/50\n",
      "2024-07-30 11:46:23.004 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 215us/step - accuracy: 0.8314 - loss: 0.3141\n",
      "2024-07-30 11:46:23.005 [1722354345288526/train_model/22 (pid 87466)] Epoch 36/50\n",
      "2024-07-30 11:46:23.007 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 231us/step - accuracy: 0.8314 - loss: 0.3097\n",
      "2024-07-30 11:46:23.008 [1722354345288526/train_model/22 (pid 87466)] Epoch 37/50\n",
      "2024-07-30 11:46:23.010 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 226us/step - accuracy: 0.8343 - loss: 0.3055\n",
      "2024-07-30 11:46:23.010 [1722354345288526/train_model/22 (pid 87466)] Epoch 38/50\n",
      "2024-07-30 11:46:23.013 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 217us/step - accuracy: 0.8343 - loss: 0.3016\n",
      "2024-07-30 11:46:23.013 [1722354345288526/train_model/22 (pid 87466)] Epoch 39/50\n",
      "2024-07-30 11:46:23.016 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 225us/step - accuracy: 0.8430 - loss: 0.2976\n",
      "2024-07-30 11:46:23.016 [1722354345288526/train_model/22 (pid 87466)] Epoch 40/50\n",
      "2024-07-30 11:46:23.019 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 222us/step - accuracy: 0.8459 - loss: 0.2938\n",
      "2024-07-30 11:46:23.019 [1722354345288526/train_model/22 (pid 87466)] Epoch 41/50\n",
      "2024-07-30 11:46:23.021 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 213us/step - accuracy: 0.8459 - loss: 0.2900\n",
      "2024-07-30 11:46:23.022 [1722354345288526/train_model/22 (pid 87466)] Epoch 42/50\n",
      "2024-07-30 11:46:23.024 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 209us/step - accuracy: 0.8517 - loss: 0.2863\n",
      "2024-07-30 11:46:23.024 [1722354345288526/train_model/22 (pid 87466)] Epoch 43/50\n",
      "2024-07-30 11:46:23.027 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 219us/step - accuracy: 0.8547 - loss: 0.2827\n",
      "2024-07-30 11:46:23.027 [1722354345288526/train_model/22 (pid 87466)] Epoch 44/50\n",
      "2024-07-30 11:46:23.029 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 209us/step - accuracy: 0.8634 - loss: 0.2791\n",
      "2024-07-30 11:46:23.029 [1722354345288526/train_model/22 (pid 87466)] Epoch 45/50\n",
      "2024-07-30 11:46:23.032 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 217us/step - accuracy: 0.8663 - loss: 0.2757\n",
      "2024-07-30 11:46:23.032 [1722354345288526/train_model/22 (pid 87466)] Epoch 46/50\n",
      "2024-07-30 11:46:23.035 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 226us/step - accuracy: 0.8692 - loss: 0.2722\n",
      "2024-07-30 11:46:23.035 [1722354345288526/train_model/22 (pid 87466)] Epoch 47/50\n",
      "2024-07-30 11:46:23.038 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 222us/step - accuracy: 0.8692 - loss: 0.2688\n",
      "2024-07-30 11:46:23.038 [1722354345288526/train_model/22 (pid 87466)] Epoch 48/50\n",
      "2024-07-30 11:46:23.040 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 214us/step - accuracy: 0.8721 - loss: 0.2656\n",
      "2024-07-30 11:46:23.041 [1722354345288526/train_model/22 (pid 87466)] Epoch 49/50\n",
      "2024-07-30 11:46:23.043 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 210us/step - accuracy: 0.8779 - loss: 0.2624\n",
      "2024-07-30 11:46:23.043 [1722354345288526/train_model/22 (pid 87466)] Epoch 50/50\n",
      "2024-07-30 11:46:23.046 [1722354345288526/train_model/22 (pid 87466)] 11/11 - 0s - 213us/step - accuracy: 0.8779 - loss: 0.2591\n",
      "2024-07-30 11:46:25.256 [1722354345288526/train_model/22 (pid 87466)] Task finished successfully.\n",
      "2024-07-30 11:46:25.287 [1722354345288526/register_model/23 (pid 87499)] Task is starting.\n",
      "2024-07-30 11:46:25.906 [1722354345288526/register_model/23 (pid 87499)] Registering model...\n",
      "2024-07-30 11:46:26.812 [1722354345288526/register_model/23 (pid 87499)] Registered model 'penguins' already exists. Creating a new version of this model...\n",
      "2024-07-30 11:46:26.825 [1722354345288526/register_model/23 (pid 87499)] Created version '25' of model 'penguins'.\n",
      "2024-07-30 11:46:26.972 [1722354345288526/register_model/23 (pid 87499)] Task finished successfully.\n",
      "2024-07-30 11:46:27.004 [1722354345288526/end/24 (pid 87515)] Task is starting.\n",
      "2024-07-30 11:46:27.619 [1722354345288526/end/24 (pid 87515)] the end\n",
      "2024-07-30 11:46:27.689 [1722354345288526/end/24 (pid 87515)] Task finished successfully.\n",
      "2024-07-30 11:46:27.691 Done!\n",
      "Run('TrainingFlow/1722354345288526')\n"
     ]
    }
   ],
   "source": [
    "from metaflow import Runner\n",
    "\n",
    "with Runner(\"training.py\", environment=\"pypi\", env={\"KERAS_BACKEND\": \"jax\"}).run(\n",
    "    max_workers=1\n",
    ") as running:\n",
    "    print(f\"{running.run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.12.3 executing IntroductionFlow for user:svpino\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint not found, so extra checks are disabled.\n",
      "2024-07-18 20:38:10.756 Workflow starting (run-id 1721327890756156):\n",
      "2024-07-18 20:38:10.762 [1721327890756156/start/1 (pid 36197)] Task is starting.\n",
      "2024-07-18 20:38:10.881 [1721327890756156/start/1 (pid 36197)] Start\n",
      "2024-07-18 20:38:10.900 [1721327890756156/start/1 (pid 36197)] Task finished successfully.\n",
      "2024-07-18 20:38:10.903 [1721327890756156/end/2 (pid 36200)] Task is starting.\n",
      "2024-07-18 20:38:11.025 [1721327890756156/end/2 (pid 36200)] the end\n",
      "2024-07-18 20:38:11.043 [1721327890756156/end/2 (pid 36200)] Task finished successfully.\n",
      "2024-07-18 20:38:11.043 Done!\n",
      "Run('IntroductionFlow/1721327890756156')\n"
     ]
    }
   ],
   "source": [
    "from metaflow import Runner\n",
    "\n",
    "with Runner(\"flows/00-introduction.py\").run() as running:\n",
    "    print(f\"{running.run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.12.3 executing LoadFlow for user:svpino\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint not found, so extra checks are disabled.\n",
      "2024-07-18 20:40:03.290 Workflow starting (run-id 1721328003289419):\n",
      "2024-07-18 20:40:03.297 [1721328003289419/start/1 (pid 38623)] Task is starting.\n",
      "2024-07-18 20:40:03.426 [1721328003289419/start/1 (pid 38623)] Start\n",
      "2024-07-18 20:40:03.448 [1721328003289419/start/1 (pid 38623)] Task finished successfully.\n",
      "2024-07-18 20:40:03.452 [1721328003289419/load_data/2 (pid 38627)] Task is starting.\n",
      "2024-07-18 20:40:03.580 [1721328003289419/load_data/2 (pid 38627)] Load\n",
      "2024-07-18 20:40:03.600 [1721328003289419/load_data/2 (pid 38627)] Task finished successfully.\n",
      "2024-07-18 20:40:03.603 [1721328003289419/end/3 (pid 38630)] Task is starting.\n",
      "2024-07-18 20:40:03.730 [1721328003289419/end/3 (pid 38630)] the end\n",
      "2024-07-18 20:40:03.753 [1721328003289419/end/3 (pid 38630)] Task finished successfully.\n",
      "2024-07-18 20:40:03.753 Done!\n",
      "Run('LoadFlow/1721328003289419')\n"
     ]
    }
   ],
   "source": [
    "from metaflow import Runner\n",
    "\n",
    "with Runner(\"flows/01-load.py\").run() as running:\n",
    "    print(f\"{running.run}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3  Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  FEMALE  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "location = Path(\"../penguins.csv\")\n",
    "df = pd.read_csv(location)\n",
    "df[\"sex\"] = df[\"sex\"].replace(\".\", np.nan)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = df.pop(\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.to_numpy().reshape(-1, 1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "label_transformer = ColumnTransformer(\n",
    "    transformers=[(\"species\", OrdinalEncoder(), [0])],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target_transformer():\n",
    "    \"\"\"Build a Scikit-Learn transformer to preprocess the target variable.\"\"\"\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[(\"species\", OrdinalEncoder(), [0])],\n",
    "    )\n",
    "\n",
    "\n",
    "def build_features_transformer():\n",
    "    \"\"\"Build a Scikit-Learn transformer to preprocess the feature columns.\"\"\"\n",
    "    from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "    numeric_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"mean\"),\n",
    "        StandardScaler(),\n",
    "    )\n",
    "\n",
    "    categorical_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy=\"most_frequent\"),\n",
    "        # We can use the `handle_unknown=\"ignore\"` parameter to ignore\n",
    "        # unseen categories during inference. When encoding an unknown\n",
    "        # category, the transformer will return an all-zero vector.\n",
    "        OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "    )\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                \"numeric\",\n",
    "                numeric_transformer,\n",
    "                make_column_selector(dtype_exclude=\"object\"),\n",
    "            ),\n",
    "            (\n",
    "                \"categorical\",\n",
    "                categorical_transformer,\n",
    "                [\"island\", \"sex\"],\n",
    "                # make_column_selector(dtype_include=\"object\"),\n",
    "            ),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transformer = build_target_transformer()\n",
    "y = target_transformer.fit_transform(df.species.to_numpy().reshape(-1, 1))\n",
    "\n",
    "features_transformer = build_features_transformer()\n",
    "x = features_transformer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.88708123,  0.78774251, -1.42248782, -0.56578921,  0.        ,\n",
       "        0.        ,  1.        ,  0.        ,  1.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        # TODO: I thought we needed 10 inputs here?\n",
    "        Input(shape=(9,)),\n",
    "        Dense(10, activation=\"relu\"),\n",
    "        Dense(8, activation=\"relu\"),\n",
    "        Dense(3, activation=\"softmax\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.01),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x358888a00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, verbose=0, epochs=1, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.88708123,  0.78774251, -1.42248782, -0.56578921,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"] = df[\"sex\"].replace(\".\", np.nan)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.sample(frac=0.2, random_state=42)\n",
    "train_df = df.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>38.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3625.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
       "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
       "6  Adelie  Torgersen              38.9             17.8              181.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "4       3450.0  FEMALE  \n",
       "6       3625.0  FEMALE  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=2, shuffle=True)\n",
    "kfold_indices = list(enumerate(kfold.split(train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " (array([  0,   1,   3,   4,   5,   7,  10,  14,  16,  17,  18,  23,  24,\n",
       "          25,  26,  28,  29,  30,  31,  32,  35,  36,  37,  38,  40,  41,\n",
       "          43,  45,  46,  47,  50,  52,  53,  59,  60,  61,  65,  66,  67,\n",
       "          68,  69,  71,  72,  78,  79,  80,  81,  82,  84,  95,  98,  99,\n",
       "         101, 102, 103, 104, 108, 109, 111, 115, 116, 117, 119, 122, 130,\n",
       "         132, 133, 136, 137, 139, 140, 141, 143, 144, 145, 147, 149, 150,\n",
       "         152, 153, 154, 155, 160, 162, 166, 172, 173, 174, 175, 177, 178,\n",
       "         179, 187, 188, 194, 195, 196, 197, 200, 201, 202, 203, 205, 215,\n",
       "         216, 217, 219, 220, 221, 222, 224, 225, 227, 228, 230, 234, 235,\n",
       "         238, 239, 242, 244, 245, 246, 247, 248, 249, 251, 254, 255, 256,\n",
       "         261, 263, 265, 267, 268, 271, 274]),\n",
       "  array([  2,   6,   8,   9,  11,  12,  13,  15,  19,  20,  21,  22,  27,\n",
       "          33,  34,  39,  42,  44,  48,  49,  51,  54,  55,  56,  57,  58,\n",
       "          62,  63,  64,  70,  73,  74,  75,  76,  77,  83,  85,  86,  87,\n",
       "          88,  89,  90,  91,  92,  93,  94,  96,  97, 100, 105, 106, 107,\n",
       "         110, 112, 113, 114, 118, 120, 121, 123, 124, 125, 126, 127, 128,\n",
       "         129, 131, 134, 135, 138, 142, 146, 148, 151, 156, 157, 158, 159,\n",
       "         161, 163, 164, 165, 167, 168, 169, 170, 171, 176, 180, 181, 182,\n",
       "         183, 184, 185, 186, 189, 190, 191, 192, 193, 198, 199, 204, 206,\n",
       "         207, 208, 209, 210, 211, 212, 213, 214, 218, 223, 226, 229, 231,\n",
       "         232, 233, 236, 237, 240, 241, 243, 250, 252, 253, 257, 258, 259,\n",
       "         260, 262, 264, 266, 269, 270, 272, 273])))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[kfold_indices[0][1][0]]\n",
    "test_df = df.iloc[kfold_indices[0][1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import StringLookup\n",
    "\n",
    "label_lookup = StringLookup(\n",
    "    # the order here is important since the first index will be encoded as 0\n",
    "    vocabulary=[\"Adelie\", \"Chinstrap\", \"Gentoo\"],\n",
    "    num_oov_indices=0,\n",
    ")\n",
    "\n",
    "\n",
    "def encode_label(x, y):\n",
    "    encoded_y = label_lookup(y)\n",
    "    return x, encoded_y\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(df):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(\"species\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    ds = ds.map(encode_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.shuffle(buffer_size=len(df))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_dataset = dataframe_to_dataset(train_df)\n",
    "test_dataset = dataframe_to_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'island': <tf.Tensor: shape=(), dtype=string, numpy=b'Biscoe'>, 'culmen_length_mm': <tf.Tensor: shape=(), dtype=float64, numpy=42.8>, 'culmen_depth_mm': <tf.Tensor: shape=(), dtype=float64, numpy=14.2>, 'flipper_length_mm': <tf.Tensor: shape=(), dtype=float64, numpy=209.0>, 'body_mass_g': <tf.Tensor: shape=(), dtype=float64, numpy=4700.0>, 'sex': <tf.Tensor: shape=(), dtype=string, numpy=b'FEMALE'>}\n",
      "Target: tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 17:21:07.476200: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(32)\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'island': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Biscoe', b'Torgersen', b'Biscoe', b'Dream', b'Biscoe', b'Biscoe',\n",
      "       b'Torgersen', b'Torgersen', b'Dream', b'Biscoe', b'Dream',\n",
      "       b'Biscoe', b'Dream', b'Biscoe', b'Biscoe', b'Biscoe', b'Dream',\n",
      "       b'Biscoe', b'Biscoe', b'Biscoe', b'Biscoe', b'Biscoe', b'Biscoe',\n",
      "       b'Biscoe', b'Biscoe', b'Biscoe', b'Dream', b'Dream', b'Dream',\n",
      "       b'Torgersen', b'Dream', b'Biscoe'], dtype=object)>, 'culmen_length_mm': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([44. , 41.5, 49.6, 49.8, 35.5, 43.3, 36.2, 36.2, 43.5, 39.7, 47.6,\n",
      "       45.6, 51.3, 49.9, 49.5, 46.8, 45.6, 45.2, 37.7, 47.5, 40.6, 50.8,\n",
      "       49.4, 50. , 36.5, 49.3, 50.8, 39.7, 49. , 39.7, 35.6, 42. ])>, 'culmen_depth_mm': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([13.6, 18.3, 15. , 17.3, 16.2, 14. , 17.2, 16.1, 18.1, 17.7, 18.3,\n",
      "       20.3, 19.9, 16.1, 16.1, 14.3, 19.4, 13.8, 16. , 14.2, 18.6, 15.7,\n",
      "       15.8, 15.9, 16.6, 15.7, 19. , 17.9, 19.6, 18.4, 17.5, 19.5])>, 'flipper_length_mm': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([208., 195., 216., 198., 195., 208., 187., 187., 202., 193., 195.,\n",
      "       191., 198., 213., 224., 215., 194., 215., 183., 209., 183., 226.,\n",
      "       216., 224., 181., 217., 210., 193., 212., 190., 191., 200.])>, 'body_mass_g': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([4350., 4300., 4750., 3675., 3350., 4575., 3150., 3550., 3400.,\n",
      "       3200., 3850., 4600., 3700., 5400., 5650., 4850., 3525., 4750.,\n",
      "       3075., 4600., 3550., 5200., 4925., 5350., 2850., 5850., 4100.,\n",
      "       4250., 4300., 3900., 3175., 4050.])>, 'sex': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'FEMALE', b'MALE', b'MALE', b'FEMALE', b'FEMALE', b'FEMALE',\n",
      "       b'FEMALE', b'FEMALE', b'FEMALE', b'FEMALE', b'FEMALE', b'MALE',\n",
      "       b'MALE', b'MALE', b'MALE', b'FEMALE', b'FEMALE', b'FEMALE',\n",
      "       b'FEMALE', b'FEMALE', b'MALE', b'MALE', b'MALE', b'MALE',\n",
      "       b'FEMALE', b'MALE', b'MALE', b'MALE', b'MALE', b'MALE', b'FEMALE',\n",
      "       b'MALE'], dtype=object)>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 16:08:53.143833: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(\"Input:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import FeatureSpace\n",
    "\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"sex\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"island\": \"string_categorical\",\n",
    "        \"culmen_length_mm\": \"float_normalized\",\n",
    "        \"culmen_depth_mm\": \"float_normalized\",\n",
    "        \"flipper_length_mm\": \"float_normalized\",\n",
    "        \"body_mass_g\": \"float_normalized\",\n",
    "    },\n",
    "    output_mode=\"concat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 14:52:46.673085: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.701861: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.726271: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.750699: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.774244: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.801095: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.823662: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.850782: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.873484: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.903032: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.926288: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.953709: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_ds_with_no_labels = train_dataset.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_x.shape: (32, 10)\n",
      "preprocessed_x.dtype: <dtype: 'float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 14:52:47.613255: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, _ in train_dataset.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
    "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_ds = train_dataset.map(\n",
    "    lambda x, y: (feature_space(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_test_ds = test_dataset.map(\n",
    "    lambda x, y: (feature_space(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "preprocessed_test_ds = preprocessed_test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'island': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=island>,\n",
       " 'sex': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=sex>,\n",
       " 'culmen_length_mm': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=culmen_length_mm>,\n",
       " 'culmen_depth_mm': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=culmen_depth_mm>,\n",
       " 'flipper_length_mm': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=flipper_length_mm>,\n",
       " 'body_mass_g': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=body_mass_g>}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 10), dtype=float32, sparse=False, name=keras_tensor_110>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "x = Dense(10, activation=\"relu\")(encoded_features)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "outputs = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=encoded_features, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.01),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = Model(inputs=dict_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - 23ms/step - accuracy: 0.1873 - loss: 1.2161 - val_accuracy: 0.2879 - val_loss: 1.1632\n",
      "Epoch 2/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.2322 - loss: 1.1728 - val_accuracy: 0.3636 - val_loss: 1.1302\n",
      "Epoch 3/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.2996 - loss: 1.1336 - val_accuracy: 0.3636 - val_loss: 1.1041\n",
      "Epoch 4/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.3408 - loss: 1.1017 - val_accuracy: 0.4242 - val_loss: 1.0803\n",
      "Epoch 5/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.3858 - loss: 1.0732 - val_accuracy: 0.4545 - val_loss: 1.0581\n",
      "Epoch 6/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.4120 - loss: 1.0464 - val_accuracy: 0.5152 - val_loss: 1.0365\n",
      "Epoch 7/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.4494 - loss: 1.0204 - val_accuracy: 0.5152 - val_loss: 1.0140\n",
      "Epoch 8/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.4906 - loss: 0.9946 - val_accuracy: 0.5606 - val_loss: 0.9917\n",
      "Epoch 9/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.5243 - loss: 0.9701 - val_accuracy: 0.6364 - val_loss: 0.9700\n",
      "Epoch 10/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.5581 - loss: 0.9461 - val_accuracy: 0.6667 - val_loss: 0.9471\n",
      "Epoch 11/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.5993 - loss: 0.9213 - val_accuracy: 0.6818 - val_loss: 0.9248\n",
      "Epoch 12/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.6404 - loss: 0.8972 - val_accuracy: 0.7273 - val_loss: 0.9017\n",
      "Epoch 13/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.6592 - loss: 0.8727 - val_accuracy: 0.7424 - val_loss: 0.8783\n",
      "Epoch 14/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.6891 - loss: 0.8486 - val_accuracy: 0.7424 - val_loss: 0.8538\n",
      "Epoch 15/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.7079 - loss: 0.8248 - val_accuracy: 0.7727 - val_loss: 0.8297\n",
      "Epoch 16/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.7228 - loss: 0.8006 - val_accuracy: 0.7727 - val_loss: 0.8058\n",
      "Epoch 17/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.7453 - loss: 0.7767 - val_accuracy: 0.7879 - val_loss: 0.7810\n",
      "Epoch 18/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.7790 - loss: 0.7528 - val_accuracy: 0.8182 - val_loss: 0.7570\n",
      "Epoch 19/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8090 - loss: 0.7296 - val_accuracy: 0.8182 - val_loss: 0.7322\n",
      "Epoch 20/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8427 - loss: 0.7062 - val_accuracy: 0.8485 - val_loss: 0.7074\n",
      "Epoch 21/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8577 - loss: 0.6831 - val_accuracy: 0.8636 - val_loss: 0.6833\n",
      "Epoch 22/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8689 - loss: 0.6605 - val_accuracy: 0.8788 - val_loss: 0.6594\n",
      "Epoch 23/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8764 - loss: 0.6388 - val_accuracy: 0.9091 - val_loss: 0.6362\n",
      "Epoch 24/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8914 - loss: 0.6173 - val_accuracy: 0.9242 - val_loss: 0.6133\n",
      "Epoch 25/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9176 - loss: 0.5963 - val_accuracy: 0.9545 - val_loss: 0.5896\n",
      "Epoch 26/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9213 - loss: 0.5756 - val_accuracy: 0.9545 - val_loss: 0.5666\n",
      "Epoch 27/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9363 - loss: 0.5553 - val_accuracy: 0.9545 - val_loss: 0.5450\n",
      "Epoch 28/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9401 - loss: 0.5351 - val_accuracy: 0.9545 - val_loss: 0.5243\n",
      "Epoch 29/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9401 - loss: 0.5163 - val_accuracy: 0.9545 - val_loss: 0.5042\n",
      "Epoch 30/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.4974 - val_accuracy: 0.9697 - val_loss: 0.4839\n",
      "Epoch 31/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.4794 - val_accuracy: 0.9697 - val_loss: 0.4656\n",
      "Epoch 32/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9513 - loss: 0.4620 - val_accuracy: 0.9697 - val_loss: 0.4475\n",
      "Epoch 33/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9588 - loss: 0.4452 - val_accuracy: 0.9697 - val_loss: 0.4301\n",
      "Epoch 34/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9588 - loss: 0.4287 - val_accuracy: 0.9697 - val_loss: 0.4137\n",
      "Epoch 35/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9625 - loss: 0.4129 - val_accuracy: 0.9697 - val_loss: 0.3977\n",
      "Epoch 36/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9663 - loss: 0.3974 - val_accuracy: 0.9545 - val_loss: 0.3809\n",
      "Epoch 37/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9700 - loss: 0.3818 - val_accuracy: 0.9545 - val_loss: 0.3652\n",
      "Epoch 38/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9700 - loss: 0.3671 - val_accuracy: 0.9545 - val_loss: 0.3502\n",
      "Epoch 39/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3530 - val_accuracy: 0.9545 - val_loss: 0.3362\n",
      "Epoch 40/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3394 - val_accuracy: 0.9545 - val_loss: 0.3226\n",
      "Epoch 41/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3262 - val_accuracy: 0.9545 - val_loss: 0.3097\n",
      "Epoch 42/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3137 - val_accuracy: 0.9545 - val_loss: 0.2972\n",
      "Epoch 43/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3011 - val_accuracy: 0.9545 - val_loss: 0.2854\n",
      "Epoch 44/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.2890 - val_accuracy: 0.9545 - val_loss: 0.2736\n",
      "Epoch 45/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9775 - loss: 0.2774 - val_accuracy: 0.9545 - val_loss: 0.2625\n",
      "Epoch 46/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9775 - loss: 0.2665 - val_accuracy: 0.9545 - val_loss: 0.2517\n",
      "Epoch 47/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9775 - loss: 0.2553 - val_accuracy: 0.9545 - val_loss: 0.2416\n",
      "Epoch 48/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9813 - loss: 0.2448 - val_accuracy: 0.9545 - val_loss: 0.2315\n",
      "Epoch 49/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9813 - loss: 0.2347 - val_accuracy: 0.9697 - val_loss: 0.2221\n",
      "Epoch 50/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9813 - loss: 0.2247 - val_accuracy: 0.9697 - val_loss: 0.2129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3a63ae4a0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    preprocessed_train_ds,\n",
    "    epochs=50,\n",
    "    validation_data=preprocessed_test_ds,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'island': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Biscoe', b'Torgersen', b'Torgersen'], dtype=object)>,\n",
       " 'culmen_length_mm': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([48.6, 44.1, 39.1], dtype=float32)>,\n",
       " 'culmen_depth_mm': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([16. , 18. , 18.7], dtype=float32)>,\n",
       " 'flipper_length_mm': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([230., 210., 181.], dtype=float32)>,\n",
       " 'body_mass_g': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([5800., 4000., 3750.], dtype=float32)>,\n",
       " 'sex': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'MALE', b'FEMALE', b'MALE'], dtype=object)>}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = {\n",
    "    \"island\": [\"Biscoe\", \"Torgersen\", \"Torgersen\"],\n",
    "    \"culmen_length_mm\": [48.6, 44.1, 39.1],\n",
    "    \"culmen_depth_mm\": [16.0, 18.0, 18.7],\n",
    "    \"flipper_length_mm\": [230.0, 210.0, 181.0],\n",
    "    \"body_mass_g\": [5800.0, 4000.0, 3750.0],\n",
    "    \"sex\": [\"MALE\", \"FEMALE\", \"MALE\"],\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor(value) for name, value in sample.items()}\n",
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03257361, 0.14812116, 0.81930524],\n",
       "       [0.3940005 , 0.28193894, 0.32406056],\n",
       "       [0.94649315, 0.02197206, 0.0315347 ]], dtype=float32)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = inference_model.predict(input_dict)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "\n",
    "\n",
    "def pred(p):\n",
    "    return tf.stack(\n",
    "        [\n",
    "            tf.cast(tf.math.argmax(p, axis=1), dtype=tf.float32),\n",
    "            tf.math.reduce_max(p, axis=1),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "prediction = Lambda(pred)(outputs)\n",
    "\n",
    "inference_model2 = Model(inputs=dict_inputs, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.        , 0.        , 0.        ],\n",
       "       [0.81930524, 0.3940005 , 0.94649315]], dtype=float32)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = inference_model2.predict(input_dict)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adelie', 'Chinstrap', 'Gentoo']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lookup.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = StringLookup(\n",
    "    vocabulary=label_lookup.get_vocabulary(),\n",
    "    invert=True,\n",
    "    num_oov_indices=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'Gentoo', b'Adelie', b'Adelie'], dtype=object)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(np.argmax(result, axis=1)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 0]), array([0.81930524, 0.3940005 , 0.94649315], dtype=float32))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(result, axis=1), np.max(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prediction': 'Adelie', 'confidence': 0.6},\n",
       " {'prediction': 'Gentoo', 'confidence': 0.9},\n",
       " {'prediction': 'Chinstrap', 'confidence': 0.8},\n",
       " {'prediction': 'Chinstrap', 'confidence': 0.7}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n",
    "\n",
    "prediction = np.array([0, 2, 1, 1])\n",
    "condifence = np.array([0.6, 0.9, 0.8, 0.7])\n",
    "\n",
    "prediction = np.vectorize(lambda x: classes[x])(prediction)\n",
    "\n",
    "[\n",
    "    {\"prediction\": p, \"confidence\": c}\n",
    "    for p, c in zip(prediction, condifence, strict=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adelie', 'Gentoo', 'Chinstrap', 'Chinstrap']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example = {\n",
    "    \"island\": \"Biscoe\",\n",
    "    \"culmen_length_mm\": 48.6,\n",
    "    \"culmen_depth_mm\": 16.0,\n",
    "    \"flipper_length_mm\": 230.0,\n",
    "    \"body_mass_g\": 5800.0,\n",
    "    \"sex\": \"MALE\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['island': string (required), 'culmen_length_mm': double (required), 'culmen_depth_mm': double (required), 'flipper_length_mm': double (required), 'body_mass_g': double (required), 'sex': string (required)]\n",
       "outputs: \n",
       "  ['prediction': string (required), 'confidence': double (required)]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "infer_signature(\n",
    "    model_input=input_example, model_output={\"prediction\": \"Adelie\", \"confidence\": 0.90}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
