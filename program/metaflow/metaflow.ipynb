{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3  Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  FEMALE  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "location = Path(\"../penguins.csv\")\n",
    "df = pd.read_csv(location)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = df.pop(\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.to_numpy().reshape(-1, 1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "label_transformer = ColumnTransformer(\n",
    "    transformers=[(\"species\", OrdinalEncoder(), [0])],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=label_transformer.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"mean\"),\n",
    "    StandardScaler(),\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"numeric\",\n",
    "            numeric_transformer,\n",
    "            make_column_selector(dtype_exclude=\"object\"),\n",
    "        ),\n",
    "        (\n",
    "            \"categorical\",\n",
    "            categorical_transformer,\n",
    "            [\"island\"],\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.88708123,  0.78774251, -1.42248782, -0.56578921,  0.        ,\n",
       "        0.        ,  1.        ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = transformer.fit_transform(df)\n",
    "td[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([[\"Torgersen2\", 39.1, 18.7, 181.0, 3750.0, \"MALE\"]], columns=list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.88708123,  0.78774251, -1.42248782, -0.56578921,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"] = df[\"sex\"].replace(\".\", np.nan)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.sample(frac=0.2, random_state=42)\n",
    "train_df = df.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>38.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3625.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
       "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
       "6  Adelie  Torgersen              38.9             17.8              181.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "4       3450.0  FEMALE  \n",
       "6       3625.0  FEMALE  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=2, shuffle=True)\n",
    "kfold_indices = list(enumerate(kfold.split(train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " (array([  0,   1,   3,   4,   5,   7,  10,  14,  16,  17,  18,  23,  24,\n",
       "          25,  26,  28,  29,  30,  31,  32,  35,  36,  37,  38,  40,  41,\n",
       "          43,  45,  46,  47,  50,  52,  53,  59,  60,  61,  65,  66,  67,\n",
       "          68,  69,  71,  72,  78,  79,  80,  81,  82,  84,  95,  98,  99,\n",
       "         101, 102, 103, 104, 108, 109, 111, 115, 116, 117, 119, 122, 130,\n",
       "         132, 133, 136, 137, 139, 140, 141, 143, 144, 145, 147, 149, 150,\n",
       "         152, 153, 154, 155, 160, 162, 166, 172, 173, 174, 175, 177, 178,\n",
       "         179, 187, 188, 194, 195, 196, 197, 200, 201, 202, 203, 205, 215,\n",
       "         216, 217, 219, 220, 221, 222, 224, 225, 227, 228, 230, 234, 235,\n",
       "         238, 239, 242, 244, 245, 246, 247, 248, 249, 251, 254, 255, 256,\n",
       "         261, 263, 265, 267, 268, 271, 274]),\n",
       "  array([  2,   6,   8,   9,  11,  12,  13,  15,  19,  20,  21,  22,  27,\n",
       "          33,  34,  39,  42,  44,  48,  49,  51,  54,  55,  56,  57,  58,\n",
       "          62,  63,  64,  70,  73,  74,  75,  76,  77,  83,  85,  86,  87,\n",
       "          88,  89,  90,  91,  92,  93,  94,  96,  97, 100, 105, 106, 107,\n",
       "         110, 112, 113, 114, 118, 120, 121, 123, 124, 125, 126, 127, 128,\n",
       "         129, 131, 134, 135, 138, 142, 146, 148, 151, 156, 157, 158, 159,\n",
       "         161, 163, 164, 165, 167, 168, 169, 170, 171, 176, 180, 181, 182,\n",
       "         183, 184, 185, 186, 189, 190, 191, 192, 193, 198, 199, 204, 206,\n",
       "         207, 208, 209, 210, 211, 212, 213, 214, 218, 223, 226, 229, 231,\n",
       "         232, 233, 236, 237, 240, 241, 243, 250, 252, 253, 257, 258, 259,\n",
       "         260, 262, 264, 266, 269, 270, 272, 273])))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[kfold_indices[0][1][0]]\n",
    "test_df = df.iloc[kfold_indices[0][1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import StringLookup\n",
    "\n",
    "label_lookup = StringLookup(\n",
    "    # the order here is important since the first index will be encoded as 0\n",
    "    vocabulary=[\"Adelie\", \"Chinstrap\", \"Gentoo\"],\n",
    "    num_oov_indices=0,\n",
    ")\n",
    "\n",
    "\n",
    "def encode_label(x, y):\n",
    "    encoded_y = label_lookup(y)\n",
    "    return x, encoded_y\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(df):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(\"species\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    ds = ds.map(encode_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.shuffle(buffer_size=len(df))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_dataset = dataframe_to_dataset(train_df)\n",
    "test_dataset = dataframe_to_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'island': <tf.Tensor: shape=(), dtype=string, numpy=b'Biscoe'>, 'culmen_length_mm': <tf.Tensor: shape=(), dtype=float64, numpy=42.8>, 'culmen_depth_mm': <tf.Tensor: shape=(), dtype=float64, numpy=14.2>, 'flipper_length_mm': <tf.Tensor: shape=(), dtype=float64, numpy=209.0>, 'body_mass_g': <tf.Tensor: shape=(), dtype=float64, numpy=4700.0>, 'sex': <tf.Tensor: shape=(), dtype=string, numpy=b'FEMALE'>}\n",
      "Target: tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 17:21:07.476200: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(32)\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'island': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Biscoe', b'Torgersen', b'Biscoe', b'Dream', b'Biscoe', b'Biscoe',\n",
      "       b'Torgersen', b'Torgersen', b'Dream', b'Biscoe', b'Dream',\n",
      "       b'Biscoe', b'Dream', b'Biscoe', b'Biscoe', b'Biscoe', b'Dream',\n",
      "       b'Biscoe', b'Biscoe', b'Biscoe', b'Biscoe', b'Biscoe', b'Biscoe',\n",
      "       b'Biscoe', b'Biscoe', b'Biscoe', b'Dream', b'Dream', b'Dream',\n",
      "       b'Torgersen', b'Dream', b'Biscoe'], dtype=object)>, 'culmen_length_mm': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([44. , 41.5, 49.6, 49.8, 35.5, 43.3, 36.2, 36.2, 43.5, 39.7, 47.6,\n",
      "       45.6, 51.3, 49.9, 49.5, 46.8, 45.6, 45.2, 37.7, 47.5, 40.6, 50.8,\n",
      "       49.4, 50. , 36.5, 49.3, 50.8, 39.7, 49. , 39.7, 35.6, 42. ])>, 'culmen_depth_mm': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([13.6, 18.3, 15. , 17.3, 16.2, 14. , 17.2, 16.1, 18.1, 17.7, 18.3,\n",
      "       20.3, 19.9, 16.1, 16.1, 14.3, 19.4, 13.8, 16. , 14.2, 18.6, 15.7,\n",
      "       15.8, 15.9, 16.6, 15.7, 19. , 17.9, 19.6, 18.4, 17.5, 19.5])>, 'flipper_length_mm': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([208., 195., 216., 198., 195., 208., 187., 187., 202., 193., 195.,\n",
      "       191., 198., 213., 224., 215., 194., 215., 183., 209., 183., 226.,\n",
      "       216., 224., 181., 217., 210., 193., 212., 190., 191., 200.])>, 'body_mass_g': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([4350., 4300., 4750., 3675., 3350., 4575., 3150., 3550., 3400.,\n",
      "       3200., 3850., 4600., 3700., 5400., 5650., 4850., 3525., 4750.,\n",
      "       3075., 4600., 3550., 5200., 4925., 5350., 2850., 5850., 4100.,\n",
      "       4250., 4300., 3900., 3175., 4050.])>, 'sex': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'FEMALE', b'MALE', b'MALE', b'FEMALE', b'FEMALE', b'FEMALE',\n",
      "       b'FEMALE', b'FEMALE', b'FEMALE', b'FEMALE', b'FEMALE', b'MALE',\n",
      "       b'MALE', b'MALE', b'MALE', b'FEMALE', b'FEMALE', b'FEMALE',\n",
      "       b'FEMALE', b'FEMALE', b'MALE', b'MALE', b'MALE', b'MALE',\n",
      "       b'FEMALE', b'MALE', b'MALE', b'MALE', b'MALE', b'MALE', b'FEMALE',\n",
      "       b'MALE'], dtype=object)>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 16:08:53.143833: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(\"Input:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import FeatureSpace\n",
    "\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        \"sex\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"island\": \"string_categorical\",\n",
    "        \"culmen_length_mm\": \"float_normalized\",\n",
    "        \"culmen_depth_mm\": \"float_normalized\",\n",
    "        \"flipper_length_mm\": \"float_normalized\",\n",
    "        \"body_mass_g\": \"float_normalized\",\n",
    "    },\n",
    "    output_mode=\"concat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 14:52:46.673085: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.701861: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.726271: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.750699: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.774244: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.801095: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.823662: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.850782: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.873484: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.903032: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.926288: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-08 14:52:46.953709: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "train_ds_with_no_labels = train_dataset.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_x.shape: (32, 10)\n",
      "preprocessed_x.dtype: <dtype: 'float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 14:52:47.613255: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, _ in train_dataset.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
    "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_ds = train_dataset.map(\n",
    "    lambda x, y: (feature_space(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_test_ds = test_dataset.map(\n",
    "    lambda x, y: (feature_space(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "preprocessed_test_ds = preprocessed_test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'island': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=island>,\n",
       " 'sex': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=sex>,\n",
       " 'culmen_length_mm': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=culmen_length_mm>,\n",
       " 'culmen_depth_mm': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=culmen_depth_mm>,\n",
       " 'flipper_length_mm': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=flipper_length_mm>,\n",
       " 'body_mass_g': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=body_mass_g>}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 10), dtype=float32, sparse=False, name=keras_tensor_110>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "x = Dense(10, activation=\"relu\")(encoded_features)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "outputs = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=encoded_features, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.01),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = Model(inputs=dict_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - 23ms/step - accuracy: 0.1873 - loss: 1.2161 - val_accuracy: 0.2879 - val_loss: 1.1632\n",
      "Epoch 2/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.2322 - loss: 1.1728 - val_accuracy: 0.3636 - val_loss: 1.1302\n",
      "Epoch 3/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.2996 - loss: 1.1336 - val_accuracy: 0.3636 - val_loss: 1.1041\n",
      "Epoch 4/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.3408 - loss: 1.1017 - val_accuracy: 0.4242 - val_loss: 1.0803\n",
      "Epoch 5/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.3858 - loss: 1.0732 - val_accuracy: 0.4545 - val_loss: 1.0581\n",
      "Epoch 6/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.4120 - loss: 1.0464 - val_accuracy: 0.5152 - val_loss: 1.0365\n",
      "Epoch 7/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.4494 - loss: 1.0204 - val_accuracy: 0.5152 - val_loss: 1.0140\n",
      "Epoch 8/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.4906 - loss: 0.9946 - val_accuracy: 0.5606 - val_loss: 0.9917\n",
      "Epoch 9/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.5243 - loss: 0.9701 - val_accuracy: 0.6364 - val_loss: 0.9700\n",
      "Epoch 10/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.5581 - loss: 0.9461 - val_accuracy: 0.6667 - val_loss: 0.9471\n",
      "Epoch 11/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.5993 - loss: 0.9213 - val_accuracy: 0.6818 - val_loss: 0.9248\n",
      "Epoch 12/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.6404 - loss: 0.8972 - val_accuracy: 0.7273 - val_loss: 0.9017\n",
      "Epoch 13/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.6592 - loss: 0.8727 - val_accuracy: 0.7424 - val_loss: 0.8783\n",
      "Epoch 14/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.6891 - loss: 0.8486 - val_accuracy: 0.7424 - val_loss: 0.8538\n",
      "Epoch 15/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.7079 - loss: 0.8248 - val_accuracy: 0.7727 - val_loss: 0.8297\n",
      "Epoch 16/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.7228 - loss: 0.8006 - val_accuracy: 0.7727 - val_loss: 0.8058\n",
      "Epoch 17/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.7453 - loss: 0.7767 - val_accuracy: 0.7879 - val_loss: 0.7810\n",
      "Epoch 18/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.7790 - loss: 0.7528 - val_accuracy: 0.8182 - val_loss: 0.7570\n",
      "Epoch 19/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8090 - loss: 0.7296 - val_accuracy: 0.8182 - val_loss: 0.7322\n",
      "Epoch 20/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8427 - loss: 0.7062 - val_accuracy: 0.8485 - val_loss: 0.7074\n",
      "Epoch 21/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8577 - loss: 0.6831 - val_accuracy: 0.8636 - val_loss: 0.6833\n",
      "Epoch 22/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8689 - loss: 0.6605 - val_accuracy: 0.8788 - val_loss: 0.6594\n",
      "Epoch 23/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8764 - loss: 0.6388 - val_accuracy: 0.9091 - val_loss: 0.6362\n",
      "Epoch 24/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.8914 - loss: 0.6173 - val_accuracy: 0.9242 - val_loss: 0.6133\n",
      "Epoch 25/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9176 - loss: 0.5963 - val_accuracy: 0.9545 - val_loss: 0.5896\n",
      "Epoch 26/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9213 - loss: 0.5756 - val_accuracy: 0.9545 - val_loss: 0.5666\n",
      "Epoch 27/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9363 - loss: 0.5553 - val_accuracy: 0.9545 - val_loss: 0.5450\n",
      "Epoch 28/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9401 - loss: 0.5351 - val_accuracy: 0.9545 - val_loss: 0.5243\n",
      "Epoch 29/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9401 - loss: 0.5163 - val_accuracy: 0.9545 - val_loss: 0.5042\n",
      "Epoch 30/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.4974 - val_accuracy: 0.9697 - val_loss: 0.4839\n",
      "Epoch 31/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.4794 - val_accuracy: 0.9697 - val_loss: 0.4656\n",
      "Epoch 32/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9513 - loss: 0.4620 - val_accuracy: 0.9697 - val_loss: 0.4475\n",
      "Epoch 33/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9588 - loss: 0.4452 - val_accuracy: 0.9697 - val_loss: 0.4301\n",
      "Epoch 34/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9588 - loss: 0.4287 - val_accuracy: 0.9697 - val_loss: 0.4137\n",
      "Epoch 35/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9625 - loss: 0.4129 - val_accuracy: 0.9697 - val_loss: 0.3977\n",
      "Epoch 36/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9663 - loss: 0.3974 - val_accuracy: 0.9545 - val_loss: 0.3809\n",
      "Epoch 37/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9700 - loss: 0.3818 - val_accuracy: 0.9545 - val_loss: 0.3652\n",
      "Epoch 38/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9700 - loss: 0.3671 - val_accuracy: 0.9545 - val_loss: 0.3502\n",
      "Epoch 39/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3530 - val_accuracy: 0.9545 - val_loss: 0.3362\n",
      "Epoch 40/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3394 - val_accuracy: 0.9545 - val_loss: 0.3226\n",
      "Epoch 41/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3262 - val_accuracy: 0.9545 - val_loss: 0.3097\n",
      "Epoch 42/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3137 - val_accuracy: 0.9545 - val_loss: 0.2972\n",
      "Epoch 43/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.3011 - val_accuracy: 0.9545 - val_loss: 0.2854\n",
      "Epoch 44/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9738 - loss: 0.2890 - val_accuracy: 0.9545 - val_loss: 0.2736\n",
      "Epoch 45/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9775 - loss: 0.2774 - val_accuracy: 0.9545 - val_loss: 0.2625\n",
      "Epoch 46/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9775 - loss: 0.2665 - val_accuracy: 0.9545 - val_loss: 0.2517\n",
      "Epoch 47/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9775 - loss: 0.2553 - val_accuracy: 0.9545 - val_loss: 0.2416\n",
      "Epoch 48/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9813 - loss: 0.2448 - val_accuracy: 0.9545 - val_loss: 0.2315\n",
      "Epoch 49/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9813 - loss: 0.2347 - val_accuracy: 0.9697 - val_loss: 0.2221\n",
      "Epoch 50/50\n",
      "9/9 - 0s - 5ms/step - accuracy: 0.9813 - loss: 0.2247 - val_accuracy: 0.9697 - val_loss: 0.2129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3a63ae4a0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    preprocessed_train_ds,\n",
    "    epochs=50,\n",
    "    validation_data=preprocessed_test_ds,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'island': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Biscoe', b'Torgersen', b'Torgersen'], dtype=object)>,\n",
       " 'culmen_length_mm': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([48.6, 44.1, 39.1], dtype=float32)>,\n",
       " 'culmen_depth_mm': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([16. , 18. , 18.7], dtype=float32)>,\n",
       " 'flipper_length_mm': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([230., 210., 181.], dtype=float32)>,\n",
       " 'body_mass_g': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([5800., 4000., 3750.], dtype=float32)>,\n",
       " 'sex': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'MALE', b'FEMALE', b'MALE'], dtype=object)>}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = {\n",
    "    \"island\": [\"Biscoe\", \"Torgersen\", \"Torgersen\"],\n",
    "    \"culmen_length_mm\": [48.6, 44.1, 39.1],\n",
    "    \"culmen_depth_mm\": [16.0, 18.0, 18.7],\n",
    "    \"flipper_length_mm\": [230.0, 210.0, 181.0],\n",
    "    \"body_mass_g\": [5800.0, 4000.0, 3750.0],\n",
    "    \"sex\": [\"MALE\", \"FEMALE\", \"MALE\"],\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor(value) for name, value in sample.items()}\n",
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03257361, 0.14812116, 0.81930524],\n",
       "       [0.3940005 , 0.28193894, 0.32406056],\n",
       "       [0.94649315, 0.02197206, 0.0315347 ]], dtype=float32)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = inference_model.predict(input_dict)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "\n",
    "\n",
    "def pred(p):\n",
    "    return tf.stack(\n",
    "        [\n",
    "            tf.cast(tf.math.argmax(p, axis=1), dtype=tf.float32),\n",
    "            tf.math.reduce_max(p, axis=1),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "prediction = Lambda(pred)(outputs)\n",
    "\n",
    "inference_model2 = Model(inputs=dict_inputs, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.        , 0.        , 0.        ],\n",
       "       [0.81930524, 0.3940005 , 0.94649315]], dtype=float32)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = inference_model2.predict(input_dict)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adelie', 'Chinstrap', 'Gentoo']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lookup.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = StringLookup(\n",
    "    vocabulary=label_lookup.get_vocabulary(),\n",
    "    invert=True,\n",
    "    num_oov_indices=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'Gentoo', b'Adelie', b'Adelie'], dtype=object)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(np.argmax(result, axis=1)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 0]), array([0.81930524, 0.3940005 , 0.94649315], dtype=float32))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(result, axis=1), np.max(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prediction': 'Adelie', 'confidence': 0.6},\n",
       " {'prediction': 'Gentoo', 'confidence': 0.9},\n",
       " {'prediction': 'Chinstrap', 'confidence': 0.8},\n",
       " {'prediction': 'Chinstrap', 'confidence': 0.7}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n",
    "\n",
    "prediction = np.array([0, 2, 1, 1])\n",
    "condifence = np.array([0.6, 0.9, 0.8, 0.7])\n",
    "\n",
    "prediction = np.vectorize(lambda x: classes[x])(prediction)\n",
    "\n",
    "[\n",
    "    {\"prediction\": p, \"confidence\": c}\n",
    "    for p, c in zip(prediction, condifence, strict=True)\n",
    "]\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adelie', 'Gentoo', 'Chinstrap', 'Chinstrap']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
